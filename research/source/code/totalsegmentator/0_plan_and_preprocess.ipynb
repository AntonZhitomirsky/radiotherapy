{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Planning and Preprocessing Data for Transfer Learning\n",
    "\n",
    "In order to fine tune the model on data that we have, the data must be transfored so that\n",
    "it matches the fingerprint of the data the original model was trained with. We can\n",
    "apparently fine-tune the model with the `plans.json` file that appears in each model's\n",
    "checkpoint once we download the weights for the model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "dir1 = os.path.abspath(os.path.join(os.path.abspath(''), '..'))\n",
    "if not dir1 in sys.path: sys.path.append(dir1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.environment import setup_data_vars\n",
    "setup_data_vars()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_raw_and_gt_data_paths():\n",
    "    \n",
    "    setup_data_vars()\n",
    "\n",
    "    classes = [os.environ.get('Anorectum')\n",
    "             , os.environ.get('Bladder') \n",
    "             , os.environ.get('CTVn') \n",
    "             , os.environ.get('CTVp') \n",
    "             , os.environ.get('Parametrium') \n",
    "             , os.environ.get('Uterus') \n",
    "             , os.environ.get('Vagina')]\n",
    "\n",
    "    raw_data = [os.path.join(os.environ.get('nnUNet_raw'), x, os.environ.get('data_trainingImages')) for x in classes]\n",
    "    gt_labels = [os.path.join(os.environ.get('nnUNet_raw'), x, os.environ.get('data_trainingLabels')) for x in classes]\n",
    "\n",
    "    return classes, raw_data, gt_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from totalsegmentator.config import setup_nnunet, setup_totalseg\n",
    "from totalsegmentator.libs import download_pretrained_weights\n",
    "\n",
    "def fetch_pretrained_totalsegmentator_model():\n",
    "    \"\"\"\n",
    "    Fetch the pretrained TotalSegmentator model.\n",
    "\n",
    "    The total segmentator model loads a separately trained nnUNet model for each new class\n",
    "    However, it is not trained on the parametrium case. Therefore, we load the general\n",
    "    model and attempt to finetune it on my case.\n",
    "    \"\"\"\n",
    "\n",
    "    os.environ['TOTALSEG_HOME_DIR'] = os.path.join(os.environ.get('PROJECT_DIR'), 'models', 'TotalSegmentator', '.weights')\n",
    "\n",
    "    setup_nnunet()\n",
    "    setup_totalseg()\n",
    "\n",
    "    # We assume that the model we are running will be finetuned with the 'total' task from\n",
    "    # the original TotalSegmentator model because this contains the most information about\n",
    "    # soft organ classification, most of which happens in the abdomen region, which\n",
    "    # intuitively seems like the most logical knowledge to transfer into this task\n",
    "\n",
    "    # From the totalsegmentator.python_api this task ID corresponds with the model trained\n",
    "    # for organ segmentation. Note there is also potential for cropping the image.\n",
    "    task_id = 291\n",
    "    download_pretrained_weights(task_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG]: Obtained the environment variables. These are:\n",
      "nnUNet_raw: /vol/biomedic3/bglocker/ugproj2324/az620/radiotherapy/data/nnUNet_raw\n",
      "nnUNet_preprocessed: /vol/biomedic3/bglocker/ugproj2324/az620/radiotherapy/data/nnUNet_preprocessed\n",
      "nnUNet_results: /vol/biomedic3/bglocker/ugproj2324/az620/radiotherapy/data/nnUNet_results\n",
      "RUNNING THE TRANSFER OF PLANS BETWEEN DATASETS......................\n",
      "Transferring for 1\n",
      "Transferring for 2\n",
      "Transferring for 3\n",
      "Transferring for 4\n",
      "Transferring for 5\n",
      "Transferring for 6\n",
      "Transferring for 7\n",
      "Now you can run the preprocessing on the source task:\n",
      "Preprocessing for class: 1  ( Dataset001_Anorectum )\n",
      "Preprocessing dataset Dataset001_Anorectum\n",
      "Configuration: 3d_fullres...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/vol/biomedic3/bglocker/ugproj2324/az620/radiotherapy/models/nnUNet/nnunetv2/utilities/plans_handling/plans_handler.py:37: UserWarning: Detected old nnU-Net plans format. Attempting to reconstruct network architecture parameters. If this fails, rerun nnUNetv2_plan_experiment for your dataset. If you use a custom architecture, please downgrade nnU-Net to the version you implemented this or update your implementation + plans.\n",
      "  warnings.warn(\"Detected old nnU-Net plans format. Attempting to reconstruct network architecture \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing the following configuration: 3d_fullres\n",
      "{'data_identifier': 'totseg_nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 2, 'patch_size': [128, 128, 128], 'median_image_size_in_voxels': [227.0, 227.0, 239.0], 'spacing': [1.5, 1.5, 1.5], 'normalization_schemes': ['CTNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'batch_dice': True, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': [32, 64, 128, 256, 320, 320], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}}\n",
      "old shape: (219, 512, 512), new_shape: [292 333 333], old_spacing: [2.0, 0.9765625, 0.9765625], new_spacing: [1.5, 1.5, 1.5], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x797951f781f0>, is_seg=False, order=3, order_z=0, force_separate_z=None)\n",
      "1 10000\n",
      "old shape: (225, 512, 512), new_shape: [300 333 333], old_spacing: [2.0, 0.9765625, 0.9765625], new_spacing: [1.5, 1.5, 1.5], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x7fefe8b641f0>, is_seg=False, order=3, order_z=0, force_separate_z=None)\n",
      "1 10000\n",
      "old shape: (267, 512, 512), new_shape: [356 333 333], old_spacing: [2.0, 0.9765625, 0.9765625], new_spacing: [1.5, 1.5, 1.5], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x752250a641f0>, is_seg=False, order=3, order_z=0, force_separate_z=None)\n",
      "1 10000\n",
      "old shape: (297, 512, 512), new_shape: [396 333 333], old_spacing: [2.0, 0.9765625, 0.9765625], new_spacing: [1.5, 1.5, 1.5], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x762b39de81f0>, is_seg=False, order=3, order_z=0, force_separate_z=None)\n",
      "1 8792\n",
      "old shape: (180, 512, 512), new_shape: [300 367 367], old_spacing: [2.5, 1.074218988418579, 1.074218988418579], new_spacing: [1.5, 1.5, 1.5], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x797951f781f0>, is_seg=False, order=3, order_z=0, force_separate_z=None)\n",
      "1 10000\n",
      "old shape: (189, 512, 512), new_shape: [315 367 367], old_spacing: [2.5, 1.074218988418579, 1.074218988418579], new_spacing: [1.5, 1.5, 1.5], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x752250a641f0>, is_seg=False, order=3, order_z=0, force_separate_z=None)\n",
      "1 10000\n",
      "old shape: (183, 512, 512), new_shape: [305 400 400], old_spacing: [2.5, 1.171875, 1.171875], new_spacing: [1.5, 1.5, 1.5], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x762b39de81f0>, is_seg=False, order=3, order_z=0, force_separate_z=None)\n",
      "1 10000\n",
      "old shape: (248, 512, 512), new_shape: [413 433 433], old_spacing: [2.5, 1.269531011581421, 1.269531011581421], new_spacing: [1.5, 1.5, 1.5], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x7fefe8b641f0>, is_seg=False, order=3, order_z=0, force_separate_z=None)\n",
      "1 10000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 64\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPreprocessing for class:\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28mstr\u001b[39m(i), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m (\u001b[39m\u001b[38;5;124m'\u001b[39m, classes[i \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     63\u001b[0m     sys\u001b[38;5;241m.\u001b[39margv \u001b[38;5;241m=\u001b[39m [original_sys_argv[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-d\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28mstr\u001b[39m(i), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-plans_name\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtotseg_nnUNetPlans\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-c\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m3d_fullres\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m--verbose\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-np\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m4\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;66;03m#, '-overwrite_plans_name', 'totseg_nnUNetPlans']\u001b[39;00m\n\u001b[0;32m---> 64\u001b[0m     \u001b[43mpreprocess_entry\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m sys\u001b[38;5;241m.\u001b[39margv \u001b[38;5;241m=\u001b[39m original_sys_argv\n",
      "File \u001b[0;32m/vol/biomedic3/bglocker/ugproj2324/az620/radiotherapy/models/nnUNet/nnunetv2/experiment_planning/plan_and_preprocess_entrypoints.py:106\u001b[0m, in \u001b[0;36mpreprocess_entry\u001b[0;34m()\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    105\u001b[0m     np \u001b[38;5;241m=\u001b[39m args\u001b[38;5;241m.\u001b[39mnp\n\u001b[0;32m--> 106\u001b[0m \u001b[43mpreprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43md\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplans_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfigurations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_processes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/vol/biomedic3/bglocker/ugproj2324/az620/radiotherapy/models/nnUNet/nnunetv2/experiment_planning/plan_and_preprocess_api.py:142\u001b[0m, in \u001b[0;36mpreprocess\u001b[0;34m(dataset_ids, plans_identifier, configurations, num_processes, verbose)\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpreprocess\u001b[39m(dataset_ids: List[\u001b[38;5;28mint\u001b[39m],\n\u001b[1;32m    137\u001b[0m                plans_identifier: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnnUNetPlans\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    138\u001b[0m                configurations: Union[Tuple[\u001b[38;5;28mstr\u001b[39m], List[\u001b[38;5;28mstr\u001b[39m]] \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2d\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m3d_fullres\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m3d_lowres\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[1;32m    139\u001b[0m                num_processes: Union[\u001b[38;5;28mint\u001b[39m, Tuple[\u001b[38;5;28mint\u001b[39m, \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m], List[\u001b[38;5;28mint\u001b[39m]] \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m8\u001b[39m),\n\u001b[1;32m    140\u001b[0m                verbose: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m dataset_ids:\n\u001b[0;32m--> 142\u001b[0m         \u001b[43mpreprocess_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43md\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplans_identifier\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfigurations\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_processes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/vol/biomedic3/bglocker/ugproj2324/az620/radiotherapy/models/nnUNet/nnunetv2/experiment_planning/plan_and_preprocess_api.py:121\u001b[0m, in \u001b[0;36mpreprocess_dataset\u001b[0;34m(dataset_id, plans_identifier, configurations, num_processes, verbose)\u001b[0m\n\u001b[1;32m    119\u001b[0m     configuration_manager \u001b[38;5;241m=\u001b[39m plans_manager\u001b[38;5;241m.\u001b[39mget_configuration(c)\n\u001b[1;32m    120\u001b[0m     preprocessor \u001b[38;5;241m=\u001b[39m configuration_manager\u001b[38;5;241m.\u001b[39mpreprocessor_class(verbose\u001b[38;5;241m=\u001b[39mverbose)\n\u001b[0;32m--> 121\u001b[0m     \u001b[43mpreprocessor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplans_identifier\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_processes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;66;03m# copy the gt to a folder in the nnUNet_preprocessed so that we can do validation even if the raw data is no\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;66;03m# longer there (useful for compute cluster where only the preprocessed data is available)\u001b[39;00m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdistutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfile_util\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m copy_file\n",
      "File \u001b[0;32m/vol/biomedic3/bglocker/ugproj2324/az620/radiotherapy/models/nnUNet/nnunetv2/preprocessing/preprocessors/default_preprocessor.py:257\u001b[0m, in \u001b[0;36mDefaultPreprocessor.run\u001b[0;34m(self, dataset_name_or_id, configuration_name, plans_identifier, num_processes)\u001b[0m\n\u001b[1;32m    255\u001b[0m     pbar\u001b[38;5;241m.\u001b[39mupdate()\n\u001b[1;32m    256\u001b[0m remaining \u001b[38;5;241m=\u001b[39m [i \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m remaining \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m done]\n\u001b[0;32m--> 257\u001b[0m \u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "import sys\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Download the weights from TotalSegmentator\n",
    "    fetch_pretrained_totalsegmentator_model()\n",
    "\n",
    "    # Something in the fetch_pretrained_totalsegmentator_model overwrites the global variables\n",
    "    classes, raw_data, gt_labels = get_raw_and_gt_data_paths()\n",
    "    \n",
    "    source_file = os.path.join(os.environ.get('TOTALSEG_HOME_DIR'), 'nnunet', 'results', 'Dataset291_TotalSegmentator_part1_organs_1559subj', 'nnUNetTrainerNoMirroring__nnUNetPlans__3d_fullres', 'plans.json')\n",
    "    destination_file = os.path.join(os.environ.get('nnUNet_preprocessed'), 'Dataset008_TotalSegmentator', 'nnUNetPlans.json')\n",
    "\n",
    "    assert os.path.exists(source_file), \"The source file does not exist\"\n",
    "    shutil.copy(source_file, destination_file)\n",
    "\n",
    "    print('[DEBUG]: Obtained the environment variables. These are:')\n",
    "    print(f'nnUNet_raw: {os.environ.get(\"nnUNet_raw\")}')\n",
    "    print(f'nnUNet_preprocessed: {os.environ.get(\"nnUNet_preprocessed\")}')\n",
    "    print(f'nnUNet_results: {os.environ.get(\"nnUNet_results\")}')\n",
    "\n",
    "    # Set the data to pre-train on the fingerprint of the training data.\n",
    "    \n",
    "    \"\"\"\n",
    "    TARGET_DATASET = the one you wish to fine tune on, Radiotherapy data\n",
    "    SOURCE_DATASET = dataset you intend to run the pretraining on, TotalSegmentator\n",
    "\n",
    "    1. nnUNetv2_plan_and_preprocess -d TARGET_DATASET (this has been done already)\n",
    "    2. nnUNetv2_extract_fingerprint -d SOURCE_DATASET (this has been achieved by creating a dummy dataset id into which I copied the .json files obtained from the downloaded model)\n",
    "\n",
    "    Path to the plans.json for TotalSegmentator:\n",
    "    /vol/bitbucket/az620/radiotherapy/models/TotalSegmentator/.weights/nnunet/results/Dataset291_TotalSegmentator_part1_organs_1559subj/nnUNetTrainerNoMirroring__nnUNetPlans__3d_fullres/plans.json\n",
    "\n",
    "    3. Now I need to move the plans from the dummy dataset to the Radiotherapy dataset. Need to do this one at a time for each class\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    print('RUNNING THE TRANSFER OF PLANS BETWEEN DATASETS......................')\n",
    "\n",
    "    from nnunetv2.experiment_planning.plans_for_pretraining.move_plans_between_datasets import move_plans_between_datasets\n",
    "\n",
    "    starting_class = 1\n",
    "    end_class = 7 # len(classes)\n",
    "\n",
    "    for i in range(starting_class, end_class + 1):\n",
    "        print(f'Transferring for {i}')\n",
    "\n",
    "        move_plans_between_datasets(source_dataset_name_or_id=8\n",
    "                                    , target_dataset_name_or_id=i\n",
    "                                    , source_plans_identifier='nnUNetPlans'\n",
    "                                    , target_plans_identifier=f'totseg_nnUNetPlans'\n",
    "        )\n",
    "\n",
    "    print('Now you can run the preprocessing on the source task:')\n",
    "\n",
    "    from nnunetv2.experiment_planning.plan_and_preprocess_entrypoints import preprocess_entry\n",
    "\n",
    "    original_sys_argv = sys.argv\n",
    "\n",
    "    for i in range(starting_class, end_class + 1):\n",
    "        print('Preprocessing for class:', str(i), ' (', classes[i - 1], ')')\n",
    "\n",
    "        sys.argv = [original_sys_argv[0], '-d', str(i), '-plans_name', 'totseg_nnUNetPlans', '-c', '3d_fullres', '--verbose', '-np', '4'] #, '-overwrite_plans_name', 'totseg_nnUNetPlans']\n",
    "        preprocess_entry()\n",
    "    \n",
    "    sys.argv = original_sys_argv"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
