{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run inference on the nnUNet Model we have fine-tuned\n",
    "\n",
    "Assuming that the pre-processed data is available, and the model has been trained for a\n",
    "fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "dir1 = os.path.abspath(os.path.join(os.path.abspath(''), '..'))\n",
    "if not dir1 in sys.path: sys.path.append(dir1)\n",
    "from utils.environment import setup_data_vars\n",
    "setup_data_vars()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_raw_and_gt_data_paths():\n",
    "    \n",
    "    setup_data_vars()\n",
    "\n",
    "    classes = [os.environ.get('Anorectum')\n",
    "             , os.environ.get('Bladder') \n",
    "             , os.environ.get('CTVn') \n",
    "             , os.environ.get('CTVp') \n",
    "             , os.environ.get('Parametrium') \n",
    "             , os.environ.get('Uterus') \n",
    "             , os.environ.get('Vagina')]\n",
    "\n",
    "    raw_data = [os.path.join(os.environ.get('nnUNet_raw'), x, os.environ.get('data_trainingImages')) for x in classes]\n",
    "    gt_labels = [os.path.join(os.environ.get('nnUNet_raw'), x, os.environ.get('data_trainingLabels')) for x in classes]\n",
    "\n",
    "    return classes, raw_data, gt_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialise_predictor(model_path, fold, device):\n",
    "\n",
    "    from nnunetv2.inference.predict_from_raw_data import nnUNetPredictor\n",
    "    import torch\n",
    "\n",
    "    predictor = nnUNetPredictor(\n",
    "            tile_step_size=0.5,\n",
    "            use_gaussian=True,\n",
    "            use_mirroring=True,\n",
    "            perform_everything_on_device=True,\n",
    "            device=device,\n",
    "            verbose=False,\n",
    "            verbose_preprocessing=False,\n",
    "            allow_tqdm=True\n",
    "        )\n",
    "\n",
    "    predictor.initialize_from_trained_model_folder(\n",
    "        model_path,\n",
    "        use_folds=fold,\n",
    "        checkpoint_name='checkpoint_final.pth',\n",
    "    )\n",
    "\n",
    "    return predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG]: Obtained the environment variables. These are:\n",
      "nnUNet_raw: /vol/bitbucket/az620/radiotherapy/data/nnUNet_raw\n",
      "nnUNet_preprocessed: /vol/bitbucket/az620/radiotherapy/data/nnUNet_preprocessed\n",
      "nnUNet_results: /vol/bitbucket/az620/radiotherapy/data/nnUNet_results\n",
      "I am predicting on the dataset: Dataset002_Bladder\n",
      "The Fold is: (0,)\n",
      "The config I'm using is: 3d_fullres\n",
      "The model path is: /vol/bitbucket/az620/radiotherapy/data/nnUNet_results/Dataset002_Bladder/nnUNetTrainer_50epochs__totseg_nnUNetPlans__3d_fullres\n",
      "The input file is: /vol/bitbucket/az620/radiotherapy/data/nnUNet_raw/Dataset002_Bladder/imagesTr\n",
      "The output file is: /vol/bitbucket/az620/radiotherapy/data/nnUNet_raw/../TotalSegmentator_inference/Dataset002_Bladder/nnUNetTrainer_50epochs__totseg_nnUNetPlans__3d_fullres\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/vol/bitbucket/az620/radiotherapy/models/nnUNet/nnunetv2/utilities/plans_handling/plans_handler.py:37: UserWarning: Detected old nnU-Net plans format. Attempting to reconstruct network architecture parameters. If this fails, rerun nnUNetv2_plan_experiment for your dataset. If you use a custom architecture, please downgrade nnU-Net to the version you implemented this or update your implementation + plans.\n",
      "  warnings.warn(\"Detected old nnU-Net plans format. Attempting to reconstruct network architecture \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 100 cases in the source folder\n",
      "I am process 0 out of 1 (max process ID is 0, we start counting with 0!)\n",
      "There are 100 cases that I would like to predict\n",
      "overwrite was set to False, so I am only working on cases that haven't been predicted yet. That's 100 cases.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 56\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe output file is:\u001b[39m\u001b[38;5;124m'\u001b[39m, output_file)\n\u001b[1;32m     55\u001b[0m predictor \u001b[38;5;241m=\u001b[39m initialise_predictor(model_path, FOLD, device)\n\u001b[0;32m---> 56\u001b[0m \u001b[43mpredictor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_from_files\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[43m                             \u001b[49m\u001b[43moutput_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[43m                             \u001b[49m\u001b[43msave_probabilities\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moverwrite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mnum_processes_preprocessing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_processes_segmentation_export\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mfolder_with_segs_from_prev_stage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_parts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpart_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/vol/bitbucket/az620/radiotherapy/models/nnUNet/nnunetv2/inference/predict_from_raw_data.py:256\u001b[0m, in \u001b[0;36mnnUNetPredictor.predict_from_files\u001b[0;34m(self, list_of_lists_or_source_folder, output_folder_or_list_of_truncated_output_files, save_probabilities, overwrite, num_processes_preprocessing, num_processes_segmentation_export, folder_with_segs_from_prev_stage, num_parts, part_id)\u001b[0m\n\u001b[1;32m    250\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    252\u001b[0m data_iterator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_internal_get_data_iterator_from_lists_of_filenames(list_of_lists_or_source_folder,\n\u001b[1;32m    253\u001b[0m                                                                          seg_from_prev_stage_files,\n\u001b[1;32m    254\u001b[0m                                                                          output_filename_truncated,\n\u001b[1;32m    255\u001b[0m                                                                          num_processes_preprocessing)\n\u001b[0;32m--> 256\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_from_data_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_iterator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_probabilities\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_processes_segmentation_export\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/vol/bitbucket/az620/radiotherapy/models/nnUNet/nnunetv2/inference/predict_from_raw_data.py:349\u001b[0m, in \u001b[0;36mnnUNetPredictor.predict_from_data_iterator\u001b[0;34m(self, data_iterator, save_probabilities, num_processes_segmentation_export)\u001b[0m\n\u001b[1;32m    347\u001b[0m worker_list \u001b[38;5;241m=\u001b[39m [i \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m export_pool\u001b[38;5;241m.\u001b[39m_pool]\n\u001b[1;32m    348\u001b[0m r \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m--> 349\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m preprocessed \u001b[38;5;129;01min\u001b[39;00m data_iterator:\n\u001b[1;32m    350\u001b[0m     data \u001b[38;5;241m=\u001b[39m preprocessed[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m    351\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mstr\u001b[39m):\n",
      "File \u001b[0;32m/vol/bitbucket/az620/radiotherapy/models/nnUNet/nnunetv2/inference/data_iterators.py:114\u001b[0m, in \u001b[0;36mpreprocessing_iterator_fromfiles\u001b[0;34m(list_of_lists, list_of_segs_from_prev_stage_files, output_filenames_truncated, plans_manager, dataset_json, configuration_manager, num_processes, pin_memory, verbose)\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m all_ok:\n\u001b[1;32m    111\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBackground workers died. Look for the error message further up! If there is \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    112\u001b[0m                            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnone then your RAM was full and the worker was killed by the OS. Use fewer \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    113\u001b[0m                            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mworkers or get more RAM in that case!\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 114\u001b[0m     \u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pin_memory:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import torch\n",
    "import argparse\n",
    "import multiprocessing\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    multiprocessing.freeze_support()\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device('cuda')\n",
    "    else:\n",
    "        device = torch.device('cpu')   \n",
    "\n",
    "    setup_data_vars()\n",
    "    classes, raw_data, gt_labels = get_raw_and_gt_data_paths()\n",
    "\n",
    "    print('[DEBUG]: Obtained the environment variables. These are:')\n",
    "    print(f'nnUNet_raw: {os.environ.get(\"nnUNet_raw\")}')\n",
    "    print(f'nnUNet_preprocessed: {os.environ.get(\"nnUNet_preprocessed\")}')\n",
    "    print(f'nnUNet_results: {os.environ.get(\"nnUNet_results\")}')\n",
    "\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('dataset', type=int, help='The dataset to run inference on')\n",
    "    parser.add_argument('fold', type=int, help='The max number of nodes that were trained')\n",
    "    args = parser.parse_args()\n",
    "    \n",
    "    assert args.dataset is not None, \"Please provide the dataset to fine tune on\"\n",
    "    assert args.dataset in range(1, len(classes) + 1), \"Please provide a valid dataset to fine tune on\"\n",
    "\n",
    "    assert args.fold is not None, \"Please provide the fold to run inference on\"\n",
    "    assert args.fold in range(5), \"Please provide a valid fold to run inference on\"\n",
    "\n",
    "    TARGET_DATASET = args.dataset\n",
    "    FOLD = tuple(range(0, args.fold + 1))\n",
    "    CONFIG = '3d_fullres'\n",
    "\n",
    "    # TARGET_DATASET = 2\n",
    "    # FOLD = tuple(range(0, 0 + 1))\n",
    "\n",
    "    # Run inference\n",
    "    model_name = 'nnUNetTrainer_500epochs__nnUNetResEncUNetLPlans__3d_fullres'\n",
    "    input_file = os.path.join(os.environ.get('nnUNet_raw'), classes[TARGET_DATASET - 1], os.environ.get('data_trainingImages'))\n",
    "    model_path = os.path.join(os.environ.get('nnUNet_results'), classes[TARGET_DATASET - 1], model_name) \n",
    "    output_file = os.path.join(os.environ.get('TotalSegmentator_inference'), classes[TARGET_DATASET - 1], model_name)\n",
    "\n",
    "    print('I am predicting on the dataset:', classes[TARGET_DATASET - 1])\n",
    "    print('The Fold is:', FOLD)\n",
    "    print('The config I\\'m using is:', CONFIG)\n",
    "    print('The model path is:', model_path)\n",
    "    print('The input file is:', input_file)\n",
    "    print('The output file is:', output_file)\n",
    "\n",
    "    predictor = initialise_predictor(model_path, FOLD, device)\n",
    "    predictor.predict_from_files(input_file,\n",
    "                                 output_file,\n",
    "                                 save_probabilities=False, overwrite=False,\n",
    "                                 num_processes_preprocessing=2, num_processes_segmentation_export=2,\n",
    "                                 folder_with_segs_from_prev_stage=None, num_parts=1, part_id=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
