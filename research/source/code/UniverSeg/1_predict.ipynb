{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UniverSeg\n",
    "\n",
    "- From the following paper: https://universeg.csail.mit.edu/\n",
    "- From the git repo: https://github.com/JJGO/UniverSeg\n",
    "- Form the example google colab: https://colab.research.google.com/drive/1TiNAgCehFdyHMJsS90V9ygUw0rLXdW0r?usp=sharing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/vol/bitbucket/az620/radiotherapy/.venv/lib/python3.10/site-packages/torch/cuda/__init__.py:141: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 11040). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import itertools\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "from universeg import universeg\n",
    "\n",
    "model = universeg(pretrained=True)\n",
    "_ = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using visualisation code from tutorial in google colab\n",
    "def visualize_tensors(tensors, col_wrap=8, col_names=None, title=None):\n",
    "    M = len(tensors)\n",
    "    N = len(next(iter(tensors.values())))\n",
    "\n",
    "    cols = col_wrap\n",
    "    rows = math.ceil(N/cols) * M\n",
    "\n",
    "    d = 2.5\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(d*cols, d*rows))\n",
    "    if rows == 1:\n",
    "      axes = axes.reshape(1, cols)\n",
    "\n",
    "    for g, (grp, tensors) in enumerate(tensors.items()):\n",
    "        for k, tensor in enumerate(tensors):\n",
    "            col = k % cols\n",
    "            row = g + M*(k//cols)\n",
    "            x = tensor.detach().cpu().numpy().squeeze()\n",
    "            ax = axes[row,col]\n",
    "            if len(x.shape) == 2:\n",
    "                ax.imshow(x,vmin=0, vmax=1, cmap='gray')\n",
    "            else:\n",
    "                ax.imshow(E.rearrange(x,'C H W -> H W C'))\n",
    "            if col == 0:\n",
    "                ax.set_ylabel(grp, fontsize=16)\n",
    "            if col_names is not None and row == 0:\n",
    "                ax.set_title(col_names[col])\n",
    "\n",
    "    for i in range(rows):\n",
    "        for j in range(cols):\n",
    "            ax = axes[i,j]\n",
    "            ax.grid(False)\n",
    "            ax.set_xticks([])\n",
    "            ax.set_yticks([])\n",
    "\n",
    "    if title:\n",
    "        plt.suptitle(title, fontsize=20)\n",
    "\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quoted from the tutorial, helpful text for setting up the context;\n",
    "\n",
    "\"\"\"Given a new segmentation task (e.g. new biomedical domain, new image type, new region of interest, etc), most existing strategies involve training or fine-tuning a segmentation model (often a UNet-like CNN) that takes as input an image $x$ and outputs the segmentation map $y$.\n",
    "\n",
    "This process works well in machine-learning labs, but is challenging in many applied settings, such as for scientists or clinical researchers who drive important scientific questions, but often lack the machine-learning expertiese and computational resources necessary.\n",
    "\n",
    "UniverSeg enables users to tackle a new segmentation task without the need to train or fine-tune a model, removing the ML experience requirements and computational burden. The key idea is to have a *single* global model which adapts to a new segmentation task at inference. Given a new segmentation task, defined by a few example image-segmentation pairs $\\mathcal{T} = \\{x_n, y_n\\}$, UniverSeg segments a new image $x$ by taking as input both $x$ and the task examples $\\mathcal{T}$ and outputs the segmentation map $f(x, \\mathcal{T}) = y$.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The path exists.\n",
      "The relevant contents are...\n",
      "   nnUNet_preprocessed\n",
      "   nnUNet_raw\n",
      "   nnUNet_results\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Set up the path to the data.\n",
    "data_path = '/vol/bitbucket/az620/radiotherapy/data'\n",
    "\n",
    "if os.path.exists(data_path):\n",
    "    print(\"The path exists.\")\n",
    "    print('The relevant contents are...')\n",
    "    for x in sorted(os.listdir(data_path)): \n",
    "        if 'nnUNet' in x: print(f'   {x}')\n",
    "else:\n",
    "    print(\"The path does not exist.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each anatomical structure has a unique identifier.\n",
    "id_anorectum = 'Dataset001_Anorectum'\n",
    "id_bladder = 'Dataset002_Bladder'\n",
    "id_ctvn = 'Dataset003_CTVn'\n",
    "id_ctvp = 'Dataset004_CTVp'\n",
    "id_parametrium = 'Dataset005_Parametrium'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'channel_names': {'0': 'CT'},\n",
       " 'labels': {'background': 0, 'anorectum': 1},\n",
       " 'numTraining': 100,\n",
       " 'file_ending': '.nii.gz',\n",
       " 'overwrite_image_reader_writer': 'SimpleITKIO'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "file_path = os.path.join(data_path, 'nnUNet_raw', id_anorectum, 'dataset.json')\n",
    "\n",
    "with open(file_path, 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "bladder_raw_data_x_path = os.path.join(data_path, 'nnUNet_raw', id_bladder, 'imagesTr')\n",
    "bladder_label_y_path = os.path.join(data_path, 'nnUNet_raw', id_bladder, 'imagesTr')\n",
    "bladder_output_path = os.path.join(data_path, 'UniverSeg', id_bladder, 'resultsTr')\n",
    "\n",
    "os.makedirs(bladder_output_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1291053/2070392723.py:12: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:275.)\n",
      "  bladder_raw_data_x = torch.tensor(images).to(device)\n"
     ]
    }
   ],
   "source": [
    "import nibabel as nib\n",
    "\n",
    "images = []\n",
    "for file_path in os.listdir(bladder_raw_data_x_path):\n",
    "    if file_path.endswith('.nii.gz'):\n",
    "        image_path = os.path.join(bladder_raw_data_x_path, file_path)\n",
    "        image = nib.load(image_path).get_fdata()\n",
    "        images.append(image)\n",
    "    break\n",
    "\n",
    "# Convert the images to tensors\n",
    "bladder_raw_data_x = torch.tensor(images).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 79, 79, 79, 79]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualise Some Examples"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
