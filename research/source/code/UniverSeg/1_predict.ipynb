{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UniverSeg\n",
    "\n",
    "- From the following paper: https://universeg.csail.mit.edu/\n",
    "- From the git repo: https://github.com/JJGO/UniverSeg\n",
    "- Form the example google colab: https://colab.research.google.com/drive/1TiNAgCehFdyHMJsS90V9ygUw0rLXdW0r?usp=sharing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quoted from the tutorial, helpful text for setting up the context;\n",
    "\n",
    "\"\"\"Given a new segmentation task (e.g. new biomedical domain, new image type, new region of interest, etc), most existing strategies involve training or fine-tuning a segmentation model (often a UNet-like CNN) that takes as input an image $x$ and outputs the segmentation map $y$.\n",
    "\n",
    "This process works well in machine-learning labs, but is challenging in many applied settings, such as for scientists or clinical researchers who drive important scientific questions, but often lack the machine-learning expertiese and computational resources necessary.\n",
    "\n",
    "UniverSeg enables users to tackle a new segmentation task without the need to train or fine-tune a model, removing the ML experience requirements and computational burden. The key idea is to have a *single* global model which adapts to a new segmentation task at inference. Given a new segmentation task, defined by a few example image-segmentation pairs $\\mathcal{T} = \\{x_n, y_n\\}$, UniverSeg segments a new image $x$ by taking as input both $x$ and the task examples $\\mathcal{T}$ and outputs the segmentation map $f(x, \\mathcal{T}) = y$.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import subprocess\n",
    "\n",
    "def setup_data_vars(mine = True, overwrite = True):\n",
    "    \"\"\"\n",
    "    From within any directory related to radiotherapy with backtrack into the data folder\n",
    "    and execute the data_vars script. The assumption is that the datavars script will\n",
    "    output the list of environment variables that need to be set. This function will set\n",
    "    the environment variables for the current session.\n",
    "\n",
    "    For the mean while, my model hasn't completely finished training, therefore, to get\n",
    "    this task done, I will use Ben's pretrained nnUNet and then once mine has finished\n",
    "    training I will use my own. For the mean while, this means that we can choose between\n",
    "    using Ben's pretrained model or my own.\n",
    "    \"\"\"\n",
    "\n",
    "    # If the environment variables are not set, assume that either a custom one has been\n",
    "    # provided or resetting them again is a redundant task\n",
    "    if os.environ.get('nnUNet_raw') is None or overwrite is True:\n",
    "        # run the script in the data folder for specifying the environment variables\n",
    "        if mine:\n",
    "            cwd = os.getcwd().split('/')\n",
    "            data_dir = os.path.join('/'.join(cwd[:cwd.index('radiotherapy') + 1]), 'data')\n",
    "\n",
    "            # Assuming the data_vars.sh script echoes the environment variables\n",
    "            script = os.path.join(data_dir, 'data_vars.sh')\n",
    "            output = subprocess.run([script], capture_output=True)\n",
    "            \n",
    "            assert len(output.stdout) != 0, f\"Please check {script} and make sure it echoes \\\n",
    "    the environment variables.\"\n",
    "\n",
    "            output = output.stdout.decode('utf-8')\n",
    "        else:\n",
    "            data_dir = '/vol/biomedic3/bglocker/nnUNet'\n",
    "\n",
    "            # Assuming this script won't change, it contains hard coded exports\n",
    "            script = os.path.join(data_dir, 'exports')\n",
    "\n",
    "            with open(script, 'r') as file:\n",
    "                output = file.read()\n",
    "        \n",
    "        for line in output.split('\\n'):\n",
    "            if line != '':\n",
    "                if mine:\n",
    "                    line = line.split(': ')\n",
    "                    os.environ[line[0]] = line[1]\n",
    "                else:\n",
    "                    line = line.split('=')\n",
    "                    os.environ[line[0].split(' ')[1]] = line[1]\n",
    "\n",
    "    assert os.environ.get('nnUNet_raw') is not None, \"Environemnt variables not set. \\\n",
    "Please run the data_vars.sh script in the data folder.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import SimpleITK as sitk\n",
    "import numpy as np\n",
    "import torchio as tio\n",
    "\n",
    "def universeg_preprocess(path_to_images: str, normalize: bool, overwrite = True):\n",
    "    \"\"\"Given a input path to images, preprocess the images according to the specification\n",
    "    supplied by the paper. That is, we resize the input images to be 128x128 WxH\n",
    "    dimensions and normalize the CT images to be within the range of 0 to 1. The images\n",
    "    are then saved to a new directory with a sensible name. Files will be named after the\n",
    "    input, therefore, if there are alraedy files in this directory, we will check that\n",
    "    there is a match between a filename and the input image in order to skip.\n",
    "\n",
    "    Args:\n",
    "        path_to_images (str): A path to the directory containing the images that need to\n",
    "        be preprocessed. The output directory will be saved in a sensible location\n",
    "        derrived from `os.environ.get('nnUNet_raw)`\n",
    "        \n",
    "        normalize (bool): A flag to indicate whether the input pixels values should be\n",
    "        normalized to the 0 to 1 range. \n",
    "\n",
    "        overwrite (bool): A flag to indicate whether the output directory should be\n",
    "        overwritten.\n",
    "    \"\"\"\n",
    "\n",
    "    # Check that the input directory exists\n",
    "    assert os.path.exists(path_to_images), f\"Path to images: {path_to_images} does not exist.\"\n",
    "    assert os.environ.get('nnUNet_raw') is not None, \"Environment variables not set. \\\n",
    "Please run the data_vars.sh script in the data folder.\"\n",
    "\n",
    "    def resize_image(original_CT, width_new = 128, height_new = 128):\n",
    "        # Data Augmentation with SimpleITK:\n",
    "        # https://github.com/InsightSoftwareConsortium/SimpleITK-Notebooks/blob/master/Python/70_Data_Augmentation.ipynb\n",
    "        # https://stackoverflow.com/questions/48065117/simpleitk-resize-images\n",
    "\n",
    "        reference_dimension = original_CT.GetDimension()\n",
    "        reference_origin = original_CT.GetOrigin()\n",
    "        reference_direction = original_CT.GetDirection()\n",
    "        reference_size = original_CT.GetSize()\n",
    "        reference_spacing = original_CT.GetSpacing()\n",
    "\n",
    "        # Compute the reference physical size which acts as a placeholder for the expected\n",
    "        # metadata of the image after transformation\n",
    "\n",
    "        reference_physical_size = np.zeros(reference_dimension)\n",
    "        reference_physical_size[:] = [(sz-1)*spc if sz*spc>mx  else mx for sz,spc,mx in zip(reference_size, reference_spacing, reference_physical_size)]\n",
    "        \n",
    "        reference_size = [width_new, height_new, reference_size[2]]\n",
    "        reference_spacing = [ phys_sz/(sz-1) for sz,phys_sz in zip(reference_size, reference_physical_size) ]\n",
    "\n",
    "        # Create a blank image with the desired size after transormation\n",
    "\n",
    "        reference_image = sitk.Image(reference_size, original_CT.GetPixelIDValue())\n",
    "        reference_image.SetOrigin(reference_origin)\n",
    "        reference_image.SetSpacing(reference_spacing)\n",
    "        reference_image.SetDirection(reference_direction)\n",
    "\n",
    "        # Calculate affine transform to match direction matrix of the original image moves\n",
    "        # the center of the original image to the center of the new image. This transform\n",
    "        # is added to the composite transform.\n",
    "\n",
    "        reference_center = np.array(reference_image.TransformContinuousIndexToPhysicalPoint(np.array(reference_image.GetSize())/2.0))\n",
    "        \n",
    "        transform = sitk.AffineTransform(reference_dimension)\n",
    "        transform.SetMatrix(original_CT.GetDirection())\n",
    "\n",
    "        transform.SetTranslation(np.array(original_CT.GetOrigin()) - reference_origin)\n",
    "    \n",
    "        centering_transform = sitk.TranslationTransform(reference_dimension)\n",
    "        img_center = np.array(original_CT.TransformContinuousIndexToPhysicalPoint(np.array(original_CT.GetSize())/2.0))\n",
    "        centering_transform.SetOffset(np.array(transform.GetInverse().TransformPoint(img_center) - reference_center))\n",
    "        centered_transform = sitk.CompositeTransform(transform)\n",
    "        centered_transform.AddTransform(centered_transform)\n",
    "\n",
    "        # sitk.Show(sitk.Resample(original_CT, reference_image, centered_transform, sitk.sitkLinear, 0.0))\n",
    "        \n",
    "        return sitk.Resample(original_CT, reference_image, centered_transform, sitk.sitkLinear, 0.0)\n",
    "\n",
    "    def normalize_image(image):\n",
    "        # https://www.imaios.com/en/resources/blog/ct-images-normalization-zero-centering-and-standardization\n",
    "        # Convert SimpleITK image to TorchIO image\n",
    "        x, y, z = image.GetSize()\n",
    "        torchio_image = tio.ScalarImage(tensor = sitk.GetArrayFromImage(image).reshape(1, x, y , z))\n",
    "\n",
    "        # Apply normalization transform\n",
    "        normalization_transform = tio.transforms.RescaleIntensity(out_min_max = (0, 1), percentiles = (0.5, 99.5))\n",
    "        normalized_image = normalization_transform(torchio_image)\n",
    "\n",
    "        # Convert TorchIO image back to SimpleITK image\n",
    "        normalized_sitk_image = normalized_image.as_sitk()\n",
    "\n",
    "        # Copy the metadata from the original image\n",
    "        normalized_sitk_image.CopyInformation(image)\n",
    "\n",
    "        return normalized_sitk_image\n",
    "\n",
    "    # Get the output directory\n",
    "    class_name = path_to_images.split('/')[-2]\n",
    "    image_type = path_to_images.split('/')[-1]\n",
    "    output_dir = os.path.join(os.environ.get('nnUNet_raw')[:-len('nnUNet_raw')-1], 'UniverSegPreprocessed', class_name, image_type)\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Arrange files to pre-process\n",
    "    input_files = sorted([file for file in os.listdir(path_to_images) if file.endswith('.nii.gz')])\n",
    "    output_files = sorted([file for file in os.listdir(output_dir) if file.endswith('.nii.gz')])\n",
    "\n",
    "    prefix = 'universeg_'\n",
    "\n",
    "    to_process = sorted(set(input_files)- set([file[len(prefix):] for file in output_files])) if not overwrite else input_files\n",
    "\n",
    "    for file in tqdm(to_process):\n",
    "        input_file = os.path.join(path_to_images, file)\n",
    "        output_file = os.path.join(output_dir, prefix + file)\n",
    "\n",
    "        # Load data\n",
    "        data = sitk.ReadImage(input_file)\n",
    "        # Resize data\n",
    "        data = resize_image(data)\n",
    "        # Normalize data\n",
    "        data = data if not normalize else normalize_image(data)\n",
    "\n",
    "        # Save data\n",
    "        sitk.WriteImage(data, output_file)          \n",
    "\n",
    "    return output_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def universeg_run_inference(path_to_image, path_to_labels, path_to_output):\n",
    "    \"\"\"Performs the forward pass of the model on the input image according to the\n",
    "    walkthrough at https://github.com/JJGO/UniverSeg\n",
    "\n",
    "    Args:\n",
    "        path_to_image (str): path to image\n",
    "\n",
    "        path_to_labels (str): path to labels\n",
    "\n",
    "        path_to_output (str): path to save predictions in\n",
    "    \"\"\"\n",
    "\n",
    "    assert os.path.exists(path_to_image), f\"Path to image: {path_to_image} does not exist.\"\n",
    "    assert os.path.exists(path_to_labels), f\"Path to labels: {path_to_labels} does not exist.\"\n",
    "\n",
    "    os.makedirs(path_to_output, exist_ok=True)\n",
    "\n",
    "    # Load the data in\n",
    "\n",
    "    # Separate the different z slices of the image into different tasks for the model to\n",
    "    # predict. We must do the same with the ground truth segmentations and convince\n",
    "    # ourselves that the segmentations vs the iamge are aligned and have been transformed\n",
    "    # correctly.\n",
    "\n",
    "    # Run the inference\n",
    "\n",
    "    # Save the output to the path_to_output\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw directory /vol/bitbucket/az620/radiotherapy/data/nnUNet_raw\n",
      "Data Traning images imagesTr\n",
      "Data Traning labels labelsTr\n",
      "Image_Path: /vol/bitbucket/az620/radiotherapy/data/nnUNet_raw/Dataset001_Anorectum/imagesTr \n",
      "Label_Path: /vol/bitbucket/az620/radiotherapy/data/nnUNet_raw/Dataset001_Anorectum/labelsTr \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/83 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 83/83 [01:28<00:00,  1.06s/it]\n",
      "0it [00:00, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    setup_data_vars()\n",
    "\n",
    "    print(f'Raw directory {os.environ.get(\"nnUNet_raw\")}')\n",
    "    print(f'Data Traning images {os.environ.get(\"data_trainingImages\")}')\n",
    "    print(f'Data Traning labels {os.environ.get(\"data_trainingLabels\")}')\n",
    "\n",
    "    classes = [os.environ.get('data_Anorectum'), \n",
    "        os.environ.get('data_Bladder'), \n",
    "        os.environ.get('data_CTVn'), \n",
    "        os.environ.get('data_CTVp'), \n",
    "        os.environ.get('data_Parametrium'), \n",
    "        os.environ.get('data_Uterus'), \n",
    "        os.environ.get('data_Vagina')]\n",
    "    \n",
    "    # Suppose we try to predict labels for the Anorectum\n",
    "    class_id = 0\n",
    "\n",
    "    image_path = '/'.join([os.environ.get(\"nnUNet_raw\"), classes[class_id], os.environ.get(\"data_trainingImages\")])\n",
    "    label_path = '/'.join([os.environ.get(\"nnUNet_raw\"), classes[class_id], os.environ.get(\"data_trainingLabels\")])\n",
    "    \n",
    "    print(f'Image_Path: {image_path} {\"(Warning: os cannot find this path)\" if not os.path.isdir(image_path) else \"\"}')\n",
    "    print(f'Label_Path: {label_path} {\"(Warning: os cannot find this path)\" if not os.path.isdir(label_path) else \"\"}')\n",
    "\n",
    "    # For all inputs ensure that pixel values are min-max normalized to the range [0, 1]\n",
    "    # and that the spatial dimensions are (H, W) = (128, 128)\n",
    "\n",
    "    universeg_image_path = universeg_preprocess(image_path, normalize=True, overwrite=False)\n",
    "    universeg_label_path = universeg_preprocess(label_path, normalize=False, overwrite=False)\n",
    "\n",
    "    assert os.path.isdir(universeg_image_path), f'File at `{universeg_image_path}` doesn\\'t exist'\n",
    "    assert os.path.isdir(universeg_label_path), f'File at `{universeg_image_path}` doesn\\'t exist'\n",
    "\n",
    "    # Attempt to perform inference on 2D slices of the preprocessed image\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
