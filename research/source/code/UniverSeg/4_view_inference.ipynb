{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "dir1 = os.path.abspath(os.path.join(os.path.abspath(''), '..'))\n",
    "if not dir1 in sys.path: sys.path.append(dir1)\n",
    "from utils.environment import setup_data_vars\n",
    "setup_data_vars()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "\n",
    "# define argparser for anatomy, and axis\n",
    "\n",
    "parser = argparse.ArgumentParser(description='Inference for UniverSeg')\n",
    "\n",
    "parser.add_argument('anatomy', type=str, help='The anatomy to infer on')\n",
    "parser.add_argument('axis', type=str, help='The axis to infer on (0,1,2)')\n",
    "\n",
    "args = parser.parse_args(\n",
    "    ['Vagina', '1']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "anatomy = args.anatomy # 'Anorectum'\n",
    "support_size = 80\n",
    "axis = int(args.axis) # 0\n",
    "batch_size = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Infering on Vagina along axis 1\n",
      "Using support size 80 and batch size 3\n"
     ]
    }
   ],
   "source": [
    "print(f'Infering on {anatomy} along axis {axis}')\n",
    "print(f'Using support size {support_size} and batch size {batch_size}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import random\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "\n",
    "class UniverSegDataSet(Dataset):\n",
    "    def __init__(self, support_size, anatomy, axis):\n",
    "\n",
    "        self.medsam_gts = os.path.join(os.environ.get('MedSAM_preprocessed_lowres'), 'gts', anatomy, f'axis{axis}')\n",
    "        self.medsam_imgs = os.path.join(os.environ.get('MedSAM_preprocessed_lowres'), 'imgs', f'axis{axis}')\n",
    "\n",
    "        self.support_size = support_size\n",
    "        self.anatomy = anatomy\n",
    "        self.axis = axis\n",
    "\n",
    "        self.gts_samples = [f for f in sorted(os.listdir(self.medsam_gts)) if f.endswith('.npy')]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.gts_samples)\n",
    "    \n",
    "    def _read_image_and_gt(self, img_id, img_slice):\n",
    "        img = np.load(os.path.join(self.medsam_imgs, f'CT_zzAMLART_{img_id:03d}-{img_slice:03d}.npy'))\n",
    "        gt = np.load(os.path.join(self.medsam_gts, f'CT_{self.anatomy}_zzAMLART_{img_id:03d}-{img_slice:03d}.npy'))\n",
    "        return img, gt\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        ith_example = self.gts_samples[idx]\n",
    "\n",
    "        # get a support set that doesn't contain the same id as the ith example\n",
    "        get_id_from_img = lambda img_name: int(img_name.split('_')[3].split('-')[0])\n",
    "        get_slice_from_img = lambda img_name: int(img_name.split('_')[3].split('-')[1].split('.')[0])\n",
    "\n",
    "        ith_id = get_id_from_img(ith_example)\n",
    "        ith_slice = get_slice_from_img(ith_example)\n",
    "\n",
    "        support_set = random.sample([f for f in self.gts_samples if get_id_from_img(f) != ith_id], self.support_size)\n",
    "\n",
    "        # read in the images and gts for the ith example and the support set and resize them appropriately\n",
    "        ith_img, ith_gt = self._read_image_and_gt(ith_id, ith_slice)\n",
    "\n",
    "        support_imgs = []\n",
    "        support_gts = []\n",
    "\n",
    "        for support_example in support_set:\n",
    "            support_img, support_gt = self._read_image_and_gt(get_id_from_img(support_example), get_slice_from_img(support_example))\n",
    "\n",
    "            support_imgs.append(support_img)\n",
    "            support_gts.append(support_gt)\n",
    "\n",
    "        # resize the images and gts to 128x128 we need for universeg\n",
    "\n",
    "        ith_img = cv2.resize(ith_img, (128, 128), interpolation=cv2.INTER_LINEAR)\n",
    "        ith_gt = cv2.resize(ith_gt, (128, 128), interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "        support_imgs = [cv2.resize(support_img, (128, 128), interpolation=cv2.INTER_LINEAR) for support_img in support_imgs]\n",
    "        support_gts = [cv2.resize(support_gt, (128, 128), interpolation=cv2.INTER_NEAREST) for support_gt in support_gts]\n",
    "\n",
    "        # convert to torch tensors\n",
    "\n",
    "        ith_img = torch.from_numpy(ith_img).float().unsqueeze(0)\n",
    "        ith_gt = torch.from_numpy(ith_gt).float().unsqueeze(0)\n",
    "\n",
    "        support_imgs = [torch.from_numpy(support_img).float().unsqueeze(0) for support_img in support_imgs]\n",
    "        support_gts = [torch.from_numpy(support_gt).float().unsqueeze(0) for support_gt in support_gts]\n",
    "\n",
    "        # stack the support images and gts\n",
    "        support_imgs = torch.stack(support_imgs) # (S x 128 x 128)\n",
    "        support_gts = torch.stack(support_gts) # (S x 128 x 128)\n",
    "\n",
    "        assert support_imgs.shape == (self.support_size, 1, 128, 128), support_imgs.shape\n",
    "        assert support_gts.shape == (self.support_size, 1, 128, 128), support_gts.shape\n",
    "        assert ith_img.shape == (1, 128, 128), ith_img.shape\n",
    "        assert ith_gt.shape == (1, 128, 128), ith_gt.shape\n",
    "\n",
    "        return {\n",
    "            'query_name': ith_example,\n",
    "            'query': ith_img,\n",
    "            'query_gt': ith_gt,\n",
    "            'support_imgs': support_imgs,\n",
    "            'support_gts': support_gts\n",
    "        }\n",
    "\n",
    "    def get_id_and_slice(self, img_id, img_slice):\n",
    "        name = f'CT_{self.anatomy}_zzAMLART_{img_id:03d}-{img_slice:03d}.npy'\n",
    "\n",
    "        idx = self.gts_samples.index(name)\n",
    "\n",
    "        return self.__getitem__(idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "# my_dataset = UniverSegDataSet(support_size=support_size, anatomy=anatomy, axis=axis)\n",
    "# my_dataloder = DataLoader(my_dataset, batch_size=1, shuffle=True)\n",
    "\n",
    "# # get a batch of data\n",
    "\n",
    "# for i, batch in enumerate(my_dataloder):\n",
    "#     print(batch['query'].shape)\n",
    "#     print(batch['query_gt'].shape)\n",
    "#     print(batch['support_imgs'].shape)\n",
    "#     print(batch['support_gts'].shape)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from universeg import universeg\n",
    "from platipy.imaging.label.comparison import compute_metric_total_apl, compute_surface_dsc, compute_metric_hd\n",
    "import SimpleITK as sitk\n",
    "\n",
    "dataset = UniverSegDataSet(support_size=support_size, anatomy=anatomy, axis=axis)\n",
    "dataloader = DataLoader(dataset, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "overlap_measures_filter = sitk.LabelOverlapMeasuresImageFilter()\n",
    "\n",
    "# Run the inference\n",
    "model = universeg(pretrained=True)\n",
    "model = model.to(device)\n",
    "\n",
    "# load in parameters from the trained model\n",
    "# checkpoint = torch.load('results_finetuned/finetuning/model_checkpoint_best.pth')\n",
    "\n",
    "# model.load_state_dict(checkpoint['model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/7 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting up dataloader and getting batch:   0%|          | 0/7 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CT_Anorectum_zzAMLART_079-059.png', 'CT_Anorectum_zzAMLART_042-070.png', 'CT_Anorectum_zzAMLART_029-047.png']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting up dataloader and getting batch:  43%|████▎     | 3/7 [00:29<00:36,  9.22s/it]               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CT_Anorectum_zzAMLART_046-261.png', 'CT_Anorectum_zzAMLART_035-326.png', 'CT_Anorectum_zzAMLART_026-286.png']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting up dataloader and getting batch:  86%|████████▌ | 6/7 [00:58<00:09,  9.64s/it]               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CT_Anorectum_zzAMLART_051-263.png', 'CT_Anorectum_zzAMLART_021-249.png', 'CT_Anorectum_zzAMLART_013-215.png', 'CT_Anorectum_zzAMLART_028-242.png', 'CT_Anorectum_zzAMLART_026-235.png']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting up dataloader and getting batch: : 12it [01:40,  8.61s/it]                                   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CT_Bladder_zzAMLART_090-074.png', 'CT_Bladder_zzAMLART_090-111.png', 'CT_Bladder_zzAMLART_057-079.png']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting up dataloader and getting batch: : 15it [02:02,  6.56s/it]             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CT_Bladder_zzAMLART_036-253.png', 'CT_Bladder_zzAMLART_078-221.png', 'CT_Bladder_zzAMLART_082-263.png']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting up dataloader and getting batch: : 18it [02:25,  7.18s/it]             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CT_Bladder_zzAMLART_013-235.png', 'CT_Bladder_zzAMLART_019-283.png', 'CT_Bladder_zzAMLART_079-264.png', 'CT_Bladder_zzAMLART_012-254.png']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Plotting and saving results for Bladder along axis 2: : 21it [02:57,  7.83s/it]/tmp/ipykernel_2432386/2599152368.py:79: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.\n",
      "  fig, axs = plt.subplots(nrows=nrows, ncols=ncols, figsize=(ncols*5, nrows*5))\n",
      "Setting up dataloader and getting batch: : 22it [02:58,  7.91s/it]             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CT_CTVn_zzAMLART_039-166.png', 'CT_CTVn_zzAMLART_076-115.png', 'CT_CTVn_zzAMLART_088-142.png']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting up dataloader and getting batch: : 25it [03:26,  8.82s/it]          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CT_CTVn_zzAMLART_060-221.png', 'CT_CTVn_zzAMLART_016-291.png', 'CT_CTVn_zzAMLART_056-265.png']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting up dataloader and getting batch: : 28it [03:51,  8.62s/it]          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CT_CTVn_zzAMLART_070-313.png', 'CT_CTVn_zzAMLART_083-199.png', 'CT_CTVn_zzAMLART_008-291.png']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting up dataloader and getting batch: : 31it [04:18,  8.99s/it]          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CT_CTVp_zzAMLART_082-102.png', 'CT_CTVp_zzAMLART_069-100.png', 'CT_CTVp_zzAMLART_060-068.png']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting up dataloader and getting batch: : 34it [04:40,  7.71s/it]          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CT_CTVp_zzAMLART_004-297.png', 'CT_CTVp_zzAMLART_083-259.png', 'CT_CTVp_zzAMLART_093-248.png']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting up dataloader and getting batch: : 37it [05:02,  7.59s/it]          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CT_CTVp_zzAMLART_055-276.png', 'CT_CTVp_zzAMLART_094-278.png', 'CT_CTVp_zzAMLART_073-272.png']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting up dataloader and getting batch: : 40it [05:27,  7.99s/it]          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CT_Parametrium_zzAMLART_077-050.png', 'CT_Parametrium_zzAMLART_099-072.png', 'CT_Parametrium_zzAMLART_020-045.png']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting up dataloader and getting batch: : 43it [05:47,  7.12s/it]                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CT_Parametrium_zzAMLART_037-269.png', 'CT_Parametrium_zzAMLART_054-272.png', 'CT_Parametrium_zzAMLART_015-305.png']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting up dataloader and getting batch: : 46it [06:12,  7.79s/it]                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CT_Parametrium_zzAMLART_043-277.png', 'CT_Parametrium_zzAMLART_083-216.png', 'CT_Parametrium_zzAMLART_020-300.png']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting up dataloader and getting batch: : 49it [06:38,  8.39s/it]                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CT_Uterus_zzAMLART_094-099.png', 'CT_Uterus_zzAMLART_062-085.png', 'CT_Uterus_zzAMLART_058-069.png']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting up dataloader and getting batch: : 52it [07:01,  7.81s/it]            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CT_Uterus_zzAMLART_033-279.png', 'CT_Uterus_zzAMLART_019-255.png', 'CT_Uterus_zzAMLART_064-258.png']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting up dataloader and getting batch: : 55it [07:26,  8.02s/it]            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CT_Uterus_zzAMLART_046-232.png', 'CT_Uterus_zzAMLART_013-276.png', 'CT_Uterus_zzAMLART_083-225.png']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting up dataloader and getting batch: : 58it [07:48,  7.70s/it]            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CT_Vagina_zzAMLART_092-073.png', 'CT_Vagina_zzAMLART_015-058.png', 'CT_Vagina_zzAMLART_039-083.png']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting up dataloader and getting batch: : 61it [08:05,  6.14s/it]            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CT_Vagina_zzAMLART_052-273.png', 'CT_Vagina_zzAMLART_028-269.png', 'CT_Vagina_zzAMLART_089-280.png']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting up dataloader and getting batch: : 64it [08:23,  6.25s/it]            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CT_Vagina_zzAMLART_043-275.png', 'CT_Vagina_zzAMLART_078-260.png', 'CT_Vagina_zzAMLART_068-271.png']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Finished Vagina along axis 2: 100%|██████████| 7/7 [08:42<00:00, 74.66s/it]   \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "classes = ['Anorectum', 'Bladder', 'CTVn', 'CTVp', 'Parametrium', 'Uterus', 'Vagina']\n",
    "axes = [0, 1, 2]\n",
    "\n",
    "# quantity = len(classes) * len(axes)\n",
    "\n",
    "progress_bar = tqdm(classes, total=len(classes))\n",
    "\n",
    "if True:\n",
    "    for anatomy in progress_bar:\n",
    "        for axis in axes:\n",
    "            dataset = UniverSegDataSet(support_size=support_size, anatomy=anatomy, axis=axis)\n",
    "            # dataloader = DataLoader(dataset, batch_size=1, shuffle=True)\n",
    "            # dataloader_iter = iter(dataloader)\n",
    "\n",
    "            # batch = next(dataloader_iter)\n",
    "\n",
    "            # read in pngs that have already been processed. These are the fine-tuned predictions\n",
    "            file_path = f'results_finetuned/{anatomy}/axis{axis}'\n",
    "            inferred_images = [f for f in os.listdir(file_path) if f.endswith('.png')]\n",
    "\n",
    "            print(inferred_images)\n",
    "            for ii in inferred_images:\n",
    "                progress_bar.set_description(f'Setting up dataloader and getting batch')\n",
    "\n",
    "                image_id = int(ii.split('_')[3].split('-')[0])\n",
    "                slice_num = int(ii.split('_')[3].split('-')[1].split('.')[0])\n",
    "\n",
    "                batch = dataset.get_id_and_slice(image_id, slice_num)\n",
    "\n",
    "                names = batch['query_name'] # [0]\n",
    "                image = batch['query'].to(device).unsqueeze(0)\n",
    "                label = batch['query_gt'].unsqueeze(0)\n",
    "                support_images = batch['support_imgs'].to(device).unsqueeze(0)\n",
    "                support_labels = batch['support_gts'].to(device).unsqueeze(0)\n",
    "                \n",
    "                progress_bar.set_description(f'Running inference on {names}')\n",
    "\n",
    "                image = image.to(device)\n",
    "                # label = label.to(device)\n",
    "                support_images = support_images.to(device)\n",
    "                support_labels = support_labels.to(device)\n",
    "\n",
    "                prediction_logits = model(image, support_images, support_labels)\n",
    "                prediction_soft = torch.sigmoid(prediction_logits)\n",
    "\n",
    "                # threshold probabilities to get hard predictions\n",
    "                prediction_hard = (prediction_soft > 0.5).float()\n",
    "\n",
    "                progress_bar.set_description(f'Computing metrics for {anatomy} along axis {axis}')\n",
    "\n",
    "                # for each batch of predictions, compute the metrics\n",
    "                for j in range(prediction_hard.shape[0]):\n",
    "                    # compute the metrics\n",
    "                    prediction = prediction_hard[j].cpu().detach().numpy()\n",
    "                    prediction = sitk.GetImageFromArray(prediction)\n",
    "                    label_sitk = sitk.GetImageFromArray(label[j])\n",
    "\n",
    "                    prediction = sitk.Cast(prediction, sitk.sitkUInt8)\n",
    "                    label_sitk = sitk.Cast(label_sitk, sitk.sitkUInt8)\n",
    "\n",
    "                    overlap_measures_filter.Execute(label_sitk, prediction)\n",
    "\n",
    "                    dice = overlap_measures_filter.GetDiceCoefficient()\n",
    "                    hd = compute_metric_hd(label_sitk, prediction)\n",
    "                    volume_similarity = overlap_measures_filter.GetVolumeSimilarity()\n",
    "                    surface_dsc = compute_surface_dsc(label_sitk, prediction)\n",
    "                    apl = compute_metric_total_apl(label_sitk, prediction)\n",
    "\n",
    "                progress_bar.set_description(f'Plotting and saving results for {anatomy} along axis {axis}')\n",
    "\n",
    "                import matplotlib.pyplot as plt\n",
    "                import numpy as np\n",
    "\n",
    "                ncols = 3\n",
    "                nrows = 1\n",
    "\n",
    "                fig, axs = plt.subplots(nrows=nrows, ncols=ncols, figsize=(ncols*5, nrows*5))\n",
    "                axs = axs.reshape(nrows, ncols)\n",
    "\n",
    "                # show the image\n",
    "                axs[0][0].imshow(image[0, 0].cpu().detach().numpy(), cmap='grey')\n",
    "                axs[0][0].set_title('Query Image')\n",
    "                axs[0][0].axis('off')\n",
    "\n",
    "                # show the ground truth overlayed on the query image\n",
    "                axs[0][1].imshow(image[0, 0].cpu().detach().numpy(), cmap='gray')\n",
    "                axs[0][1].imshow(label[0, 0].cpu().detach().numpy(), alpha=label[0, 0].cpu().detach().numpy(), cmap='viridis')\n",
    "                axs[0][1].set_title('Ground Truth')\n",
    "                axs[0][1].axis('off')\n",
    "\n",
    "                # show the prediction overlayed on the query image\n",
    "                axs[0][2].imshow(image[0, 0].cpu().detach().numpy(), cmap='gray')\n",
    "                axs[0][2].imshow(prediction_hard[0, 0].cpu().detach().numpy(), alpha=prediction_hard[0, 0].cpu().detach().numpy(), cmap='viridis')\n",
    "                axs[0][2].set_title('Prediction')\n",
    "                axs[0][2].axis('off')\n",
    "\n",
    "                plt.tight_layout()\n",
    "                plt.suptitle(f'Prediction of {anatomy} along axis {axis} ({names}) with scores Dice: {dice:.2f}, HD: {hd:.2f}, Volume Similarity: {volume_similarity:.2f}, Surface DSC: {surface_dsc:.2f}, APL: {apl:.2f}', y=1.05)\n",
    "\n",
    "                plt.savefig(f'results/{anatomy}/axis{axis}/{names.split(\".\")[0]}.png', bbox_inches='tight')\n",
    "                plt.clf()\n",
    "\n",
    "                progress_bar.set_description(f'Finished {anatomy} along axis {axis}')\n",
    "                # increment the progress_bar\n",
    "                progress_bar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anatomy = 'CTVn'\n",
    "axis = '1'\n",
    "\n",
    "dataset = UniverSegDataSet(support_size=support_size, anatomy=anatomy, axis=axis)\n",
    "dataloader = DataLoader(dataset, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader_iter = iter(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(dataloader_iter)\n",
    "\n",
    "names = batch['query_name']\n",
    "image = batch['query'].to(device)\n",
    "label = batch['query_gt']\n",
    "support_images = batch['support_imgs'].to(device)\n",
    "support_labels = batch['support_gts'].to(device)\n",
    "\n",
    "image = image.to(device)\n",
    "# label = label.to(device)\n",
    "support_images = support_images.to(device)\n",
    "support_labels = support_labels.to(device)\n",
    "\n",
    "prediction_logits = model(image, support_images, support_labels)\n",
    "prediction_soft = torch.sigmoid(prediction_logits)\n",
    "\n",
    "# threshold probabilities to get hard predictions\n",
    "prediction_hard = (prediction_soft > 0.5).float()\n",
    "\n",
    "# for each batch of predictions, compute the metrics\n",
    "for j in range(prediction_hard.shape[0]):\n",
    "    # compute the metrics\n",
    "    prediction = prediction_hard[j].cpu().detach().numpy()\n",
    "    prediction = sitk.GetImageFromArray(prediction)\n",
    "    label_sitk = sitk.GetImageFromArray(label[j])\n",
    "\n",
    "    prediction = sitk.Cast(prediction, sitk.sitkUInt8)\n",
    "    label_sitk = sitk.Cast(label_sitk, sitk.sitkUInt8)\n",
    "\n",
    "    overlap_measures_filter.Execute(label_sitk, prediction)\n",
    "\n",
    "    dice = overlap_measures_filter.GetDiceCoefficient()\n",
    "    hd = compute_metric_hd(label_sitk, prediction)\n",
    "    volume_similarity = overlap_measures_filter.GetVolumeSimilarity()\n",
    "    surface_dsc = compute_surface_dsc(label_sitk, prediction)\n",
    "    apl = compute_metric_total_apl(label_sitk, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "ncols = 3\n",
    "nrows = 1\n",
    "\n",
    "fig, axs = plt.subplots(nrows=nrows, ncols=ncols, figsize=(ncols*5, nrows*5))\n",
    "axs = axs.reshape(nrows, ncols)\n",
    "\n",
    "# show the image\n",
    "axs[0][0].imshow(image[0, 0].cpu().detach().numpy(), cmap='grey')\n",
    "axs[0][0].set_title('Query Image')\n",
    "axs[0][0].axis('off')\n",
    "\n",
    "# show the ground truth overlayed on the query image\n",
    "axs[0][1].imshow(image[0, 0].cpu().detach().numpy(), cmap='gray')\n",
    "axs[0][1].imshow(label[0, 0].cpu().detach().numpy(), alpha=label[0, 0].cpu().detach().numpy(), cmap='jet')\n",
    "axs[0][1].set_title('Ground Truth')\n",
    "axs[0][1].axis('off')\n",
    "\n",
    "# show the prediction overlayed on the query image\n",
    "axs[0][2].imshow(image[0, 0].cpu().detach().numpy(), cmap='gray')\n",
    "axs[0][2].imshow(prediction_hard[0, 0].cpu().detach().numpy(), alpha=prediction_hard[0, 0].cpu().detach().numpy(), cmap='viridis')\n",
    "axs[0][2].set_title('Prediction')\n",
    "axs[0][2].axis('off')\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.suptitle(f'Prediction of {anatomy} along axis {axis} ({names[0]}) with scores Dice: {dice:.2f}, HD: {hd:.2f}, Volume Similarity: {volume_similarity:.2f}, Surface DSC: {surface_dsc:.2f}, APL: {apl:.2f}', y=1.05)\n",
    "\n",
    "plt.savefig(f'results_finetuned/{anatomy}/axis{axis}/{names[0].split(\".\")[0]}.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the support set\n",
    "\n",
    "ncols = support_size\n",
    "nrows = 2\n",
    "\n",
    "fig, axs = plt.subplots(nrows=nrows, ncols=ncols, figsize=(ncols*5, nrows*5))\n",
    "axs = axs.reshape(nrows, ncols)\n",
    "\n",
    "for i in range(support_size):\n",
    "    axs[0][i].imshow(support_images[0, i, 0].cpu().detach().numpy(), cmap='gray')\n",
    "    axs[0][i].axis('off')\n",
    "\n",
    "    axs[1][i].imshow(support_images[0, i, 0].cpu().detach().numpy(), cmap='gray')\n",
    "    axs[1][i].imshow(support_labels[0, i, 0].cpu().detach().numpy(), alpha=support_labels[0, i, 0].cpu().detach().numpy(), cmap='viridis')\n",
    "    axs[1][i].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.suptitle('Support Set')\n",
    "plt.show()\n",
    "\n",
    "plt.savefig(f'results_finetuned/{anatomy}/axis{axis}/{names[0].split(\".\")[0]}-support.png', bbox_inches='tight')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
