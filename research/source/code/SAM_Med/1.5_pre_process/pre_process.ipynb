{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing\n",
    "\n",
    "As it has been discussed in the paper and at `../2_no_finetuning/1_inference_example.ipynb` the images that the network is used to taking are images of 1024x1024x3. Therefore, we pre-process the images we have in batch to fine tune at a later stage. Therefore, for simplicity, translate each image into a 1024x1024x1024 image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "dir1 = os.path.abspath(os.path.join(os.path.abspath(''), '..', '..'))\n",
    "if not dir1 in sys.path: sys.path.append(dir1)\n",
    "\n",
    "from utils.environment import setup_data_vars\n",
    "\n",
    "setup_data_vars()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:   0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# import nibabel as nib\n",
    "import SimpleITK as sitk\n",
    "import os\n",
    "\n",
    "join = os.path.join\n",
    "from skimage import transform\n",
    "from tqdm import tqdm\n",
    "import cc3d\n",
    "\n",
    "def pre_process(\n",
    "      input_path_nii: str\n",
    "    , input_path_gt: str\n",
    "    , anatomy: str\n",
    "    , modality = 'CT'\n",
    "    , image_prefix = 'zzAMLART_'\n",
    "    , nii_postfix = '_0000.nii.gz'\n",
    "    , gt_postfix = '.nii.gz'\n",
    "    , output_postfix = '.nii.gz'\n",
    "    , WINDOW_WIDTH = 400\n",
    "    , WINDOW_LEVEL = 40\n",
    "    , image_size = 1024\n",
    "    , voxel_num_thre2d = 50\n",
    "    , voxel_num_thre3d = 1000\n",
    "    ):\n",
    "    # << SETUP DESTINATION >>\n",
    "    \n",
    "    # Convince yourself that the anatomy parsed in is the same as the one mentioned in the input paths. Hacky workaround exists, but assume we're cooperating for now.\n",
    "    assert all([anatomy in x for x in [input_path_nii, input_path_gt]])\n",
    "\n",
    "    prefix = modality + \"_\" + anatomy + \"_\"\n",
    "\n",
    "    nyp_path_imgs = os.path.join(os.environ.get('PROJECT_DIR'), 'data', 'MedSAM_preprocessed', 'imgs') # e.g. MedSAM_preprocessed/imgs/\n",
    "    nyp_path_gts = os.path.join(os.environ.get('PROJECT_DIR'), 'data', 'MedSAM_preprocessed', 'gts', prefix[:-1]) # e.g. MedSAM_preprocessed/gts/CT_Bladder/\n",
    "\n",
    "    os.makedirs(nyp_path_imgs, exist_ok=True) # Nii images\n",
    "    os.makedirs(nyp_path_gts, exist_ok=True) # Ground truth images\n",
    "\n",
    "    # << ITERATE OVER ALL IMAGES AND CONVERT >>\n",
    "\n",
    "    # Get the list of images to process\n",
    "    img_names = sorted([f for f in os.listdir(input_path_nii) if f.endswith(nii_postfix)])\n",
    "    gt_names = sorted([f for f in os.listdir(input_path_gt) if f.endswith(gt_postfix)])\n",
    "\n",
    "    # Get the processed images for images and ground truth\n",
    "    img_processed_names = sorted([f for f in os.listdir(nyp_path_imgs) if f.endswith(output_postfix)])\n",
    "    gt_processed_names = sorted([f for f in os.listdir(nyp_path_gts) if f.endswith(output_postfix)])\n",
    "\n",
    "    # Get list of remaining images assuming each image id is unique.\n",
    "    img_ids = [int(img.split(image_prefix)[1].split(nii_postfix)[0]) for img in img_names]\n",
    "    gt_ids = [int(gt.split(image_prefix)[1].split(gt_postfix)[0]) for gt in gt_names]\n",
    "    processed_img_ids = [int(img.split(prefix)[1].split('.npy')[0]) for img in img_processed_names]\n",
    "    processed_gt_ids = [int(gt.split(prefix)[1].split('.npy')[0]) for gt in gt_processed_names]\n",
    "\n",
    "    remaining_img_names = set(img_ids) - set(processed_img_ids)\n",
    "    remaining_gt_names = set(gt_ids) - set(processed_gt_ids)\n",
    "\n",
    "    # << PROCESS IMAGES >>\n",
    "    # Make the sensible assumption that the dimensions of the images and the ground truth segmentations are the same. Therefore, we can process these separately and not be impacted\n",
    "\n",
    "    for img_id in tqdm(remaining_img_names, desc='Processing images'):\n",
    "        img_path = os.path.join(input_path_nii, image_prefix + str(img_id).zfill(3) + nii_postfix)\n",
    "        image_data = sitk.GetArrayFromImage(sitk.ReadImage(img_path))\n",
    "\n",
    "        if modality == \"CT\":\n",
    "            lower_bound = WINDOW_LEVEL - WINDOW_WIDTH / 2\n",
    "            upper_bound = WINDOW_LEVEL + WINDOW_WIDTH / 2\n",
    "            image_data_pre = np.clip(image_data, lower_bound, upper_bound)\n",
    "            image_data_pre = (\n",
    "                (image_data_pre - np.min(image_data_pre))\n",
    "                / (np.max(image_data_pre) - np.min(image_data_pre))\n",
    "                * 255.0    \n",
    "            )\n",
    "        else:\n",
    "            raise NotImplementedError(\"Modality not supported\")\n",
    "\n",
    "        image_data_pre = np.uint8(image_data_pre)\n",
    "\n",
    "        resize_img_skimg = transform.resize(\n",
    "            image_data_pre,\n",
    "            (image_size, image_size, image_size),\n",
    "            order=3,\n",
    "            preserve_range=True,\n",
    "            mode=\"constant\",\n",
    "            anti_aliasing=True,\n",
    "        )\n",
    "\n",
    "        print(resize_img_skimg.GetShape())\n",
    "\n",
    "\n",
    "    # for gt_id in tqdm(remaining_gt_names, desc='Processing ground truths'):\n",
    "    #     gt_path = os.path.join(input_path_gt, image_prefix + str(gt_id).zfill(3) + gt_postfix)\n",
    "    #     gt_data_ori = sitk.GetArrayFromImage(sitk.ReadImage(gt_path))\n",
    "\n",
    "    #     # exclude objects with less than 1000 pixels in 3D\n",
    "    #     gt_data_ori = cc3d.dust(gt_data_ori, threshold=voxel_num_thre3d, connectivity=26, in_place=True)\n",
    "    #     # remove small objects with less than voxel_num_thre2d pixels in 2D slices. For\n",
    "    #     # such small objects, the main challenge is detection rather than segmentation\n",
    "    #     for slice_i in range(gt_data_ori.shape[0]):\n",
    "    #         gt_i = gt_data_ori[slice_i, :, :]\n",
    "    #         gt_data_ori = cc3d.dust(gt_i, threshold=voxel_num_thre2d, connectivity=6, in_place=True)\n",
    "\n",
    "    #     # find non-zero slices\n",
    "    #     z_index, _, _ = np.where(gt_data_ori > 0)\n",
    "    #     z_index = np.unique(z_index)\n",
    "    \n",
    "    return -1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "anatomy = 'Bladder'\n",
    "\n",
    "pre_process(\n",
    "    input_path_nii = os.path.join(os.environ.get('nnUNet_raw'), os.environ.get(anatomy), os.environ.get('data_trainingImages')),\n",
    "    input_path_gt = os.path.join(os.environ.get('nnUNet_raw'), os.environ.get(anatomy), os.environ.get('data_trainingLabels')),\n",
    "    anatomy = anatomy\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
