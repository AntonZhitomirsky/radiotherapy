{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example Running:\n",
    "```\n",
    "python pre_CT_MR.py CT Anorectum /vol/biomedic3/bglocker/ugproj2324/az620/radiotherapy/data/nnUNet_raw/Dataset001_Anorectum/imagesTr /vol/biomedic3/bglocker/ugproj2324/az620/radiotherapy/data/nnUNet_raw/Dataset001_Anorectum/labelsTr /vol/biomedic3/bglocker/ugproj2324/az620/radiotherapy/data/MedSAM_preprocessed --axis 0 --verbose\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install connected-components-3d\n",
    "import numpy as np\n",
    "\n",
    "# import nibabel as nib\n",
    "import SimpleITK as sitk\n",
    "import os\n",
    "\n",
    "join = os.path.join\n",
    "from skimage import transform\n",
    "from tqdm import tqdm\n",
    "import cc3d\n",
    "\n",
    "import argparse\n",
    "\n",
    "import SimpleITK as sitk\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description=\"Preprocess CT/MR images\")\n",
    "parser.add_argument('modality', type=str, help='modality of the images, CT or MR')\n",
    "parser.add_argument('anatomy', type=str, help='anatomy of the images')\n",
    "parser.add_argument('nii_path', type=str, help='path to the nii images')\n",
    "parser.add_argument('gt_path', type=str, help='path to the ground truth')\n",
    "parser.add_argument('npy_path', type=str, help='path to save the npy files')\n",
    "parser.add_argument('--img_name_suffix', type=str, default='_0000.nii.gz', help='suffix of the image name')\n",
    "parser.add_argument('--gt_name_suffix', type=str, default='.nii.gz', help='suffix of the ground truth name')\n",
    "parser.add_argument('--image_size', type=int, default=1024, help='size of the images')\n",
    "parser.add_argument('--voxel_num_thre2d', type=int, default=100, help='threshold of the number of voxels in 2D')\n",
    "parser.add_argument('--voxel_num_thre3d', type=int, default=1000, help='threshold of the number of voxels in 3D')\n",
    "parser.add_argument('--WINDOW_LEVEL', type=int, default=40, help='window level for CT images')\n",
    "parser.add_argument('--WINDOW_WIDTH', type=int, default=400, help='window width for CT images')\n",
    "parser.add_argument('--axis', type=int, default=0, help='along which axis to preprocess image')\n",
    "parser.add_argument('--verbose', action='store_true', help='print more information', default=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# args = parser.parse_args([\n",
    "#     'nnUNet',\n",
    "#     'TotalBinary',\n",
    "#     '/vol/biomedic3/bglocker/ugproj2324/az620/radiotherapy/data/nnUNet_preprocessed/Dataset008_TotalBinary/nnUNetPlans_3d_fullres/',\n",
    "#     '/vol/biomedic3/bglocker/ugproj2324/az620/radiotherapy/data/nnUNet_preprocessed/Dataset008_TotalBinary/nnUNetPlans_3d_fullres/',\n",
    "#     '/vol/biomedic3/bglocker/ugproj2324/az620/radiotherapy/data/MedSAM_nnpp_lowres',\n",
    "#     '--axis', '0', \n",
    "#     '--image_size', '512',\n",
    "#     '--verbose',\n",
    "#     '--img_name_suffix', '.npy',\n",
    "#     '--gt_name_suffix', '_seg.npy',\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = parser.parse_args()\n",
    "\n",
    "if args.verbose:\n",
    "    for arg in vars(args):\n",
    "        print(f\"{arg}: {getattr(args, arg)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Preprocessing', args.modality, args.anatomy, args.axis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modality = args.modality\n",
    "assert modality in [\"CT\", \"nnUNet\"]\n",
    "anatomy = args.anatomy\n",
    "\n",
    "img_name_suffix = args.img_name_suffix\n",
    "gt_name_suffix = args.gt_name_suffix\n",
    "prefix = modality + \"_\" + anatomy + \"_\"\n",
    "\n",
    "nii_path = args.nii_path  # path to the nii images\n",
    "gt_path = args.gt_path  # path to the ground truth\n",
    "npy_path = args.npy_path\n",
    "\n",
    "gt_save_dir = join(npy_path, \"gts\", anatomy, f'axis{str(args.axis)}')\n",
    "img_save_dir = join(npy_path, \"imgs\", f'axis{str(args.axis)}')\n",
    "\n",
    "os.makedirs(gt_save_dir, exist_ok=True)\n",
    "os.makedirs(img_save_dir, exist_ok=True)\n",
    "\n",
    "image_size = args.image_size\n",
    "voxel_num_thre2d = args.voxel_num_thre2d\n",
    "voxel_num_thre3d = args.voxel_num_thre3d\n",
    "\n",
    "names = sorted([name for name in os.listdir(nii_path) if name.endswith(gt_name_suffix)])\n",
    "print(names[:10])\n",
    "\n",
    "# set window level and width\n",
    "# https://radiopaedia.org/articles/windowing-ct\n",
    "WINDOW_LEVEL = args.WINDOW_LEVEL  # only for CT images\n",
    "WINDOW_WIDTH = args.WINDOW_WIDTH  # only for CT images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slice_at(i):\n",
    "    slices = [slice(None)] * 3\n",
    "    slices[args.axis] = i\n",
    "    return tuple(slices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_array(path):\n",
    "    if path.endswith('.nii.gz'):\n",
    "        img = sitk.ReadImage(path)\n",
    "        img = sitk.GetArrayFromImage(img).squeeze()\n",
    "    elif path.endswith('.npy'):\n",
    "        img = np.load(path).squeeze()\n",
    "\n",
    "    assert img.ndim == 3\n",
    "    \n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save preprocessed images and masks as npz files\n",
    "for name in tqdm(names):\n",
    "\n",
    "    if args.verbose:\n",
    "        print(f'processing name {name}')\n",
    "\n",
    "    image_name = name.split(gt_name_suffix)[0] + img_name_suffix\n",
    "    gt_name = name\n",
    "    gt_data_ori = load_array(join(gt_path, gt_name))\n",
    "\n",
    "    if args.verbose:\n",
    "        print('dusting images')\n",
    "\n",
    "    # exclude the objects with less than 1000 pixels in 3D\n",
    "    gt_data_ori = cc3d.dust(\n",
    "        gt_data_ori, threshold=voxel_num_thre3d, connectivity=26, in_place=True\n",
    "    )\n",
    "\n",
    "    if args.verbose:\n",
    "        print('gt_data_ori.shape', gt_data_ori.shape)\n",
    "\n",
    "    # remove small objects with less than 100 pixels in 2D slices\n",
    "    for slice_i in range(gt_data_ori.shape[args.axis]):\n",
    "        slices = slice_at(slice_i)\n",
    "        gt_i = gt_data_ori[slices]\n",
    "        # remove small objects with less than 100 pixels\n",
    "        # reason: for such small objects, the main challenge is detection rather than segmentation\n",
    "        gt_data_ori[slices] = cc3d.dust(\n",
    "            gt_i, threshold=voxel_num_thre2d, connectivity=8, in_place=True\n",
    "        )\n",
    "        \n",
    "    if args.verbose:\n",
    "        print('finding non-zero slices')\n",
    "\n",
    "    # find non-zero slices\n",
    "    # For some reason vectorizing this operation doesn't work.\n",
    "    slice_index = []\n",
    "    for i in range(gt_data_ori.shape[args.axis]):\n",
    "        my_slice = gt_data_ori[slice_at(i)]\n",
    "        if np.any(my_slice):\n",
    "            slice_index.append(i)\n",
    "\n",
    "    if args.verbose:\n",
    "        print(f'for name {name} the non zero slices for axis {args.axis} are {slice_index}')\n",
    "\n",
    "    if len(slice_index) > 0:\n",
    "        # crop the ground truth with non-zero slices\n",
    "        gt_roi = gt_data_ori[slice_at(slice_index)]\n",
    "        # load image and preprocess\n",
    "        image_data = load_array(join(nii_path, image_name))\n",
    "        # nii preprocess start\n",
    "        if modality == \"CT\":\n",
    "            if args.verbose:\n",
    "                print('normalizing Hosfield units')\n",
    "            lower_bound = WINDOW_LEVEL - WINDOW_WIDTH / 2\n",
    "            upper_bound = WINDOW_LEVEL + WINDOW_WIDTH / 2\n",
    "            image_data_pre = np.clip(image_data, lower_bound, upper_bound)\n",
    "            image_data_pre = (\n",
    "                (image_data_pre - np.min(image_data_pre))\n",
    "                / (np.max(image_data_pre) - np.min(image_data_pre))\n",
    "                * 255.0\n",
    "            )\n",
    "        elif modality == \"nnUNet\":\n",
    "            # data is already preprocessed, all that needs to be done is to noramlize from 0 to 1\n",
    "            if args.verbose:\n",
    "                print('modality set to nnUNet, skipping clipping')\n",
    "            image_data_pre = image_data\n",
    "        else:\n",
    "            raise NotImplementedError(f\"modality {modality} is not implemented yet\")\n",
    "\n",
    "        if args.verbose:\n",
    "            print('Saving slices...')\n",
    "\n",
    "        # image_data_pre = np.uint8(image_data_pre)\n",
    "        img_roi = image_data_pre[slice_at(slice_index)]\n",
    "\n",
    "        # np.savez_compressed(join(npy_path, prefix + gt_name.split(gt_name_suffix)[0]+'.npz'), imgs=img_roi, gts=gt_roi, spacing=img_sitk.GetSpacing())\n",
    "        # # save the image and ground truth as nii files for sanity check;\n",
    "        # # they can be removed\n",
    "        # img_roi_sitk = sitk.GetImageFromArray(img_roi)\n",
    "        # gt_roi_sitk = sitk.GetImageFromArray(gt_roi)\n",
    "        # sitk.WriteImage(\n",
    "        #     img_roi_sitk,\n",
    "        #     join(npy_path, prefix + gt_name.split(gt_name_suffix)[0] + \"_img.nii.gz\"),\n",
    "        # )\n",
    "        # sitk.WriteImage(\n",
    "        #     gt_roi_sitk,\n",
    "        #     join(npy_path, prefix + gt_name.split(gt_name_suffix)[0] + \"_gt.nii.gz\"),\n",
    "        # )\n",
    "        # save the each CT image as npy file\n",
    "        for i, original_slice in zip(range(img_roi.shape[args.axis]), slice_index):\n",
    "            img_save_path = join(\n",
    "                    img_save_dir,\n",
    "                    modality + \"_\"\n",
    "                    + gt_name.split(gt_name_suffix)[0]\n",
    "                    + \"-\"\n",
    "                    + str(original_slice).zfill(3)\n",
    "                    + \".npy\",\n",
    "                )\n",
    "\n",
    "            gt_save_path =  join(\n",
    "                    gt_save_dir,\n",
    "                    prefix\n",
    "                    + gt_name.split(gt_name_suffix)[0]\n",
    "                    + \"-\"\n",
    "                    + str(original_slice).zfill(3)\n",
    "                    + \".npy\",\n",
    "                )\n",
    "            \n",
    "            if not os.path.isfile(img_save_path):\n",
    "                img_i = img_roi[slice_at(i)]\n",
    "                # img_3c = np.repeat(img_i[:, :, None], 3, axis=-1)\n",
    "                img_3c = img_i # don't repeat the channels when saving. This should be done in the dataloader as otherwise there is a lot of redundancy\n",
    "                resize_img_skimg = transform.resize(\n",
    "                    img_3c,\n",
    "                    (image_size, image_size),\n",
    "                    order=3,\n",
    "                    preserve_range=True,\n",
    "                    mode=\"constant\",\n",
    "                    anti_aliasing=True,\n",
    "                )\n",
    "\n",
    "                resize_img_skimg = (resize_img_skimg - resize_img_skimg.min()) / np.clip(\n",
    "                    resize_img_skimg.max() - resize_img_skimg.min(), a_min=1e-8, a_max=None\n",
    "                )  # normalize to [0, 1], (H, W, 3)\n",
    "                # elif args.verbose:\n",
    "                #     print('modality set to nnUNet, skipping normalization')\n",
    "\n",
    "\n",
    "                np.save(img_save_path, resize_img_skimg)\n",
    "            elif args.verbose:\n",
    "                print('file already found at ', img_save_path)\n",
    "\n",
    "            if not os.path.isfile(gt_save_path):\n",
    "                gt_i = gt_roi[slice_at(i)]\n",
    "                resize_gt_skimg = transform.resize(\n",
    "                    gt_i,\n",
    "                    (image_size, image_size),\n",
    "                    order=0,\n",
    "                    preserve_range=True,\n",
    "                    mode=\"constant\",\n",
    "                    anti_aliasing=False,\n",
    "                )\n",
    "                resize_gt_skimg = np.uint8(resize_gt_skimg)\n",
    "                # assert resize_img_skimg_01.shape[:2] == resize_gt_skimg.shape\n",
    "\n",
    "                np.save(gt_save_path, resize_gt_skimg)\n",
    "            elif args.verbose:\n",
    "                print('file already found at ', gt_save_path)\n",
    "    \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
