{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Imports\n",
    "import re\n",
    "import os\n",
    "import cv2\n",
    "import sys\n",
    "import json\n",
    "import torch\n",
    "import monai\n",
    "import random\n",
    "import argparse\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "import torch.optim as optim\n",
    "from time import time, sleep\n",
    "from datetime import datetime\n",
    "from skimage import transform\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Add the setup_data_vars function as we will need it to find the directory for the training data.\n",
    "dir1 = os.path.abspath(os.path.join(os.path.abspath(''), '..', '..'))\n",
    "if not dir1 in sys.path: sys.path.append(dir1)\n",
    "\n",
    "from utils.environment import setup_data_vars\n",
    "setup_data_vars()\n",
    "\n",
    "dir2 = os.path.abspath(os.path.join(os.path.abspath(''), '..', '0_utils'))\n",
    "if not dir2 in sys.path: sys.path.append(dir2)\n",
    "\n",
    "from dataload_handler import DataLoaderHandler\n",
    "from checkpoint_handler import CheckpointHandler\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=['--anatomy'], dest='anatomy', nargs=None, const=None, default=None, type=<class 'str'>, choices=None, required=True, help='Anatomy on which to fine-tune the model. Note: this is case sensitive, please capitalize the first letter and accronyms such as CTVn or CTVp.', metavar=None)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import argparse\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "# Inspired by orginal code from the MedSAM/extensions/point_prompt\n",
    "\n",
    "# 1. Add the anatomy on which we will fine-tune\n",
    "parser.add_argument(\n",
    "    '--anatomy',\n",
    "    type=str,\n",
    "    help='Anatomy on which to fine-tune the model. Note: this is case sensitive, please capitalize the first letter and accronyms such as CTVn or CTVp.',\n",
    "    required=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = parser.parse_args(\n",
    "    ['--anatomy', 'CTVn']\n",
    ")\n",
    "\n",
    "anatomy = args.anatomy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup classes for loading up the stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lowres = True\n",
    "save_dir = os.path.join(os.environ.get('MedSAM_finetuned'), 'boxed_lowres', anatomy)\n",
    "checkpoint_path = os.path.join(os.environ['PROJECT_DIR'], 'models', 'MedSAM', 'work_dir', 'MedSAM', 'medsam_vit_b.pth')\n",
    "model_path = os.path.join(save_dir, 'checkpoint_best.pth')\n",
    "data_split = os.path.join(save_dir, 'data_splits.json')\n",
    "img_dir = os.path.join(os.environ.get('MedSAM_preprocessed_lowres'), 'imgs')\n",
    "gt_dir = os.path.join(os.environ.get('MedSAM_preprocessed_lowres'), 'gts', anatomy)\n",
    "batch_size = 1\n",
    "num_workers = 16\n",
    "\n",
    "use_boxes = True\n",
    "use_positive_points = False\n",
    "\n",
    "assert os.path.exists(model_path), f\"Model path {model_path} does not exist.\"\n",
    "assert os.path.exists(data_split), f\"Data split {data_split} does not exist.\"\n",
    "assert os.path.exists(img_dir), f\"Raw data {img_dir} does not exist.\"\n",
    "assert os.path.exists(gt_dir), f\"Ground truth data {gt_dir} does not exist.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size (6.6 GiB) fits in cache limit (20 GiB). Allocating space to cache all 6718 samples.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2, 10, 11, 16, 38, 42, 43, 46, 49, 51, 56, 57, 66, 71, 73, 74, 77, 79, 92, 93}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dlh = DataLoaderHandler(save_dir = save_dir,\n",
    "                        image_dir = img_dir,\n",
    "                        gt_dir = gt_dir,\n",
    "                        batch_size = batch_size,\n",
    "                        num_workers = num_workers,\n",
    "                        data_aug = False,\n",
    "                        max_points = 0,\n",
    "                        box_padding = 5,\n",
    "                        max_box_points = 5)\n",
    "dlh.load_split_from_json()\n",
    "dlh.setup_specific_dataloader('validation')\n",
    "dlh.validation_image_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded the model for anatomy CTVn from epoch 53\n"
     ]
    }
   ],
   "source": [
    "cph = CheckpointHandler(save_dir, checkpoint_path, device)\n",
    "if cph.checkpoint_exists():\n",
    "    model, optimizer, epoch, best_loss = cph.load_checkpoint()\n",
    "    print(f'Loaded the model for anatomy {anatomy} from epoch {epoch}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main validaiton loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# create a pandas dataframe to store the name, axis, dice, jaccard, volume_similarity, apl, surface_distance, and hausdorff_distance\n",
    "\n",
    "df = pd.DataFrame(columns=['name', 'axis', 'dice', 'jaccard', 'volume_similarity', 'apl', 'surface_distance', 'hausdorff_distance'])\n",
    "\n",
    "# load in the processed data if it already exists\n",
    "if os.path.exists(os.path.join(save_dir, 'validation.csv')):\n",
    "    df = pd.read_csv(os.path.join(save_dir, 'validation.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 3839/6718 [17:12<09:07,  5.25it/s] "
     ]
    }
   ],
   "source": [
    "import SimpleITK as sitk\n",
    "from platipy.imaging.label.comparison import compute_metric_total_apl, compute_surface_dsc, compute_metric_hd\n",
    "overlap_measures_filter = sitk.LabelOverlapMeasuresImageFilter()\n",
    "\n",
    "length_of_val_loader = len(dlh.val_loader)\n",
    "\n",
    "# iterate through the validation loader\n",
    "for i, batch in tqdm(enumerate(dlh.val_loader), total=length_of_val_loader):\n",
    "\n",
    "    # check if we have already processed this name and axis\n",
    "    if batch[\"image_name\"][0] in df.name.values and batch[\"axis\"].item() in df.axis.values:\n",
    "        continue\n",
    "\n",
    "    # Get data\n",
    "    image = batch[\"image\"].to(device)\n",
    "    gt2D = batch[\"gt2D\"].to(device)\n",
    "    # coords_torch = batch[\"coords\"].squeeze().to(device) # ([B, Ps, 2])\n",
    "    boxes_torch = batch[\"boxes\"].squeeze().reshape(batch_size, -1, 4).to(device) # ([B, Ps, 4])\n",
    "    axis = batch[\"axis\"].squeeze() # ([B])\n",
    "\n",
    "    medsam_preds = []\n",
    "    medsam_segs = []\n",
    "\n",
    "    for b in torch.unique(boxes_torch.squeeze().reshape(-1, batch_size, 4), dim=0):\n",
    "        b = b.reshape(batch_size, 1, 4)\n",
    "        # print(b)\n",
    "        medsam_lite_pred = model(image, None, b)\n",
    "        medsam_seg_prob = torch.sigmoid(medsam_lite_pred)\n",
    "        # convert soft mask to hard mask\n",
    "        medsam_seg_prob = medsam_seg_prob.detach().cpu().numpy().squeeze()\n",
    "        medsam_seg = (medsam_seg_prob > 0.5).astype(np.uint8)\n",
    "\n",
    "        medsam_preds.append(medsam_lite_pred.detach().cpu())\n",
    "        medsam_segs.append(medsam_seg)\n",
    "\n",
    "    medsam_preds = torch.tensor(np.stack(medsam_preds))\n",
    "    medsam_segs = torch.tensor(np.stack(medsam_segs))\n",
    "\n",
    "    # do an OR operation on the medsam_segs\n",
    "    medsam_seg = medsam_segs.sum(dim=0)\n",
    "\n",
    "    # Get evaluation metrics\n",
    "    y_gt_sitk = sitk.GetImageFromArray(gt2D[0].detach().cpu().numpy().astype(np.uint8))\n",
    "    ypred_sitk = sitk.GetImageFromArray(medsam_seg[None, :, :].numpy().astype(np.uint8))\n",
    "\n",
    "    overlap_measures_filter.Execute(y_gt_sitk, ypred_sitk)\n",
    "                \n",
    "    dice = overlap_measures_filter.GetDiceCoefficient()\n",
    "    jaccard = overlap_measures_filter.GetJaccardCoefficient()\n",
    "    volume_similarity = overlap_measures_filter.GetVolumeSimilarity()\n",
    "\n",
    "    apl = compute_metric_total_apl(y_gt_sitk, ypred_sitk)\n",
    "    surface_dsc = compute_surface_dsc(y_gt_sitk, ypred_sitk)\n",
    "    hd = compute_metric_hd(y_gt_sitk, ypred_sitk)\n",
    "\n",
    "    # add metrics to dataframe\n",
    "\n",
    "    new_record = pd.DataFrame([\n",
    "        {'name': batch[\"image_name\"][0], 'axis': batch[\"axis\"].item(), 'dice': dice, 'jaccard': jaccard, 'volume_similarity': volume_similarity, 'apl': apl, 'surface_distance': surface_dsc, 'hausdorff_distance': hd}\n",
    "    ])\n",
    "\n",
    "    df = pd.concat([df, new_record], ignore_index=True)\n",
    "\n",
    "    if i % 10 == 0:\n",
    "        # save the dataframe to a csv file\n",
    "        df.to_csv(os.path.join(save_dir, 'validation.csv'), index=False)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
