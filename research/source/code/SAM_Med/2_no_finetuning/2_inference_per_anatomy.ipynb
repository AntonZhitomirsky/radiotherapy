{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from MEDSAM_helper_functions import * # show_mask, show_box, medsam_inference\n",
    "\n",
    "import sys, os\n",
    "dir1 = os.path.abspath(os.path.join(os.path.abspath(''), '..', '..'))\n",
    "if not dir1 in sys.path: sys.path.append(dir1)\n",
    "\n",
    "from utils.environment import setup_data_vars\n",
    "\n",
    "setup_data_vars()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import sys\n",
    "\n",
    "parser = argparse.ArgumentParser(description=\"Preprocess CT/MR images\")\n",
    "parser.add_argument('anatomy', type=str, help='anatomy of the images')\n",
    "parser.add_argument('axis', type=int, help='axis 0,1,2')\n",
    "\n",
    "original_args = sys.argv\n",
    "sys.argv = [original_args[0], 'Anorectum', 0]\n",
    "\n",
    "args = parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/vol/biomedic3/bglocker/ugproj2324/az620/radiotherapy/data/MedSAM_preprocessed/imgs/axis0',\n",
       " '/vol/biomedic3/bglocker/ugproj2324/az620/radiotherapy/data/MedSAM_preprocessed/gts/Anorectum/axis0')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_processed_imgs = os.path.join(os.environ.get('MedSAM_preprocessed'), 'imgs', f'axis{args.axis}')\n",
    "pre_processed_gts = os.path.join(os.environ.get('MedSAM_preprocessed'), 'gts', args.anatomy, f'axis{args.axis}')\n",
    "pre_processed_imgs, pre_processed_gts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5196/5196 [00:00<00:00, 555010.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5196 distinct image slices for this axis (0) and anatomy (Anorectum)\n",
      "Average slices per sample: 52.05\n",
      "The most slices per sample: 74\n",
      "The least slices per sample: 31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# Get the image ids and arrange them into slices\n",
    "gt_slices = os.listdir(pre_processed_gts)\n",
    "get_id = lambda x: int(x.split('_')[3].split('-')[0])\n",
    "get_slice = lambda x: int(x.split('_')[3].split('-')[1].split('.')[0])\n",
    "\n",
    "slices_per_sample = {}\n",
    "for image_slice in tqdm(os.listdir(pre_processed_gts)):\n",
    "    gt_id = get_id(image_slice)\n",
    "    gt_slice = get_slice(image_slice)\n",
    "\n",
    "    if gt_id not in slices_per_sample:\n",
    "        slices_per_sample[gt_id] = [gt_slice, gt_slice] # (min, max)\n",
    "    else:\n",
    "        min_slice, max_slice = slices_per_sample[gt_id]\n",
    "        slices_per_sample[gt_id] = (min([min_slice, gt_slice]), max([max_slice, gt_slice]))\n",
    "\n",
    "print(f'Found {len(gt_slices)} distinct image slices for this axis ({args.axis}) and anatomy ({args.anatomy})')\n",
    "slice_intervals = [mx - mn + 1 for mn, mx in slices_per_sample.values()]\n",
    "print(f'Average slices per sample: {np.mean(slice_intervals)}')\n",
    "print(f'The most slices per sample: {np.max(slice_intervals)}')\n",
    "print(f'The least slices per sample: {np.min(slice_intervals)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "def get_bounding_boxes(resized_gt):\n",
    "    # Find contours in the segmentation map\n",
    "    contours, _ = cv2.findContours(resized_gt, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Initialize list to store bounding boxes\n",
    "    bounding_boxes = []\n",
    "\n",
    "    # Loop through contours to find bounding boxes\n",
    "    for contour in contours:\n",
    "        # Get bounding box coordinates\n",
    "        x, y, w, h = cv2.boundingRect(contour)\n",
    "        bounding_boxes.append([x, y, x + w, y + h])  # Format: (x_min, y_min, x_max, y_max)\n",
    "\n",
    "    return np.array(bounding_boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def visualise_bounding_box_with_prediction(array_image, array_gt_label, bounding_boxes=None, predicted_mask=None, show_boxes_of_predictions=False, save_title = None):\n",
    "    ncols = sum([2, int(bounding_boxes is not None), int(predicted_mask is not None)])\n",
    "\n",
    "    _, axes = plt.subplots(1, ncols, figsize=(5 * ncols, 5))\n",
    "    axes[0].imshow(array_image, cmap='gray')\n",
    "    axes[0].set_title('Raw Image')\n",
    "\n",
    "    alpha_mask_gt = np.where(array_gt_label > 0, 1, 0).astype(np.float32)\n",
    "    axes[1].imshow(array_image, cmap='gray')\n",
    "    axes[1].imshow(array_gt_label, alpha=alpha_mask_gt, cmap='viridis')\n",
    "    axes[1].set_title('Ground Truth')\n",
    "\n",
    "    currcol = 2\n",
    "\n",
    "    if bounding_boxes is not None:\n",
    "        assert len(bounding_boxes) >= 1\n",
    "        axes[2].imshow(array_image, cmap='gray')\n",
    "        for box in bounding_boxes:\n",
    "            box = list(box)\n",
    "            x0, y0 = box[0], box[1]\n",
    "            w, h = box[2] - box[0], box[3] - box[1]\n",
    "            axes[2].add_patch(\n",
    "                plt.Rectangle((x0, y0), w, h, edgecolor=\"blue\", facecolor=(0, 0, 0, 0), lw=2)\n",
    "            )\n",
    "        axes[2].set_title('Bounding Box From Segmentation')\n",
    "        currcol += 1\n",
    "\n",
    "    if predicted_mask is not None:\n",
    "\n",
    "        alpha_mask_pred = np.where(predicted_mask > 0, 1, 0).astype(np.float32)\n",
    "        axes[currcol].imshow(array_image, cmap='gray')\n",
    "        axes[currcol].imshow(predicted_mask, alpha=alpha_mask_pred, cmap='viridis')\n",
    "        axes[currcol].set_title('Predicted Mask')\n",
    "\n",
    "        if show_boxes_of_predictions:\n",
    "            bounding_boxes_of_predictions = get_bounding_boxes(predicted_mask)\n",
    "\n",
    "            for box in bounding_boxes_of_predictions:\n",
    "                box = list(box)\n",
    "                x0, y0 = box[0], box[1]\n",
    "                w, h = box[2] - box[0], box[3] - box[1]\n",
    "                axes[currcol].add_patch(\n",
    "                    plt.Rectangle((x0, y0), w, h, edgecolor=\"red\", facecolor=(0, 0, 0, 0), lw=2)\n",
    "                )\n",
    "                \n",
    "    plt.tight_layout()\n",
    "\n",
    "    if not save_title is None:\n",
    "        save_path = '/'.join(save_title.split('/')[:-1])\n",
    "        os.makedirs(save_path, exist_ok=True)\n",
    "        \n",
    "        plt.savefig(save_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import SimpleITK as sitk\n",
    "\n",
    "def dice_similarity(gt, pred):\n",
    "    overlap_measures_filter = sitk.LabelOverlapMeasuresImageFilter()\n",
    "\n",
    "    ypred_sitk = sitk.GetImageFromArray(pred)\n",
    "    y_gt_sitk = sitk.GetImageFromArray(gt)\n",
    "\n",
    "    overlap_measures_filter.Execute(y_gt_sitk, ypred_sitk)\n",
    "    return overlap_measures_filter.GetDiceCoefficient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'model set to evaluation mode'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MedSAM_CKPT_PATH = os.path.join(os.environ.get('PROJECT_DIR'),  \"models/MedSAM/work_dir/MedSAM/medsam_vit_b.pth\")\n",
    "device = \"cuda:0\"\n",
    "medsam_model = sam_model_registry['vit_b'](checkpoint=MedSAM_CKPT_PATH)\n",
    "medsam_model = medsam_model.to(device)\n",
    "medsam_model.eval()\n",
    "\"model set to evaluation mode\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import bisect \n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class SAM_Dataset(Dataset):\n",
    "\n",
    "    def __init__(self, axis = args.axis, anatomy = args.anatomy):\n",
    "        self.gt_slice_dir = os.path.join(os.environ.get('MedSAM_preprocessed'), 'gts', anatomy.capitalize(), f'axis{axis}')\n",
    "        self.img_slice_dir = os.path.join(os.environ.get('MedSAM_preprocessed'), 'imgs', f'axis{axis}')\n",
    "        \n",
    "        self.slices_per_sample = {}\n",
    "        for image_slice in os.listdir(self.gt_slice_dir):\n",
    "            gt_id, gt_slice = self.get_id_and_slice_from_gt_path(image_slice)\n",
    "\n",
    "            if gt_id not in self.slices_per_sample.keys():\n",
    "                self.slices_per_sample[gt_id] = [gt_slice] # (min, max)\n",
    "            else:\n",
    "                bisect.insort(self.slices_per_sample[gt_id], gt_slice)\n",
    "\n",
    "    def __len__(self):\n",
    "        return sum([len(vs) for vs in self.slices_per_sample.values()])\n",
    "\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        assert 0 <= idx < self.__len__(), f\"Index {idx} is out of range for dataset of size {self.__len__()}\"\n",
    "\n",
    "        for img_ids, img_slices in self.slices_per_sample.items():\n",
    "            if idx - len(img_slices) > 0:\n",
    "                idx = idx - len(img_slices)\n",
    "                continue\n",
    "            else:\n",
    "                curr_slice = img_slices[idx]\n",
    "                break\n",
    "\n",
    "        gt_slice_path = os.path.join(self.gt_slice_dir, self.gt_slice_format(img_ids, curr_slice))\n",
    "        img_slice_path = os.path.join(self.img_slice_dir, self.img_slice_format(img_ids, curr_slice))\n",
    "\n",
    "        # load in the image\n",
    "        gt_array = np.load(gt_slice_path)\n",
    "        img_array = np.load(img_slice_path)\n",
    "\n",
    "        bounding_boxes = get_bounding_boxes(gt_array)\n",
    "\n",
    "        img_array = torch.tensor(img_array).float().permute(2, 0, 1)\n",
    "\n",
    "        # return img_array, gt_array, and bounding box pair\n",
    "        return img_array, gt_array, bounding_boxes\n",
    "\n",
    "    def gt_slice_format(self, img_num: int, slice_num: int) -> str:\n",
    "        return 'CT_' + args.anatomy.capitalize() + '_zzAMLART_' + str(img_num).zfill(3) + '-' + str(slice_num).zfill(3) + '.npy'\n",
    "\n",
    "    def img_slice_format(self, img_num, slice_num):\n",
    "        return 'CT_zzAMLART_' + str(img_num).zfill(3) + '-' + str(slice_num).zfill(3) + '.npy'\n",
    "    \n",
    "    def get_id_and_slice_from_gt_path(self, path: str):\n",
    "        get_id = lambda x: int(x.split('_')[3].split('-')[0])\n",
    "        get_slice = lambda x: int(x.split('_')[3].split('-')[1].split('.')[0])\n",
    "\n",
    "        return get_id(path), get_slice(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = SAM_Dataset()\n",
    "loader = DataLoader(dataset, batch_size=5, shuffle=False)\n",
    "\n",
    "for img, gt, bounding_boxes in loader:\n",
    "    img = img.to(device)\n",
    "    B, C, H, W = img.shape\n",
    "\n",
    "    with torch.no_grad():\n",
    "            image_embedding = medsam_model.image_encoder(img)\n",
    "        \n",
    "    medsam_preds = medsam_inference(medsam_model, image_embedding, bounding_boxes , H, W)\n",
    "#     combined_preds = np.logical_or.reduce(np.array(medsam_preds)).astype(np.uint8)\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m percentile \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241m.\u001b[39marray(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, max_slice \u001b[38;5;241m-\u001b[39m min_slice \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)) \u001b[38;5;241m/\u001b[39m (max_slice \u001b[38;5;241m-\u001b[39m min_slice \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(percentile, per_image_dice, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDice Score\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39mhlines(np\u001b[38;5;241m.\u001b[39mmean(per_image_dice), \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, linestyles \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdotted\u001b[39m\u001b[38;5;124m\"\u001b[39m, label \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "percentile = np.array(range(0, max_slice - min_slice + 1)) / (max_slice - min_slice + 1)\n",
    "plt.plot(percentile, per_image_dice, label=\"Dice Score\")\n",
    "plt.hlines(np.mean(per_image_dice), 0, 1, linestyles = \"dotted\", label = \"mean\")\n",
    "plt.xlabel('Percentile Across Slices')\n",
    "plt.ylabel('Dice Score')\n",
    "plt.title('How Dice Score changes as we move through the slices')\n",
    "plt.legend()\n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
