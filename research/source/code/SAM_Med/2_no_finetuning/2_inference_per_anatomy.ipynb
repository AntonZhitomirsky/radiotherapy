{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Raw MED_SAM inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from MEDSAM_helper_functions import *\n",
    "\n",
    "import sys, os\n",
    "dir1 = os.path.abspath(os.path.join(os.path.abspath(''), '..', '..'))\n",
    "if not dir1 in sys.path: sys.path.append(dir1)\n",
    "\n",
    "from utils.environment import setup_data_vars\n",
    "\n",
    "setup_data_vars()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import sys\n",
    "\n",
    "parser = argparse.ArgumentParser(description=\"Preprocess CT/MR images\")\n",
    "parser.add_argument('anatomy', type=str, help='anatomy of the images')\n",
    "parser.add_argument('axis', type=int, help='axis 0,1,2')\n",
    "\n",
    "original_args = sys.argv\n",
    "sys.argv = [original_args[0], 'Anorectum', 0]\n",
    "\n",
    "args = parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_processed_imgs = os.path.join(os.environ.get('MedSAM_preprocessed'), 'imgs', f'axis{args.axis}')\n",
    "pre_processed_gts = os.path.join(os.environ.get('MedSAM_preprocessed'), 'gts', args.anatomy, f'axis{args.axis}')\n",
    "pre_processed_imgs, pre_processed_gts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# Get the image ids and arrange them into slices\n",
    "gt_slices = os.listdir(pre_processed_gts)\n",
    "get_id = lambda x: int(x.split('_')[3].split('-')[0])\n",
    "get_slice = lambda x: int(x.split('_')[3].split('-')[1].split('.')[0])\n",
    "\n",
    "slices_per_sample = {}\n",
    "for image_slice in tqdm(os.listdir(pre_processed_gts)):\n",
    "    gt_id = get_id(image_slice)\n",
    "    gt_slice = get_slice(image_slice)\n",
    "\n",
    "    if gt_id not in slices_per_sample:\n",
    "        slices_per_sample[gt_id] = [gt_slice, gt_slice] # (min, max)\n",
    "    else:\n",
    "        min_slice, max_slice = slices_per_sample[gt_id]\n",
    "        slices_per_sample[gt_id] = (min([min_slice, gt_slice]), max([max_slice, gt_slice]))\n",
    "\n",
    "print(f'Found {len(gt_slices)} distinct image slices for this axis ({args.axis}) and anatomy ({args.anatomy})')\n",
    "slice_intervals = [mx - mn + 1 for mn, mx in slices_per_sample.values()]\n",
    "print(f'Average slices per sample: {np.mean(slice_intervals)}')\n",
    "print(f'The most slices per sample: {np.max(slice_intervals)}')\n",
    "print(f'The least slices per sample: {np.min(slice_intervals)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MedSAM_CKPT_PATH = os.path.join(os.environ.get('PROJECT_DIR'),  \"models/MedSAM/work_dir/MedSAM/medsam_vit_b.pth\")\n",
    "device = \"cuda:0\"\n",
    "medsam_model = sam_model_registry['vit_b'](checkpoint=MedSAM_CKPT_PATH)\n",
    "medsam_model = medsam_model.to(device)\n",
    "medsam_model.eval()\n",
    "\"model set to evaluation mode\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Infer each bounding box separately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2\n",
    "box_limit = 2\n",
    "\n",
    "dataset = SAM_Dataset(axis=args.axis, anatomy=args.anatomy, box_limit=box_limit, box_padding=0)\n",
    "loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "for img, gt, boxes, imgids, currslice in loader:\n",
    "    img = img.to(device)\n",
    "    B, C, H, W = img.shape\n",
    "\n",
    "    with torch.no_grad():\n",
    "            image_embedding = medsam_model.image_encoder(img)\n",
    "\n",
    "    per_batch_boxes = boxes.transpose(1, 0)\n",
    "    \n",
    "    # medsam_preds = []\n",
    "    # for b in per_batch_boxes:\n",
    "    #     batch_prediction = medsam_inference(medsam_model, image_embedding, b.reshape(-1, 1, 4) , H, W)\n",
    "    #     for i in range(batch_size):\n",
    "    #         visualise_bounding_box_with_prediction(img[i].permute(1, 2, 0).cpu().numpy()\n",
    "    #                                             , gt[i]\n",
    "    #                                             , b[None, i]\n",
    "    #                                             , batch_prediction[i]\n",
    "    #                                             , show_boxes_of_predictions=True\n",
    "    #                                             , sup_title=f\"Image ID: {imgids[i]}, Slice: {currslice[i]}\")\n",
    "    #     medsam_preds.append(batch_prediction)\n",
    "\n",
    "    medsam_preds = np.array([medsam_inference(medsam_model, image_embedding, H, W, b.reshape(-1, 1, 4)) for b in per_batch_boxes])\n",
    "#     combined_preds = np.logical_or.reduce(np.array(medsam_preds)).astype(np.uint8)\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "view_medsam_preds = medsam_preds.swapaxes(0, 1)\n",
    "\n",
    "# Iterate over the images and extract the bounding box predictions\n",
    "for (i, j) in ((a, b) for a in range(batch_size) for b in range(box_limit)):\n",
    "    dice_score = dice_similarity(gt[i], view_medsam_preds[i][j])\n",
    "    print(f\"{(i,j)}, Image ID: {imgids[i]}, Slice: {currslice[i]}, Dice Score: {dice_score}\")\n",
    "\n",
    "    visualise_bounding_box_with_prediction(array_image = img[i].permute(1, 2, 0).cpu().numpy(),\n",
    "                                           array_gt_label = gt[i],\n",
    "                                           bounding_boxes = boxes[i][None, j],\n",
    "                                           predicted_mask = view_medsam_preds[i][j],\n",
    "                                           show_boxes_of_predictions=True,\n",
    "                                           sup_title=f\"Image ID: {imgids[i]}, Slice: {currslice[i]}, Dice Score: {dice_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine each prediction into one for total inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.argv = [original_args[0], 'Bladder', 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2\n",
    "box_limit = 2\n",
    "\n",
    "dataset = SAM_Dataset(axis=args.axis, anatomy=args.anatomy, box_limit=box_limit, box_padding=0)\n",
    "loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "for img, gt, boxes, imgids, currslice in loader:\n",
    "    img = img.to(device)\n",
    "    B, C, H, W = img.shape\n",
    "\n",
    "    with torch.no_grad():\n",
    "            image_embedding = medsam_model.image_encoder(img)\n",
    "\n",
    "    per_batch_boxes = boxes.transpose(1, 0)\n",
    "\n",
    "    medsam_preds = np.array([medsam_inference(medsam_model, image_embedding , H, W, b.reshape(-1, 1, 4)) for b in per_batch_boxes])\n",
    "    combined_preds = np.logical_or.reduce(np.array(medsam_preds)).astype(np.uint8)\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over the images and extract the bounding box predictions\n",
    "for i in range(batch_size):\n",
    "    print(f\"{(i)}, Image ID: {imgids[i]}, Slice: {currslice[i]}\")\n",
    "\n",
    "    dice_score = dice_similarity(gt[i], combined_preds[i])\n",
    "    title = f\"Image ID: {imgids[i]}, Slice: {currslice[i]}, Dice Score: {dice_score}\"\n",
    "\n",
    "    visualise_bounding_box_with_prediction(array_image = img[i].permute(1, 2, 0).cpu().numpy(),\n",
    "                                        array_gt_label = gt[i],\n",
    "                                        bounding_boxes = boxes[i],\n",
    "                                        predicted_mask = combined_preds[i],\n",
    "                                        show_boxes_of_predictions=True,\n",
    "                                        sup_title=title,\n",
    "                                        save_title=f'./results/{args.anatomy}/axis{args.axis}/{imgids[i]}_{currslice[i]}_{dice_score}.png')\n",
    "\n",
    "    # visualise_bounding_box_with_prediction(img[i].permute(1, 2, 0).cpu().numpy(),\n",
    "    #                                        gt[i],\n",
    "    #                                        boxes[i],\n",
    "    #                                        combined_preds[i],\n",
    "    #                                        show_boxes_of_predictions=True,\n",
    "    #                                        sup_title=title,\n",
    "    #                                        save_title=f'./results/{args.anatomy}/axis{args.axis}/{imgids[i]}_{currslice[i]}_{dice_score}.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get predictions for each anatomy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging \n",
    "from tqdm import tqdm\n",
    "logging.basicConfig(filename='results/dice_scores_axis_2.1.log', filemode='w', format='%(name)s - %(levelname)s - %(message)s', level=logging.INFO)\n",
    "\n",
    "save_dir = os.path.join(os.environ.get('MedSAM_results'))\n",
    "\n",
    "for axis in [2] : # [0,1,2]:\n",
    "    for anatomy in tqdm(['Bladder', 'Anorectum', 'CTVn', 'CTVp', 'Parametrium', 'Vagina', 'Uterus'], desc=f'Running predictions for axis 2 across all anatomies'):\n",
    "\n",
    "        save_path = os.path.join(save_dir, anatomy, f'axis{axis}')\n",
    "        os.makedirs(save_path, exist_ok=True)\n",
    "        batch_size = 8\n",
    "        box_limit = 2\n",
    "\n",
    "        dataset = SAM_Dataset(axis=axis, anatomy=anatomy, box_limit=box_limit, box_padding=0)\n",
    "        loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "        for img, gt, boxes, imgids, currslice in tqdm(loader):\n",
    "            img = img.to(device)\n",
    "            B, C, H, W = img.shape\n",
    "\n",
    "            with torch.no_grad():\n",
    "                    image_embedding = medsam_model.image_encoder(img)\n",
    "\n",
    "            per_batch_boxes = boxes.transpose(1, 0)\n",
    "\n",
    "            medsam_preds = np.array([medsam_inference(medsam_model, image_embedding, H, W, b.reshape(-1, 1, 4)) for b in per_batch_boxes])\n",
    "            combined_preds = np.logical_or.reduce(np.array(medsam_preds)).astype(np.uint8)\n",
    "            \n",
    "            for i in range(B):\n",
    "                # Save prediction\n",
    "                np.save(os.path.join(save_path, f'{imgids[i]}-{currslice[i]}.npy'), combined_preds[i])\n",
    "\n",
    "                #  calcualte the DICE score\n",
    "                dice_score = dice_similarity(gt[i], combined_preds[i])\n",
    "                logging.info(f'{anatomy} - {axis} - {imgids[i]} - {currslice[i]} - {dice_score}')\n",
    "\n",
    "        # # Iterate over the images and extract the bounding box predictions\n",
    "        # for i in range(batch_size):\n",
    "        #     print(f\"{(i)}, Image ID: {imgids[i]}, Slice: {currslice[i]}\")\n",
    "\n",
    "        #     dice_score = dice_similarity(gt[i], combined_preds[i])\n",
    "\n",
    "        #     visualise_bounding_box_with_prediction(img[i].permute(1, 2, 0).cpu().numpy(),\n",
    "        #                                         gt[i],\n",
    "        #                                         boxes[i],\n",
    "        #                                         combined_preds[i],\n",
    "        #                                         show_boxes_of_predictions=True,\n",
    "        #                                         sup_title=f\"Image ID: {imgids[i]}, Slice: {currslice[i]}, Dice Score: {dice_score}\",\n",
    "        #                                         save_title=f'./results/{anatomy}/axis{axis}/{imgids[i]}_{currslice[i]}_{dice_score}.png')\n",
    "\n",
    "        # Done 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Make sure that the saved predictions are being saved ok\n",
    "# # From my check, these seem ok.\n",
    "\n",
    "# # I'll pick id = 1, slice = 92\n",
    "# img_id = [1,2,3,3,4,4,5,6,6,6]\n",
    "# slice_num = [92,72,82,92,76,79,55,67,68,93]\n",
    "# anatomy = 'Bladder'\n",
    "# axis = 0\n",
    "\n",
    "# for ii, sn in zip(img_id, slice_num):\n",
    "#     gt_slice_path = os.path.join(os.environ.get('MedSAM_preprocessed'), 'gts', anatomy, f'axis{axis}', f'CT_{anatomy}_zzAMLART_{str(ii).zfill(3)}-{str(sn).zfill(3)}.npy')\n",
    "#     img_slice_path = os.path.join(pre_processed_imgs, f'CT_zzAMLART_{str(ii).zfill(3)}-{str(sn).zfill(3)}.npy')\n",
    "#     pred_path = os.path.join(save_dir, anatomy, f'axis{axis}', f'{ii}-{sn}.npy')\n",
    "\n",
    "#     gt_array = np.load(gt_slice_path)\n",
    "#     img_array = np.load(img_slice_path)\n",
    "#     pred_array = np.load(pred_path)\n",
    "\n",
    "#     visualise_bounding_box_with_prediction(img_array, gt_array, predicted_mask=pred_array)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
