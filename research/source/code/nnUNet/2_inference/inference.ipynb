{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance of nnUNet architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a checkpoint of a model for a given class, evaluate the different metrics of the \n",
    "model by performing forward inference on the model and extracting the different\n",
    "evaluation metrics on the data, such as DICE, Haussdorff distance, Jaccard etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup env variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import subprocess\n",
    "\n",
    "def setup_data_vars(mine = False, overwrite = False):\n",
    "    \"\"\"\n",
    "    From within any directory related to radiotherapy with backtrack into the data folder\n",
    "    and execute the data_vars script. The assumption is that the datavars script will\n",
    "    output the list of environment variables that need to be set. This function will set\n",
    "    the environment variables for the current session.\n",
    "\n",
    "    For the mean while, my model hasn't completely finished training, therefore, to get\n",
    "    this task done, I will use Ben's pretrained nnUNet and then once mine has finished\n",
    "    training I will use my own. For the mean while, this means that we can choose between\n",
    "    using Ben's pretrained model or my own.\n",
    "    \"\"\"\n",
    "\n",
    "    # If the environment variables are not set, assume that either a custom one has been\n",
    "    # provided or resetting them again is a redundant task\n",
    "    if os.environ.get('nnUNet_raw') is None or overwrite is True:\n",
    "        # run the script in the data folder for specifying the environment variables\n",
    "        if mine:\n",
    "            cwd = os.getcwd().split('/')\n",
    "            data_dir = os.path.join('/'.join(cwd[:cwd.index('radiotherapy') + 1]), 'data')\n",
    "\n",
    "            # Assuming the data_vars.sh script echoes the environment variables\n",
    "            script = os.path.join(data_dir, 'data_vars.sh')\n",
    "            output = subprocess.run([script], capture_output=True)\n",
    "            \n",
    "            assert len(output.stdout) != 0, f\"Please check {script} and make sure it echoes \\\n",
    "    the environment variables.\"\n",
    "\n",
    "            output = output.stdout.decode('utf-8')\n",
    "        else:\n",
    "            data_dir = '/vol/biomedic3/bglocker/nnUNet'\n",
    "\n",
    "            # Assuming this script won't change, it contains hard coded exports\n",
    "            script = os.path.join(data_dir, 'exports')\n",
    "\n",
    "            with open(script, 'r') as file:\n",
    "                output = file.read()\n",
    "        \n",
    "        for line in output.split('\\n'):\n",
    "            if line != '':\n",
    "                if mine:\n",
    "                    line = line.split(': ')\n",
    "                    os.environ[line[0]] = line[1]\n",
    "                else:\n",
    "                    line = line.split('=')\n",
    "                    os.environ[line[0].split(' ')[1]] = line[1]\n",
    "\n",
    "    assert os.environ.get('nnUNet_raw') is not None, \"Environemnt variables not set. \\\n",
    "Please run the data_vars.sh script in the data folder.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Inference Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'Dataset001_Anorectum/nnUNetTrainer_50epochs__nnUNetPlans__3d_fullres/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialise_predictor():\n",
    "\n",
    "    from nnunetv2.inference.predict_from_raw_data import nnUNetPredictor\n",
    "    import torch\n",
    "\n",
    "    predictor = nnUNetPredictor(\n",
    "            tile_step_size=0.5,\n",
    "            use_gaussian=True,\n",
    "            use_mirroring=True,\n",
    "            perform_everything_on_device=True,\n",
    "            device=device,\n",
    "            verbose=False,\n",
    "            verbose_preprocessing=False,\n",
    "            allow_tqdm=True\n",
    "        )\n",
    "\n",
    "    predictor.initialize_from_trained_model_folder(\n",
    "        os.path.join(os.environ.get('nnUNet_results'), model_path),\n",
    "        # use_folds=(0,1,2,3,4),\n",
    "        use_folds=(0,1),\n",
    "        checkpoint_name='checkpoint_final.pth',\n",
    "    )\n",
    "\n",
    "    return predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_file(input_file, output_file, predictor):\n",
    "    \"\"\"\n",
    "    Predict the segmentation of a single file and save it to the output location.\n",
    "    \"\"\"\n",
    "\n",
    "    if os.path.exists(input_file):\n",
    "        print(f\"{input_file} exists\")\n",
    "    else:\n",
    "        print(f\"{input_file} does not exist\")\n",
    "\n",
    "    predictor.predict_from_files(input_file,\n",
    "                                 output_file,\n",
    "                                 save_probabilities=False, overwrite=False,\n",
    "                                 num_processes_preprocessing=2, num_processes_segmentation_export=2,\n",
    "                                 folder_with_segs_from_prev_stage=None, num_parts=1, part_id=0)\n",
    "\n",
    "    # variant 2, use list of files as inputs. Note how we use nested lists!!!\n",
    "    # predictor.predict_from_files([[file_name]],\n",
    "    #                             [output_name],\n",
    "    #                             save_probabilities=False, overwrite=overwrite,\n",
    "    #                             num_processes_preprocessing=2, num_processes_segmentation_export=2,\n",
    "    #                             folder_with_segs_from_prev_stage=None, num_parts=1, part_id=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running inference on inputs: https://github.com/MIC-DKFZ/nnUNet/blob/master/nnunetv2/inference/readme.md\n",
    "\n",
    "Running on slurm requires freezing: https://stackoverflow.com/questions/24374288/where-to-put-freeze-support-in-a-python-script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/vol/bitbucket/az620/radiotherapy/data/nnUNet_raw/Dataset001_Anorectum/imagesTr/zzAMLART_001_0000.nii.gz exists\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2145982/4097829194.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0moutput_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'zzAMLART_001.nii.gz'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0msetup_data_vars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mpredictor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minitialise_predictor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mpredict_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_2145982/3174441678.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(file_name, output_name, predictor, overwrite)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m# Can I open it with SimpleITK?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mimport\u001b[0m \u001b[0mSimpleITK\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msitk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msitk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mReadImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{file_name} can be opened with SimpleITK\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/vol/bitbucket/az620/radiotherapy/.venv/lib/python3.10/site-packages/SimpleITK/extra.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(fileName, outputPixelType, imageIO)\u001b[0m\n\u001b[1;32m    371\u001b[0m         \u001b[0mreader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSetFileNames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfileName\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m     \u001b[0mreader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSetImageIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimageIO\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    374\u001b[0m     \u001b[0mreader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSetOutputPixelType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputPixelType\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 375\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mreader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/vol/bitbucket/az620/radiotherapy/.venv/lib/python3.10/site-packages/SimpleITK/SimpleITK.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   8426\u001b[0m         \u001b[0mtype\u001b[0m \u001b[0mto\u001b[0m \u001b[0mbe\u001b[0m \u001b[0msame\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mIf\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mpixel\u001b[0m \u001b[0mtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mspecified\u001b[0m \u001b[0mthen\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mitk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mConvertPixelBuffer\u001b[0m \u001b[0mwill\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mused\u001b[0m \u001b[0mto\u001b[0m \u001b[0mconvert\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mpixels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8428\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8429\u001b[0m         \"\"\"\n\u001b[0;32m-> 8430\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_SimpleITK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImageFileReader_Execute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import multiprocessing\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    multiprocessing.freeze_support()\n",
    "\n",
    "    input_location = os.path.join(os.environ.get('nnUNet_raw'), 'Dataset001_Anorectum/imagesTr')\n",
    "    output_location = os.path.join('/vol/bitbucket/az620/radiotherapy/data/nnUNet_inference/', 'Dataset001_Anorectum/imagesTr_3dhighres')\n",
    "\n",
    "    # join = os.path.join\n",
    "\n",
    "    # file_path = join(input_location, 'zzAMLART_001_0000.nii.gz')\n",
    "    # output_path = join(output_location, 'zzAMLART_001.nii.gz')\n",
    "\n",
    "    setup_data_vars(mine=True, overwrite=True)\n",
    "    predictor = initialise_predictor()\n",
    "    predict_file(input_location, output_location, predictor)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
