{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combining the ground truth channels into one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Forom conversations online in the community surrounding segmentations that may exist that are allowed to overlap I found and consider the following links in the attempt to make work:\n",
    "\n",
    "https://github.com/MIC-DKFZ/nnUNet/issues/653\n",
    "\n",
    "https://github.com/MIC-DKFZ/nnUNet/issues/1823\n",
    "\n",
    "https://github.com/MIC-DKFZ/nnUNet/issues/1952"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Let the Anorectum be denoted as $A$\n",
    "- Let the Bladder be denoted as $B$\n",
    "- Let the Cervix be denoted with $C$\n",
    "- Let the CTVn be denoted with $C_n$\n",
    "- Let the CTVp be denoted with $C_p$\n",
    "- Let the GTVp be denoted with $G_p$\n",
    "- Let the GTVn be denoted with $G_n$\n",
    "- Let the Pelvic Lymph Node be denoted as $L_p$\n",
    "- Let the Common Iliac Lymph Node be denoted as $L_i$\n",
    "- Let the Para-aortic Lymph Node be denoted as $L_{pa}$\n",
    "- Let the Parametrium be denoted with $P$\n",
    "- Let the Uterus be denoted with $U$\n",
    "- Let the Vagina be denoted with $V$\n",
    "- Let $O$ denote the set $O = \\{B, A, C_n, C_p, P \\}$ for a particular patient. If we want to talk about a specific patient, we should use the super-script notation to differentiate patients, e.g., $O^i = \\{B^i, A^i, C_n^i, C_p^i, P^i\\}$.\n",
    "- Let the overlap of two structures be denoted by the set intersect symbol $\\cap$.\n",
    "- Let the joint area of two structures be denoted by the set union symbol $\\cup$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rules using the following notation are:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. There should be no overlap between the CTVn, CTVp or Anorectum.\n",
    "\n",
    "    $\\forall{i,j \\in \\{C_n, C_p, A\\}}\\text{ with } i \\neq j, i \\cap j = \\emptyset$\n",
    "\n",
    "2. The Parametrium may overlap with all of the other structures.\n",
    "\n",
    "    $\\forall i \\in S, \\quad P \\cap S_i \\neq \\emptyset \\quad \\text{(Possibly)}$\n",
    "\n",
    "3. The Bladder may overlap with the CTVn.\n",
    "\n",
    "    $B \\cap C_n \\neq \\emptyset \\vee B \\cap C_n = \\emptyset$\n",
    "\n",
    "4. The CTVp is defined as a compound structure containing:\n",
    "\n",
    "    $C_p = \\overbrace{C \\cup G_p}^{\\text{High Risk CTV}} \\quad \\cup \\quad U \\cup V$\n",
    "\n",
    "5. The CTVn is defined as a compound structure containing:\n",
    "\n",
    "    $C_n = G_n \\cup L_i \\cup L_p + L_{pa}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We only have the contours for the following classes: $A, B, C_n, C_p, P, U, V$:\n",
    "\n",
    "- $A \\mapsto 1$\n",
    "- $B \\mapsto 2$\n",
    "- $C_n \\mapsto 3$\n",
    "- $C_p \\mapsto 4$\n",
    "- $P \\mapsto 5$\n",
    "- $U \\mapsto 6$\n",
    "- $V \\mapsto 7$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- From `1.` we can mark $C_n, C_p, A$ with labels $3,4,1$ respectively becuase they are not meant to overlap\n",
    "\n",
    "- From `2.` the parametrium _may_ overlap with _all_ other structures. Therefore, we must have a binary segmentation which may describe this:\n",
    "\n",
    "    - $P \\cap A \\mapsto 8$\n",
    "    - $P \\cap B \\mapsto 9$\n",
    "    - $P \\cap C_n \\mapsto 10$\n",
    "    - $P \\cap C_p \\mapsto 11$\n",
    "    - $P \\cap U \\mapsto 12$\n",
    "    - $P \\cap V \\mapsto 13$\n",
    "\n",
    "- From `3.` the bladder may overlap with the $C_n$, however, we also find that the bladder may overlap with the $C_p$ from anecdotal experience with the scans\n",
    "\n",
    "    - $B \\cap C_n \\mapsto 14$\n",
    "\n",
    "- From `2.` and `3.` there exists an overlap where we have $B \\cap C_n$ and $P \\cap C_n$ and $P \\cap B$ therefore $B \\cap C_n \\cap P$ is possible.\n",
    "\n",
    "- From `4.`  $C_p$ is a structure which is composed of multiple other structures. Including, one that is a High-risk-CTV. We don't have a segmentation for this. However, We can nest the structures using `nnUNets` regions_class_order such that we draw the CTVp, then the Uterus then the Vagina. \n",
    "\n",
    "    - $U \\subseteq C_p$\n",
    "    - $V \\subseteq C_p$\n",
    "    - however, not necessarily $U \\subseteq V$ or $V \\subseteq U$\n",
    "\n",
    "- From `5.` $C_n$ is composed of substructures we don't have segmentations for. Therefore, it is its own segmentation id."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Id mappings\n",
    "\n",
    " - $background \\mapsto 0$\n",
    " - $anorectum \\mapsto 1$\n",
    " - $bladder \\mapsto 2$\n",
    " - $ctvn \\mapsto 3$\n",
    " - $ctvp \\mapsto 4$\n",
    " - $parametrium \\mapsto 7$ (for later convenience)\n",
    " - $uterus \\mapsto 6$\n",
    " - $vagina \\mapsto 5$ (for later convenience)\n",
    " - $pararect \\mapsto 8$\n",
    " - $parablad \\mapsto 9$\n",
    " - $paractvn \\mapsto 10$\n",
    " - $paractvp \\mapsto 11$\n",
    " - $parauter \\mapsto 12$\n",
    " - $paravagi \\mapsto 13$\n",
    " - $bladctvn \\mapsto 14$\n",
    " - $bladctvnpara \\mapsto 15$\n",
    " - $ctvputerpara \\mapsto 16$\n",
    " - $ctvpvagipara \\mapsto 17$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up Dataset class for nnUNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "dir1 = os.path.abspath(os.path.join(os.path.abspath(''), '..', '..'))\n",
    "if not dir1 in sys.path: sys.path.append(dir1)\n",
    "\n",
    "from utils.environment import setup_data_vars\n",
    "setup_data_vars()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "destination = os.path.join(os.environ.get('nnUNet_raw'), os.environ.get('TotalBinary'))\n",
    "assert os.path.exists(destination), f\"Destination folder {destination} does not exist\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_path_for_anatomy = lambda x: os.path.join(os.environ.get('nnUNet_raw'), os.environ.get(x), os.environ.get('data_trainingLabels'))\n",
    "gt_path_for_each_anatomy = dict([(os.environ.get(x), gt_path_for_anatomy(x)) for x in ['Anorectum','Bladder','CTVn','CTVp','Parametrium','Uterus','Vagina']])\n",
    "assert all([os.path.exists(x) for x in gt_path_for_each_anatomy.values()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nnunetv2.dataset_conversion.generate_dataset_json import generate_dataset_json\n",
    "\n",
    "from tqdm import tqdm\n",
    "from multiprocessing import Pool\n",
    "import multiprocessing\n",
    "import shutil\n",
    "import re\n",
    "import numpy as np\n",
    "from skimage import io\n",
    "\n",
    "import SimpleITK as sitk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gt_per_anatomy = {\n",
    "#     os.environ.get('Parametrium') : np.array([[0,0,1],\n",
    "#                                               [1,1,0],\n",
    "#                                               [1,0,0]]),\n",
    "#     os.environ.get('Bladder') : np.array([[1,0,1],\n",
    "#                                           [0,1,0],\n",
    "#                                           [0,0,1]]),\n",
    "#     os.environ.get('CTVn') : np.array([[0,1,0],\n",
    "#                                        [0,1,0],\n",
    "#                                        [1,1,0]]),\n",
    "# }\n",
    "\n",
    "# for k, v in gt_per_anatomy.items():\n",
    "#     dataset_id = int(re.findall(r'\\d+', k)[0])\n",
    "#     dataset_id = dataset_id = 5 if dataset_id == 7 else 7 if dataset_id == 5 else dataset_id\n",
    "#     gt_per_anatomy[k] = v * dataset_id\n",
    "\n",
    "# # stack all the ground truths\n",
    "# gt = np.stack([v for _,v in gt_per_anatomy.items()]) # (7, D, H, W)\n",
    "\n",
    "# # reduce the stack along axis 0 by defining a custom reducing function\n",
    "# def reduce_fn(x):\n",
    "#     values = np.unique(x) # returns a sorted array\n",
    "#     \"\"\"\n",
    "#     - $background \\mapsto 0$\n",
    "#     - $anorectum \\mapsto 1$\n",
    "#     - $bladder \\mapsto 2$\n",
    "#     - $ctvn \\mapsto 3$\n",
    "#     - $ctvp \\mapsto 4$\n",
    "#     - $parametrium \\mapsto 7$ (for later convenience)\n",
    "#     - $uterus \\mapsto 6$\n",
    "#     - $vagina \\mapsto 5$ (for later convenience)\n",
    "#     - $pararect \\mapsto 8$\n",
    "#     - $parablad \\mapsto 9$\n",
    "#     - $paractvn \\mapsto 10$\n",
    "#     - $paractvp \\mapsto 11$\n",
    "#     - $parauter \\mapsto 12$\n",
    "#     - $paravagi \\mapsto 13$\n",
    "#     - $bladctvn \\mapsto 14$\n",
    "#     - $bladctvp \\mapsto 15$\n",
    "#     - $bladctvnpara \\mapsto 16$\n",
    "#     - $bladctvputer \\mapsto 17$\n",
    "#     - $ctvputerpara \\mapsto 18$\n",
    "#     - $ctvpvagipara \\mapsto 19$\n",
    "#     \"\"\"\n",
    "#     # handles cases: [0]\n",
    "#     if np.array_equal(values, [0]):\n",
    "#         return 0\n",
    "\n",
    "#     if 0 in values:\n",
    "#         # remove the background id\n",
    "#         if len(values) == 1:\n",
    "#             return 0  \n",
    "#         values = values[1:]\n",
    "\n",
    "#     # handles cases: [1], [2], [3], [4], [5], [6], [7]\n",
    "#     if len(values) == 1:\n",
    "#         # no contention\n",
    "#         return values[0]\n",
    "    \n",
    "#     # handles case: [7, 1], [7, 2], [7, 3], [7, 4], [7, 5], [7, 6]\n",
    "#     if len(values) == 2 and 7 in values:\n",
    "#         # return the other number in the array\n",
    "#         idx = np.where(values == 7)[0][0]\n",
    "#         # idx = 0 -> 1, idx = 1 -> 0\n",
    "#         return values[abs(idx-1)] + 7\n",
    "\n",
    "#     if np.array_equal(values, [2,3]):\n",
    "#         return 14\n",
    "    \n",
    "#     if np.array_equal(values, [2,4]):\n",
    "#         return 15\n",
    "    \n",
    "#     if np.array_equal(values, [2,3,7]):\n",
    "#         return 16\n",
    "    \n",
    "#     if np.array_equal(values, [2,4,6]):\n",
    "#         return 17\n",
    "\n",
    "#     if np.array_equal(values, [4,6,7]):\n",
    "#         return 18\n",
    "    \n",
    "#     if np.array_equal(values, [4,5,7]):\n",
    "#         return 19\n",
    "    \n",
    "    \n",
    "#     raise NotImplementedError(f'Unhandled case: {values}')\n",
    "\n",
    "# gt = np.apply_along_axis(reduce_fn, 0, gt) # (D, H, W)\n",
    "\n",
    "# print(gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 3 is out of bounds for axis 1 with size 3",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[63], line 34\u001b[0m\n\u001b[1;32m     31\u001b[0m reshaped_indices \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate(reshaped_indices, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# Get unique pairs at each specified index\u001b[39;00m\n\u001b[0;32m---> 34\u001b[0m unique_pairs \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(\u001b[43mgt\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mreshaped_indices\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28mprint\u001b[39m(unique_pairs)\n",
      "\u001b[0;31mIndexError\u001b[0m: index 3 is out of bounds for axis 1 with size 3"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "gt = np.array(\n",
    "    [\n",
    "        [\n",
    "            [1,1,1,1,1],\n",
    "            [1,2,1,1,1],\n",
    "            [1,2,1,1,1]\n",
    "        ],\n",
    "        [\n",
    "            [1,1,1,1,1],\n",
    "            [1,2,1,1,1],\n",
    "            [1,2,1,1,1]\n",
    "        ]\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Define the shape of the array\n",
    "shape = gt.shape[1:]\n",
    "\n",
    "# Generate all possible indices separately for each axis\n",
    "indices = [np.arange(s) for s in shape]\n",
    "\n",
    "# Create meshgrid of indices\n",
    "meshgrid = np.meshgrid(*indices, indexing='ij')\n",
    "\n",
    "# Reshape meshgrid to match the shape of the array\n",
    "reshaped_indices = [idx.reshape(1, -1) for idx in meshgrid]\n",
    "\n",
    "# Concatenate the reshaped indices along the first axis\n",
    "reshaped_indices = np.concatenate(reshaped_indices, axis=0)\n",
    "\n",
    "# Get unique pairs at each specified index\n",
    "unique_pairs = np.unique(gt[:, tuple(reshaped_indices)], axis=1)\n",
    "\n",
    "print(unique_pairs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 30\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;66;03m# get all the unique combinations along axis 0\u001b[39;00m\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;28mprint\u001b[39m(np\u001b[38;5;241m.\u001b[39munique(gt, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m))\n\u001b[0;32m---> 30\u001b[0m \u001b[43mcombine_gt\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[14], line 28\u001b[0m, in \u001b[0;36mcombine_gt\u001b[0;34m(id)\u001b[0m\n\u001b[1;32m     25\u001b[0m gt \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mstack([v \u001b[38;5;28;01mfor\u001b[39;00m _, v \u001b[38;5;129;01min\u001b[39;00m gt_per_anatomy\u001b[38;5;241m.\u001b[39mitems()])  \u001b[38;5;66;03m# (7, D, H, W)\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# get all the unique combinations along axis 0\u001b[39;00m\n\u001b[0;32m---> 28\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munique\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m/vol/biomedic3/bglocker/ugproj2324/az620/radiotherapy/.venv/lib/python3.10/site-packages/numpy/lib/arraysetops.py:317\u001b[0m, in \u001b[0;36munique\u001b[0;34m(ar, return_index, return_inverse, return_counts, axis, equal_nan)\u001b[0m\n\u001b[1;32m    314\u001b[0m     uniq \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmoveaxis(uniq, \u001b[38;5;241m0\u001b[39m, axis)\n\u001b[1;32m    315\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m uniq\n\u001b[0;32m--> 317\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43m_unique1d\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconsolidated\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    318\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mreturn_inverse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_counts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mequal_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mequal_nan\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    319\u001b[0m output \u001b[38;5;241m=\u001b[39m (reshape_uniq(output[\u001b[38;5;241m0\u001b[39m]),) \u001b[38;5;241m+\u001b[39m output[\u001b[38;5;241m1\u001b[39m:]\n\u001b[1;32m    320\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _unpack_tuple(output)\n",
      "File \u001b[0;32m/vol/biomedic3/bglocker/ugproj2324/az620/radiotherapy/.venv/lib/python3.10/site-packages/numpy/lib/arraysetops.py:328\u001b[0m, in \u001b[0;36m_unique1d\u001b[0;34m(ar, return_index, return_inverse, return_counts, equal_nan)\u001b[0m\n\u001b[1;32m    323\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_unique1d\u001b[39m(ar, return_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, return_inverse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    324\u001b[0m               return_counts\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;241m*\u001b[39m, equal_nan\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m    325\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    326\u001b[0m \u001b[38;5;124;03m    Find the unique elements of an array, ignoring shape.\u001b[39;00m\n\u001b[1;32m    327\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 328\u001b[0m     ar \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masanyarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mar\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflatten\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    330\u001b[0m     optional_indices \u001b[38;5;241m=\u001b[39m return_index \u001b[38;5;129;01mor\u001b[39;00m return_inverse\n\u001b[1;32m    332\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m optional_indices:\n",
      "\u001b[0;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import SimpleITK as sitk\n",
    "\n",
    "combos = set()\n",
    "\n",
    "def combine_gt(id: int):\n",
    "    assert 0 <= id <= 100, 'assumed that there are only 100 ids'\n",
    "\n",
    "    # read in each anatomy ground truth\n",
    "    sample_name = f'zzAMLART_{id:03d}.nii.gz'\n",
    "\n",
    "    gt_per_anatomy = dict([(k, sitk.GetArrayFromImage(sitk.ReadImage(os.path.join(v, sample_name)))) for k, v in\n",
    "                           gt_path_for_each_anatomy.items()])\n",
    "    assert all([x.shape == gt_per_anatomy[os.environ.get('Anorectum')].shape for _, x in gt_per_anatomy.items()]), \\\n",
    "        'ground truths contain at least one element that isn\\'t the same size!'\n",
    "\n",
    "    for k, v in gt_per_anatomy.items():\n",
    "        dataset_id = int(re.findall(r'\\d+', k)[0])\n",
    "        dataset_id = 5 if dataset_id == 7 else 7 if dataset_id == 5 else dataset_id\n",
    "        gt_per_anatomy[k] = v * dataset_id\n",
    "\n",
    "    # stack all the ground truths\n",
    "    gt = np.stack([v for _, v in gt_per_anatomy.items()])  # (7, D, H, W)\n",
    "\n",
    "    # get all the unique combinations along axis 0\n",
    "    print(np.unique(gt, axis=0))\n",
    "\n",
    "combine_gt(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 38409.38it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0 1]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 11\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m101\u001b[39m)):\n\u001b[1;32m      7\u001b[0m         r\u001b[38;5;241m.\u001b[39mappend(p\u001b[38;5;241m.\u001b[39mstarmap_async(\n\u001b[1;32m      8\u001b[0m             combine_gt,\n\u001b[1;32m      9\u001b[0m             [(i, gt_path_for_each_anatomy)]\n\u001b[1;32m     10\u001b[0m         ))\n\u001b[0;32m---> 11\u001b[0m     _ \u001b[38;5;241m=\u001b[39m [i\u001b[38;5;241m.\u001b[39mget() \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m r]\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(combos)\n",
      "Cell \u001b[0;32mIn[6], line 11\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m101\u001b[39m)):\n\u001b[1;32m      7\u001b[0m         r\u001b[38;5;241m.\u001b[39mappend(p\u001b[38;5;241m.\u001b[39mstarmap_async(\n\u001b[1;32m      8\u001b[0m             combine_gt,\n\u001b[1;32m      9\u001b[0m             [(i, gt_path_for_each_anatomy)]\n\u001b[1;32m     10\u001b[0m         ))\n\u001b[0;32m---> 11\u001b[0m     _ \u001b[38;5;241m=\u001b[39m [\u001b[43mi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m r]\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(combos)\n",
      "File \u001b[0;32m/usr/lib/python3.10/multiprocessing/pool.py:768\u001b[0m, in \u001b[0;36mApplyResult.get\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    767\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 768\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    769\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mready():\n\u001b[1;32m    770\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.10/multiprocessing/pool.py:765\u001b[0m, in \u001b[0;36mApplyResult.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    764\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwait\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 765\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_event\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3.10/threading.py:607\u001b[0m, in \u001b[0;36mEvent.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    605\u001b[0m signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flag\n\u001b[1;32m    606\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[0;32m--> 607\u001b[0m     signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cond\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    608\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "File \u001b[0;32m/usr/lib/python3.10/threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 320\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    321\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from gt_processing import combine_gt, combos\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    with multiprocessing.get_context(\"spawn\").Pool(8) as p:\n",
    "        r = []\n",
    "        for i in tqdm(range(1, 101)):\n",
    "            r.append(p.starmap_async(\n",
    "                combine_gt,\n",
    "                [(i, gt_path_for_each_anatomy)]\n",
    "            ))\n",
    "        _ = [i.get() for i in r]\n",
    "\n",
    "    print(combos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
