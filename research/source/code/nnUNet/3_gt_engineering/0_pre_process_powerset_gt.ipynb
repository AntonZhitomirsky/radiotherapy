{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "dir1 = os.path.abspath(os.path.join(os.path.abspath(''), '..', '..'))\n",
    "if not dir1 in sys.path: sys.path.append(dir1)\n",
    "\n",
    "from utils.environment import setup_data_vars\n",
    "setup_data_vars()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "destination = os.path.join(os.environ.get('nnUNet_raw'), os.environ.get('TotalBinary'))\n",
    "assert os.path.exists(destination), f\"Destination folder {destination} does not exist\"\n",
    "\n",
    "gt_path_for_anatomy = lambda x: os.path.join(os.environ.get('nnUNet_raw'), os.environ.get(x), os.environ.get('data_trainingLabels'))\n",
    "gt_path_for_each_anatomy = dict([(os.environ.get(x), gt_path_for_anatomy(x)) for x in ['Anorectum','Bladder','CTVn','CTVp','Parametrium','Uterus','Vagina']])\n",
    "assert all([os.path.exists(x) for x in gt_path_for_each_anatomy.values()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Establish mapping from anatomy combinations to segmentation regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain, combinations\n",
    "import json\n",
    "\n",
    "def powerset(iterable):\n",
    "    # powerset([1,2,3]) --> () (1,) (2,) (3,) (1,2) (1,3) (2,3) (1,2,3)\n",
    "    s = list(iterable)\n",
    "    return chain.from_iterable(combinations(s, r) for r in range(len(s)+1))\n",
    "\n",
    "n_labels = 7\n",
    "\n",
    "labelscomb = list(powerset(range(1,n_labels + 1)))\n",
    "multilabels = range(len(labelscomb))\n",
    "labelscomb_to_multilabel = dict(zip(labelscomb, multilabels))\n",
    "\n",
    "# So `labelscomb_to_multilabel` is basically a look-up table for converting a combination\n",
    "# of labels to the huge integer value that will be used in the nnU-Net nifti label file.\n",
    "# labelscomb_to_multilabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing labels for dataset.json\n",
    "# labels = {'background': 0}\n",
    "# labels = {**labels, **{str(biomarker_idx): [] for biomarker_idx in range(1,n_labels+1)}}\n",
    "labels = {str(biomarker_idx): [] for biomarker_idx in range(1,n_labels+1)}\n",
    "\n",
    "for biomarker_ids, multilabel in labelscomb_to_multilabel.items():\n",
    "    for biomarker_idx in biomarker_ids:\n",
    "        labels[str(biomarker_idx)].append(multilabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename the entries in the dictionary to the appropriate anatomy names\n",
    "anatomies = ['anorectum','bladder','ctvn','ctvp','parametrium','uterus','vagina']\n",
    "\n",
    "# Create a mapping dictionary\n",
    "mapping_dict = {key: anatomies[int(key) - 1] for key in labels.keys()}\n",
    "\n",
    "# Replace keys with corresponding positions in the array\n",
    "labels = {mapping_dict[key]: value for key, value in labels.items()}\n",
    "labels = {**{'background': 0}, **labels}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to json file\n",
    "dataset_dict = { \n",
    "    \"channel_names\": {  # formerly modalities\n",
    "        \"0\": \"CT\",\n",
    "    }, \n",
    "    \"labels\": labels, \n",
    "    \"numTraining\": 100, \n",
    "    \"file_ending\": \".nii.gz\",\n",
    "    \"regions_class_order\": list(range(1, n_labels + 1)),\n",
    "}\n",
    "\n",
    "with open(os.path.join(destination, 'dataset.json'), 'w') as f:\n",
    "    f.write(json.dumps(dataset_dict, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function for converting the 7 gt segmentations into one with region ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import SimpleITK as sitk\n",
    "\n",
    "def operation(x):\n",
    "        labels_in_voxel = tuple(np.argwhere(x)[:, 0] + 1)\n",
    "        return labelscomb_to_multilabel[labels_in_voxel]\n",
    "\n",
    "def image_to_nnunet_multilabel(input_volume):\n",
    "    # Note `input_volume` should be one-hot encoded, so input_volume.shape == (n_labels, D, H, W)\n",
    "    input_volume_per_channel = input_volume.reshape(n_labels, -1).T # (n_labels, D x H x W)\n",
    "    input_volume_translated = np.apply_along_axis(operation, 1, input_volume_per_channel)\n",
    "    correct_shape = input_volume_translated.reshape(input_volume.shape[1:]) # (D x H x W)\n",
    "    \n",
    "    return correct_shape\n",
    "\n",
    "def combine_gt(id: int):\n",
    "    assert 0 <= id <= 100, 'assumed that there are only 100 ids'\n",
    "\n",
    "    # read in each anatomy ground truth\n",
    "    sample_name = f'zzAMLART_{id:03d}.nii.gz'\n",
    "\n",
    "    gt_per_anatomy = dict([(k, sitk.GetArrayFromImage(sitk.ReadImage(os.path.join(v, sample_name)))) for k, v in\n",
    "                           gt_path_for_each_anatomy.items()])\n",
    "    assert all([x.shape == gt_per_anatomy[os.environ.get('Anorectum')].shape for _, x in gt_per_anatomy.items()]), \\\n",
    "        'ground truths contain at least one element that isn\\'t the same size!'\n",
    "\n",
    "    # stack all the ground truths\n",
    "    gt = np.stack([v for _, v in gt_per_anatomy.items()])  # (7, D, H, W)\n",
    "\n",
    "    return gt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# quick test\n",
    "\n",
    "# create an array of values between 0 and 1\n",
    "gt_slice = np.random.rand(20, 40, 45)\n",
    "# threshold these values to 0 if below 0.5 or 1 otherwise\n",
    "gt_slice = np.where(gt_slice < 0.5, 0, 1)\n",
    "# repeat this slice across 7 dimensions\n",
    "gt = np.repeat(gt_slice[np.newaxis, :, :, :], 7, axis=0)\n",
    "assert np.array_equal(gt[0], gt_slice)\n",
    "\n",
    "output = image_to_nnunet_multilabel(gt)\n",
    "assert gt_slice.shape == output.shape\n",
    "assert np.array_equal(gt_slice * 127, output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup script for translating these ground truths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "for i in tqdm(range(1, 101)):\n",
    "    output_file_name = f'zzAMLART_{i:03d}.nii.gz'\n",
    "    if os.path.exists(os.path.join(destination, 'labelsTr', output_file_name)):\n",
    "        continue\n",
    "\n",
    "    # combine the ground truths for each anatomy\n",
    "    gt = combine_gt(i)\n",
    "    output = image_to_nnunet_multilabel(gt)\n",
    "\n",
    "    # save the output as a .nii.gz file in the destination folder\n",
    "    output = sitk.GetImageFromArray(output)\n",
    "    output.CopyInformation(sitk.ReadImage(os.path.join(gt_path_for_each_anatomy[os.environ.get('Anorectum')], f'zzAMLART_{i:03d}.nii.gz')))\n",
    "    sitk.WriteImage(output, os.path.join(destination, 'labelsTr', output_file_name))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
