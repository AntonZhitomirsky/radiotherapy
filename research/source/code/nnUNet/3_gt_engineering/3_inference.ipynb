{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance of nnUNet architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a checkpoint of a model for a given class, evaluate the different metrics of the \n",
    "model by performing forward inference on the model and extracting the different\n",
    "evaluation metrics on the data, such as DICE, Haussdorff distance, Jaccard etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup env variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "dir1 = os.path.abspath(os.path.join(os.path.abspath(''), '..', '..'))\n",
    "if not dir1 in sys.path: sys.path.append(dir1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.environment import setup_data_vars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Inference Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialise_predictor(model_path, fold):\n",
    "\n",
    "    from nnunetv2.inference.predict_from_raw_data import nnUNetPredictor\n",
    "    import torch\n",
    "\n",
    "    predictor = nnUNetPredictor(\n",
    "            tile_step_size=0.5,\n",
    "            use_gaussian=True,\n",
    "            use_mirroring=True,\n",
    "            perform_everything_on_device=True,\n",
    "            device=device,\n",
    "            verbose=False,\n",
    "            verbose_preprocessing=False,\n",
    "            allow_tqdm=True\n",
    "        )\n",
    "\n",
    "    predictor.initialize_from_trained_model_folder(\n",
    "        os.path.join(os.environ.get('nnUNet_results'), model_path),\n",
    "        use_folds=fold,\n",
    "        checkpoint_name='checkpoint_best.pth',\n",
    "    )\n",
    "\n",
    "    return predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_file(input_file, output_file, predictor):\n",
    "    \"\"\"\n",
    "    Predict the segmentation of a single file and save it to the output location.\n",
    "    \"\"\"\n",
    "\n",
    "    if os.path.exists(input_file):\n",
    "        print(f\"{input_file} exists\")\n",
    "    else:\n",
    "        print(f\"{input_file} does not exist\")\n",
    "\n",
    "    predictor.predict_from_files(input_file,\n",
    "                                 output_file,\n",
    "                                 save_probabilities=False,\n",
    "                                 flatten_prediction=False,\n",
    "                                 overwrite=False,\n",
    "                                 num_processes_preprocessing=2,\n",
    "                                 num_processes_segmentation_export=2,\n",
    "                                 folder_with_segs_from_prev_stage=None,\n",
    "                                 num_parts=1,\n",
    "                                 part_id=0)\n",
    "\n",
    "    # variant 2, use list of files as inputs. Note how we use nested lists!!!\n",
    "    # predictor.predict_from_files([[file_name]],\n",
    "    #                             [output_name],\n",
    "    #                             save_probabilities=False, overwrite=overwrite,\n",
    "    #                             num_processes_preprocessing=2, num_processes_segmentation_export=2,\n",
    "    #                             folder_with_segs_from_prev_stage=None, num_parts=1, part_id=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running inference on inputs: https://github.com/MIC-DKFZ/nnUNet/blob/master/nnunetv2/inference/readme.md\n",
    "\n",
    "Running on slurm requires freezing: https://stackoverflow.com/questions/24374288/where-to-put-freeze-support-in-a-python-script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initialising predictor with class Dataset008_TotalBinary, and folds ('1', '0')\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    multiprocessing.freeze_support()\n",
    "\n",
    "    setup_data_vars()\n",
    "\n",
    "    class_of_interest = os.environ.get('TotalBinary')\n",
    "    input_data_path = os.path.join(os.environ.get('nnUNet_raw'), class_of_interest, os.environ.get('data_trainingImages'))\n",
    "    output_path = os.path.join(os.environ.get('nnUNet_inference'), class_of_interest, 'nnUNetTrainer_500epochs__nnUNetPlans__3d_fullres_unflattened')\n",
    "    model_path = os.path.join(class_of_interest, 'nnUNetTrainer_500epochs__nnUNetPlans__3d_fullres')\n",
    "\n",
    "    folds_for_model = set()\n",
    "    full_path = os.path.join(os.environ.get('nnUNet_results'), model_path)\n",
    "    _, subdirs, _ = next(os.walk(full_path))\n",
    "    for folds in sorted(subdirs):\n",
    "        for checkpoints in os.listdir(os.path.join(full_path, folds)):\n",
    "            if '.pth' in checkpoints:\n",
    "                folds_for_model.add(folds.split('_')[1])\n",
    "\n",
    "    fold = tuple(folds_for_model)\n",
    "    \n",
    "    print(f'initialising predictor with class {class_of_interest}, and folds {fold}')\n",
    "    predictor = initialise_predictor(model_path, fold)\n",
    "\n",
    "    setup_data_vars()\n",
    "    \n",
    "    print(f'predicting from {input_data_path} to {output_path}')\n",
    "    predict_file(input_data_path, output_path, predictor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/210 [00:00<?, ?it/s]/vol/biomedic3/bglocker/ugproj2324/az620/radiotherapy/.venv/lib/python3.10/site-packages/torch/nn/modules/conv.py:605: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv3d(\n",
      "100%|██████████| 210/210 [02:13<00:00,  1.57it/s]\n",
      "100%|██████████| 210/210 [02:13<00:00,  1.58it/s]\n"
     ]
    }
   ],
   "source": [
    "# from nnunetv2.imageio.simpleitk_reader_writer import SimpleITKIO\n",
    "# from nnunetv2.inference.predict_from_raw_data import nnUNetPredictor\n",
    "\n",
    "# img, props = SimpleITKIO().read_images([os.path.join(os.environ.get('nnUNet_raw'), os.environ.get('TotalBinary'), os.environ.get('data_trainingImages'), 'zzAMLART_011_0000.nii.gz')])\n",
    "\n",
    "# ret = predictor.predict_single_npy_array(\n",
    "#         input_image = img, \n",
    "#         image_properties = props, \n",
    "#         segmentation_previous_stage = None,\n",
    "#         output_file_truncated = None,\n",
    "#         save_or_return_probabilities = True,\n",
    "#         flatten_prediction = False)\n",
    "\n",
    "# # iterator = predictor.get_data_iterator_from_raw_npy_data([img], None, [props], None, 1)\n",
    "# # ret = predictor.predict_from_data_iterator(iterator, False, 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
