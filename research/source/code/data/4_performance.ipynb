{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "dir1 = os.path.dirname(os.path.abspath(''))\n",
    "if not dir1 in sys.path: sys.path.append(dir1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.environment import setup_data_vars\n",
    "setup_data_vars()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_id_from_path(path: str, needs_num=True):\n",
    "    \"\"\"Given a path, assume that it is the full path that points to the file name. The\n",
    "    file nam ehsould contain a number indicating the id number. It should appear first.\n",
    "\n",
    "    Args:\n",
    "        path (str): A path to the file name or the file name itsself. \n",
    "        \n",
    "        needs_num (bool, optional): If the path needs a number. If it doesn't and no\n",
    "        number was found return 0, otherwise return the number found. Defaults to True.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If a number is required and no number was found in the path\n",
    "\n",
    "    Returns:\n",
    "        int: the number found in the path\n",
    "    \"\"\"\n",
    "    import re\n",
    "    # Assume that it is the full path that points to the file name. The file name\n",
    "    # should contain a number indicating the id number. It should appear first\n",
    "    numbers = re.findall('\\d+', path.split('/')[-1])\n",
    "    if needs_num and len(numbers) == 0:\n",
    "        raise ValueError(f\"Could not find a number in {path}\")\n",
    "    if not needs_num and len(numbers) == 0:\n",
    "        return 0\n",
    "    return int(numbers[0])\n",
    "\n",
    "def stats_about_metrics(metrics_dictionary: dict):\n",
    "\n",
    "    return_metrics_dictionary = dict()\n",
    "    return_metrics_dictionary['mean'] = dict()\n",
    "\n",
    "    for model, metrics in metrics_dictionary.items():\n",
    "        return_metrics_dictionary['mean'][model] = dict()\n",
    "        for metric, data in metrics.items():\n",
    "            return_metrics_dictionary['mean'][model][metric] = np.mean(data)\n",
    "\n",
    "    return return_metrics_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import SimpleITK as sitk\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from platipy.imaging.label.comparison import compute_metric_total_apl, compute_surface_dsc, compute_metric_hd\n",
    "\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def calculate_for_MedSAM(prediction_type, model_path):\n",
    "    dice = {0: [], 1: [], 2: []}\n",
    "    hd = {0: [], 1: [], 2: []}\n",
    "    volume_similarity = {0: [], 1: [], 2: []}\n",
    "    apl = {0: [], 1: [], 2: []}\n",
    "    surface_dsc = {0: [], 1: [], 2: []}\n",
    "\n",
    "    # CSV name depends on whether it is out-of-the-box or the fine-tuned version\n",
    "    if 'out-of-the-box' in prediction_type:\n",
    "        csv_name = 'validation_base.csv'\n",
    "    else:\n",
    "        csv_name = 'validation_checkpoint.csv'\n",
    "\n",
    "    # we assume that we've already recorded and saved the statistics in a file validation.csv\n",
    "    # this will contain the validation data for that particular anatomy across all three axis\n",
    "\n",
    "    df = pd.DataFrame(columns=['name', 'axis', 'dice', 'jaccard', 'volume_similarity', 'apl', 'surface_distance', 'hausdorff_distance'])\n",
    "\n",
    "    # load in the processed data if it already exists\n",
    "    if os.path.exists(os.path.join(model_path, csv_name)):\n",
    "        df = pd.read_csv(os.path.join(model_path, csv_name))\n",
    "    else:\n",
    "        raise ValueError(\"No validation data found for this model\")\n",
    "    \n",
    "    # go through the pandas dataframe and aggregate the metrics into each of the dictionaries keyed by the axis.\n",
    "     \n",
    "    for _, row in df.iterrows():\n",
    "        dice[row['axis']].append(row['dice'])\n",
    "        hd[row['axis']].append(row['hausdorff_distance'])\n",
    "        volume_similarity[row['axis']].append(row['volume_similarity'])\n",
    "        apl[row['axis']].append(row['apl'])\n",
    "        surface_dsc[row['axis']].append(row['surface_distance'])\n",
    "\n",
    "    return dice, hd, volume_similarity, surface_dsc, apl\n",
    "\n",
    "def calculate_for_UniverSeg(model_path):\n",
    "    dice = {0: [], 1: [], 2: []}\n",
    "    hd = {0: [], 1: [], 2: []}\n",
    "    volume_similarity = {0: [], 1: [], 2: []}\n",
    "    apl = {0: [], 1: [], 2: []}\n",
    "    surface_dsc = {0: [], 1: [], 2: []}\n",
    "\n",
    "    # we assume that we've already recorded and saved the statistics in a file validation.csv\n",
    "    # this will contain the validation data for that particular anatomy across all three axis\n",
    "\n",
    "    df = pd.DataFrame(columns=['name','dice','volume_similarity','apl','surface_distance','hausdorff_distance'])\n",
    "\n",
    "    # go through each axis in the model path and load in the validation data\n",
    "\n",
    "    axis_stats = [int(ax[-1]) for ax in sorted(os.listdir(model_path))]\n",
    "    if len(axis_stats) != 3:\n",
    "        print(\"[WARNING]: There should be 3 axis in the model path, got\" , axis_stats)\n",
    "\n",
    "    for axis in axis_stats:\n",
    "        if os.path.exists(os.path.join(model_path, f'axis{axis}', 'validation.csv')):\n",
    "            df = pd.read_csv(os.path.join(model_path, f'axis{axis}', 'validation.csv'))\n",
    "        else:\n",
    "            raise ValueError(\"No validation data found for this model\")\n",
    "    \n",
    "        # go through the pandas dataframe and aggregate the metrics into each of the dictionaries keyed by the axis.\n",
    "        \n",
    "        for _, row in df.iterrows():\n",
    "            dice[axis].append(row['dice'])\n",
    "            hd[axis].append(row['hausdorff_distance'])\n",
    "            volume_similarity[axis].append(row['volume_similarity'])\n",
    "            apl[axis].append(row['apl'])\n",
    "            surface_dsc[axis].append(row['surface_distance'])\n",
    "\n",
    "    return dice, hd, volume_similarity, surface_dsc, apl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_for_single_nnUNet_model(input_path_gt, prediction_path):\n",
    "    # if this is our first time running the model we need to run and save the statistics\n",
    "    # otherwise we can just load in the statistics\n",
    "\n",
    "    df = pd.DataFrame(columns=['name','dice','volume_similarity','apl','surface_distance','hausdorff_distance'])\n",
    "\n",
    "    if os.path.exists(os.path.join(prediction_path, 'validation.csv')):\n",
    "        df = pd.read_csv(os.path.join(prediction_path, 'validation.csv'))\n",
    "    else:\n",
    "\n",
    "        overlap_measures_filter = sitk.LabelOverlapMeasuresImageFilter()\n",
    "\n",
    "        ground_truth = [os.path.join(input_path_gt, file) for file in sorted(filter(lambda x: '.nii.gz' in x, os.listdir(input_path_gt)))]\n",
    "        assert len(ground_truth) == 100\n",
    "        assert get_id_from_path(ground_truth[0]) == 1\n",
    "\n",
    "        # Extract all .nii.gz files for metric calculation\n",
    "        predictions = [os.path.join(prediction_path, file) for file in sorted(filter(lambda x: '.nii.gz' in x, os.listdir(prediction_path)))]\n",
    "\n",
    "        # Iterate over pairs of predictions and ground truth\n",
    "        for ypred in tqdm(predictions):\n",
    "            y_gt = ground_truth[get_id_from_path(ypred) - 1]\n",
    "            # If we wish to process the metrics as a 3D whole image, then this is\n",
    "            # trivially done without loading each slice separately\n",
    "            ypred_sitk = sitk.ReadImage(ypred)\n",
    "            y_gt_sitk = sitk.ReadImage(y_gt)\n",
    "\n",
    "            # set spacing to be (1, 1, 1)\n",
    "            ypred_sitk.SetSpacing((1, 1, 1))\n",
    "            y_gt_sitk.SetSpacing((1, 1, 1))\n",
    "\n",
    "            overlap_measures_filter.Execute(y_gt_sitk, ypred_sitk)\n",
    "\n",
    "            new_record = pd.DataFrame([\n",
    "                {\n",
    "                'name': y_gt,\n",
    "                'dice': overlap_measures_filter.GetDiceCoefficient(),\n",
    "                'volume_similarity': overlap_measures_filter.GetVolumeSimilarity(),\n",
    "                'apl': compute_metric_total_apl(y_gt_sitk, ypred_sitk),\n",
    "                'surface_distance': compute_surface_dsc(y_gt_sitk, ypred_sitk),\n",
    "                'hausdorff_distance': compute_metric_hd(y_gt_sitk, ypred_sitk)\n",
    "                }\n",
    "            ])\n",
    "\n",
    "            df = pd.concat([df, new_record], ignore_index=True)\n",
    "\n",
    "        df.to_csv(os.path.join(prediction_path, 'validation.csv'), index=False)\n",
    "\n",
    "    return df['dice'].tolist(), df['hausdorff_distance'].tolist(), df['volume_similarity'].tolist(), df['surface_distance'].tolist(), df['apl'].tolist()\n",
    "\n",
    "def calculate_for_global_nnUNet_model(input_path_gt, prediction_path, class_id_position):\n",
    "    # if this is our first time running the model we need to run and save the statistics\n",
    "    # otherwise we can just load in the statistics\n",
    "\n",
    "    df = pd.DataFrame(columns=['name','dice','volume_similarity','apl','surface_distance','hausdorff_distance'])\n",
    "\n",
    "    if os.path.exists(os.path.join(prediction_path, 'validation.csv')):\n",
    "        df = pd.read_csv(os.path.join(prediction_path, 'validation.csv'))\n",
    "    else:\n",
    "\n",
    "        overlap_measures_filter = sitk.LabelOverlapMeasuresImageFilter()\n",
    "\n",
    "        # get the predicted probability maps\n",
    "        predictions = [os.path.join(prediction_path, file) for file in sorted(filter(lambda x: '.npz' in x, os.listdir(prediction_path)))]\n",
    "        ground_truth = [os.path.join(input_path_gt, file) for file in sorted(filter(lambda x: '.nii.gz' in x, os.listdir(input_path_gt)))]\n",
    "        assert len(ground_truth) == 100\n",
    "        assert get_id_from_path(ground_truth[0]) == 1\n",
    "        \n",
    "        for p in tqdm(predictions):\n",
    "            # get the image id of the prediction\n",
    "\n",
    "            image_id = get_id_from_path(p, needs_num=True)\n",
    "            probabilities = np.load(p)['probabilities'][class_id_position]\n",
    "            hard_probabilities = (probabilities > 0.5).astype(np.uint8)\n",
    "            prediction_sitk = sitk.GetImageFromArray(hard_probabilities)\n",
    "\n",
    "            # get the ground truth for this image id\n",
    "            y_gt = ground_truth[image_id - 1]\n",
    "            y_gt_sitk = sitk.ReadImage(y_gt)\n",
    "\n",
    "            # copy over properties from the ground truth into the predicted image\n",
    "            prediction_sitk.CopyInformation(y_gt_sitk)  \n",
    "\n",
    "            # set spacing to be (1,1,1)\n",
    "            prediction_sitk.SetSpacing((1, 1, 1))\n",
    "            y_gt_sitk.SetSpacing((1, 1, 1))  \n",
    "\n",
    "            overlap_measures_filter.Execute(y_gt_sitk, prediction_sitk)\n",
    "\n",
    "            new_record = pd.DataFrame([\n",
    "                {\n",
    "                'name': y_gt,\n",
    "                'dice': overlap_measures_filter.GetDiceCoefficient(),\n",
    "                'volume_similarity': overlap_measures_filter.GetVolumeSimilarity(),\n",
    "                'apl': compute_metric_total_apl(y_gt_sitk, prediction_sitk),\n",
    "                'surface_distance': compute_surface_dsc(y_gt_sitk, prediction_sitk),\n",
    "                'hausdorff_distance': compute_metric_hd(y_gt_sitk, prediction_sitk)\n",
    "                }\n",
    "            ])\n",
    "            df = pd.concat([df, new_record], ignore_index=True)\n",
    "\n",
    "        df.to_csv(os.path.join(prediction_path, 'validation.csv'), index=False)\n",
    "\n",
    "    return df['dice'].tolist(), df['hausdorff_distance'].tolist(), df['volume_similarity'].tolist(), df['surface_distance'].tolist(), df['apl'].tolist()\n",
    "\n",
    "def calculate_for_nnUNetBased(input_path_gt, prediction_type, prediction_path, class_id_position):\n",
    "    print(f'Calculating metrics for  {prediction_type}')\n",
    "    if 'global' in prediction_type:\n",
    "        return calculate_for_global_nnUNet_model(input_path_gt, prediction_path, class_id_position)\n",
    "    else:\n",
    "        return calculate_for_single_nnUNet_model(input_path_gt, prediction_path)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(input_path_gt: str, input_path_pred: dict, class_id_position: int):\n",
    "    \"\"\"Will return the metrics for each prediction path\n",
    "\n",
    "    Args:\n",
    "        input_path_gt (str): a string to the ground truth \n",
    "        input_path_pred (dict): a dictionary containing the paths to the predictions\n",
    "\n",
    "    Returns:\n",
    "        dict: returns dictionary of metrics for the main prediction paths\n",
    "    \"\"\"\n",
    "\n",
    "    final_metrics = dict()\n",
    "    for k, _ in input_path_pred.items(): final_metrics[k] = dict()\n",
    "\n",
    "    # Iterate over the models and their predictions\n",
    "    for prediction_type, prediction_path in input_path_pred.items():\n",
    "\n",
    "        dice = []\n",
    "        hd = []\n",
    "        volume_similarity = []\n",
    "        apl = []\n",
    "        surface_dsc = []\n",
    "\n",
    "        if 'MedSAM' in prediction_type:\n",
    "            # raise NotImplementedError(\"MedSAM is not decomissioned for the mean while\")\n",
    "            dice, hd, volume_similarity, surface_dsc, apl = calculate_for_MedSAM(prediction_type, prediction_path)\n",
    "        elif 'UniverSeg' in prediction_type:\n",
    "            dice, hd, volume_similarity, surface_dsc, apl = calculate_for_UniverSeg(prediction_path)\n",
    "        else:\n",
    "            dice, hd, volume_similarity, surface_dsc, apl = calculate_for_nnUNetBased(input_path_gt, prediction_type, prediction_path, class_id_position)\n",
    "\n",
    "        final_metrics[prediction_type]['DICE Similarity Coefficient'] = dice\n",
    "        final_metrics[prediction_type]['Haussdorf Distance'] = hd\n",
    "        final_metrics[prediction_type]['Relative Volume Difference'] = volume_similarity\n",
    "        final_metrics[prediction_type]['Added Path Length'] = apl\n",
    "        final_metrics[prediction_type]['Surface DSC'] = surface_dsc\n",
    "\n",
    "    return final_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "split_axis = False\n",
    "\n",
    "def plot_metrics(metrics_dictionary: dict, organ_class: str, separate: bool = False, save: bool = False, showfliers = True, table = True, additional_title_context = ''):\n",
    "    \"\"\"Plots the metrics for the given dictionary of metrics and prints a table of mean\n",
    "    metrics to the right\n",
    "\n",
    "    Args:\n",
    "        metrics_dictionary (dict): A dictionary containing a key value pair of model type\n",
    "        and value of dictionary. This dictionary will have a key value pairing of metric\n",
    "        type and a list of values for that metric.\n",
    "        \n",
    "        organ_class (str): For saving the figure, supply the name of the organ class\n",
    "        \n",
    "        separate (bool, optional): Whether we print each type of model type separately or\n",
    "        together so that for each metric we plot the models side by side for better\n",
    "        comparison. Defaults to False.\n",
    "\n",
    "        save (bool, optional): Whether to save the figure or not. Defaults to False.\n",
    "\n",
    "        showfliers (bool, optional): Whether to show the outliers in the boxplot. Defaults\n",
    "        to True.\n",
    "\n",
    "        table (bool, optional): Whether to show the table of mean metrics or not. Defaults\n",
    "        to True.\n",
    "\n",
    "        additional_title_context (str, optional): Additional context to add to the title\n",
    "        of the plot. Defaults to ''.\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def draw_table(metric_result, ax, model_type):\n",
    "        # Fetch statistics\n",
    "        mean = [np.mean(result) for result in metric_result]\n",
    "        std = [np.std(result) for result in metric_result]\n",
    "        median = [np.median(result) for result in metric_result]\n",
    "\n",
    "        # Format the table\n",
    "        cell_text = []\n",
    "        cell_text.append([f'{mean[i]:.2f}' for i in range(len(mean))])\n",
    "        cell_text.append([f'{std[i]:.2f}' for i in range(len(std))])\n",
    "        cell_text.append([f'{median[i]:.2f}' for i in range(len(std))])\n",
    "        rowLabels = [r'$\\hat{x}$', r'$\\sigma$', r'$med$']\n",
    "\n",
    "        import textwrap as twp\n",
    "        max_line_width = 15\n",
    "        colLabels = [twp.fill(label, max_line_width) for label in model_type]\n",
    "\n",
    "        # Plot the table\n",
    "        table_height = 0.05 * len(rowLabels)\n",
    "        ax_box = ax.get_position()\n",
    "        ax.set_position([ax_box.x0, ax_box.y0, ax_box.width, ax_box.height * (1 - table_height)])\n",
    "        #  bbox=[0., 1., 1., table_height / (1 - table_height)] the position before\n",
    "        table = ax.table(cell_text, cellLoc='center', rowLabels=rowLabels, colLabels=colLabels if not separate else None, fontsize=100) #, bbox=[0., 1., 1., table_height / (1 - table_height)] )\n",
    "        table.auto_set_font_size(False)\n",
    "        table.set_fontsize(9)\n",
    "        table.scale(1, 2)\n",
    "        \n",
    "\n",
    "    if separate and table:\n",
    "        print('[WARNING]: Bug with table printing in the separate mode. Set table=False to avoid this.')\n",
    "\n",
    "    augmented_metrics_dictionary = metrics_dictionary\n",
    "\n",
    "    # If we have medsam predictions, for now, plot the different axese separately\n",
    "    contains_medsam = ['MedSAM' in p or 'UniverSeg' in p for p in metrics_dictionary.keys()]\n",
    "    # heuristic to check if we've already done this shebang\n",
    "    # if sum([1 for p in contains_medsam if p]) <= 3:\n",
    "    if any(contains_medsam):\n",
    "        # go over each model type and extract the metrics for each axis\n",
    "\n",
    "        # extract the keys which are true out from the metrics_dictionary key set\n",
    "        extracted_values = [value for value, flag in zip(list(metrics_dictionary.keys()), contains_medsam) if flag]\n",
    "\n",
    "        for medsam_metric_type in extracted_values:\n",
    "\n",
    "            medsam_metrics = metrics_dictionary[medsam_metric_type]\n",
    "            if split_axis:\n",
    "                # Extract the metrics for each axis\n",
    "                set_of_processed_axis = set()\n",
    "                for metric in medsam_metrics.keys():\n",
    "                    set_of_processed_axis.update(medsam_metrics[metric].keys())\n",
    "                    for axis in medsam_metrics[metric].keys():\n",
    "                        if f'{medsam_metric_type} (axis{axis})' not in augmented_metrics_dictionary.keys():\n",
    "                            augmented_metrics_dictionary[f'{medsam_metric_type} (axis{axis})'] = dict()\n",
    "                        augmented_metrics_dictionary[f'{medsam_metric_type} (axis{axis})'][metric] = medsam_metrics[metric][axis]\n",
    "\n",
    "                del augmented_metrics_dictionary[medsam_metric_type]\n",
    "\n",
    "            # now include a global aggregate for each axis\n",
    "            augmented_metrics_dictionary[medsam_metric_type] = dict()\n",
    "            for metric in medsam_metrics.keys():\n",
    "                for axis in medsam_metrics[metric].keys():\n",
    "                    if metric not in augmented_metrics_dictionary[medsam_metric_type].keys():\n",
    "                        augmented_metrics_dictionary[medsam_metric_type][metric] = []\n",
    "                    augmented_metrics_dictionary[medsam_metric_type][metric] += medsam_metrics[metric][axis]\n",
    "\n",
    "    num_models = len(augmented_metrics_dictionary)\n",
    "\n",
    "    nrows = num_models if separate == True else 1\n",
    "    metrics_names = [list(augmented_metrics_dictionary[m].keys()) for m in augmented_metrics_dictionary.keys()]\n",
    "    metrics_names = sorted(list(set([metric for model_metrics in metrics_names for metric in model_metrics])))\n",
    "    ncols = len(metrics_names)\n",
    "\n",
    "    plot_height = 5*1.6\n",
    "    plot_width = 0.4 * max(4, num_models) * 1.6\n",
    "\n",
    "    fig, axes = plt.subplots(ncols=ncols, nrows=nrows, figsize=(plot_width * (ncols + num_models - 1), nrows * plot_height))\n",
    "\n",
    "    # Reshape axes to be a 2D array\n",
    "    axes = np.reshape(axes, (nrows, ncols))\n",
    "\n",
    "    for i, row in enumerate(axes):\n",
    "        for j, ax in enumerate(row):\n",
    "            # << Fetch Data Collections For Plotting >>\n",
    "\n",
    "            # Get the model type for printing. If we're not separating models, model_type\n",
    "            # is a list of all model names\n",
    "            model_type = list(augmented_metrics_dictionary.keys())[i] if separate else list(augmented_metrics_dictionary.keys())\n",
    "            # Get the metric type for the current column. Its possible that this metric\n",
    "            # doesn't exist for all models\n",
    "            metrics_type = metrics_names[j]\n",
    "            # Get the data for the current metric type while checking if it exists for the\n",
    "            # current model\n",
    "            getData = lambda m: augmented_metrics_dictionary[m][metrics_type] if metrics_type in augmented_metrics_dictionary[m].keys() else []\n",
    "            metric_result = getData(model_type) if separate else [getData(model) for model in augmented_metrics_dictionary.keys()]\n",
    "            \n",
    "            metric_result = [np.array(m) for m in metric_result]\n",
    "            metric_result = [m[~np.isnan(m)] for m in metric_result]\n",
    "            \n",
    "            # if len(metric_result.shape) == 1:\n",
    "            #     metric_result = metric_result[None, :]\n",
    "\n",
    "            # << Plot the Data >>\n",
    "\n",
    "            # ax.violinplot(metric_result)\n",
    "            ax.boxplot(metric_result, showfliers=showfliers, meanline=True, showmeans=True, patch_artist=True, widths=(.4))\n",
    "\n",
    "            # << Plot Table with Mean Metrics >>\n",
    "            \n",
    "            if table:\n",
    "                draw_table(np.reshape(metric_result, (1, -1)).tolist() if separate else metric_result, ax, model_type) \n",
    "\n",
    "            # << Axis Formatting >>\n",
    "\n",
    "            ax.set_title(metrics_type.capitalize(), fontsize='x-large') # y=1.02,\n",
    "            # TODO: Bug with separable mode. The x-axis labels are not being removed\n",
    "            ax.set_xticklabels([] if table else model_type, rotation=30) #  if not separate else model_type, rotation=30\n",
    "            ax.tick_params(axis='x', which='both', bottom=False)\n",
    "    \n",
    "    if separate:\n",
    "        for ax, title in zip(axes[:,0], augmented_metrics_dictionary.keys()):\n",
    "            ax.set_ylabel(title.capitalize(), fontsize='xx-large')\n",
    "    \n",
    "    # if organ class like Dataset000_classname, extract classname\n",
    "    import re\n",
    "    match = re.search(r'Dataset\\d+_(\\w+)', organ_class)\n",
    "    if match:\n",
    "        organ_class = match.group(1).lower()\n",
    "\n",
    "    fig.tight_layout()\n",
    "    # fig.set_facecolor('silver')\n",
    "    fig.suptitle(f'Segmentation metrics for the {organ_class.capitalize()} class {additional_title_context}', y=1, fontsize='xx-large', verticalalignment='center', horizontalalignment='center')  # Set the title of the whole plot\n",
    "    fig.subplots_adjust(top=0.88)  # Adjust the plot to make room for the title\n",
    "\n",
    "    # << Saving the Figure >>\n",
    "\n",
    "    if save: \n",
    "        number = max([0] + [get_id_from_path(fn, False) for fn in os.listdir('metrics/') if fn.startswith(f'metrics{organ_class}')])\n",
    "\n",
    "        file_name = lambda num: f'metrics{organ_class}_{f\"{num}_\"if num is not None else \"\"}{\"separated\" if separate else \"combined\"}_{\"_\".join(additional_title_context.split(\" \"))}.png'\n",
    "\n",
    "        try:\n",
    "            # Move the file\n",
    "            os.makedirs('metrics/old', exist_ok=True)\n",
    "            plt.savefig(f'metrics/{file_name(number + 1)}', bbox_inches='tight')\n",
    "            shutil.move(f'metrics/{file_name(number)}', f'metrics/old/')\n",
    "        except FileNotFoundError as e:\n",
    "            print(f'WARNING: {e}')\n",
    "    \n",
    "        plt.clf()\n",
    "    else:\n",
    "        plt.show()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "include_baseline = False\n",
    "include_nnUNet = False\n",
    "include_TotalSegmentator = False\n",
    "include_MedSAM = False\n",
    "include_UniverSeg = False\n",
    "include_global = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_metric_for_class(class_id: int):\n",
    "    \"\"\"Prints a plot of the segmentations for the given class in the predefined format.\n",
    "    This method acts in a factory pattern to generate the plot for each class. \n",
    "\n",
    "    Args:\n",
    "        class_id (int): 1: Anorectum ... 5: Parametrium\n",
    "    \"\"\"\n",
    "\n",
    "    setup_data_vars()\n",
    "\n",
    "    classes = [os.environ.get('Anorectum')\n",
    "             , os.environ.get('Bladder')\n",
    "             , os.environ.get('CTVn')\n",
    "             , os.environ.get('CTVp')\n",
    "             , os.environ.get('Parametrium')\n",
    "             , os.environ.get('Uterus')\n",
    "             , os.environ.get('Vagina')]\n",
    "\n",
    "    gt_labels = [os.path.join(os.environ.get('nnUNet_raw'), x, os.environ.get('data_trainingLabels')) for x in classes]\n",
    "    # gt_labels = [os.path.join(os.environ.get('nnUNet_'), x, 'nnUNetPlans_3d_fullres') for x in classes]\n",
    "    # print('WARNING: using old nnUNet predictions. Change to new path when complete')\n",
    "\n",
    "    anorectum = {\n",
    "        'nnUNet': os.path.join(os.environ.get('nnUNet_inference'), os.environ.get('Anorectum'), 'nnUNetTrainer_500epochs__nnUNetResEncUNetLPlans__3d_fullres'),\n",
    "        'nnUNet global': os.path.join(os.environ.get('nnUNet_inference'), os.environ.get('TotalBinary'), 'nnUNetTrainer_500epochs__nnUNetPlans__3d_fullres'),\n",
    "        'nnUNet global custom loss': os.path.join(os.environ.get('nnUNet_inference'), os.environ.get('TotalBinary'), 'nnUNetTrainerCervical_500epochs__nnUNetPlans__3d_fullres'),\n",
    "        'UniverSeg out-of-the-box': '/vol/biomedic3/bglocker/ugproj2324/az620/radiotherapy/research/source/code/UniverSeg/results/Anorectum',\n",
    "        'UniverSeg finetuned': '/vol/biomedic3/bglocker/ugproj2324/az620/radiotherapy/research/source/code/UniverSeg/results_finetuned/Anorectum',\n",
    "        'MedSAM boxed out-of-the-box': os.path.join(os.environ.get('MedSAM_finetuned'), 'boxed_lowres_2', 'Anorectum'),\n",
    "        'MedSAM boxed fine-tuned': os.path.join(os.environ.get('MedSAM_finetuned'), 'boxed_lowres_2', 'Anorectum'),\n",
    "        'total segmentator (fine-tuned)': os.path.join(os.environ.get('TotalSegmentator_inference'), os.environ.get('Anorectum'), 'nnUNetTrainer_250epochs__totseg_nnUNetPlans__3d_fullres'),\n",
    "        'total segmentator (fine-tuned) global': os.path.join(os.environ.get('TotalSegmentator_inference'), os.environ.get('TotalBinary'), 'nnUNetTrainer_500epochs__totseg_nnUNetPlans__3d_fullres'),\n",
    "        'total segmentator (fine-tuned) global custom loss': os.path.join(os.environ.get('TotalSegmentator_inference'), os.environ.get('TotalBinary'), 'nnUNetTrainerCervical_500epochs__totseg_nnUNetPlans__3d_fullres'),\n",
    "    }\n",
    "\n",
    "    bladder = {\n",
    "        'nnUNet': os.path.join(os.environ.get('nnUNet_inference'), os.environ.get('Bladder'), 'nnUNetTrainer_500epochs__nnUNetResEncUNetLPlans__3d_fullres'),\n",
    "        'nnUNet global': os.path.join(os.environ.get('nnUNet_inference'), os.environ.get('TotalBinary'), 'nnUNetTrainer_500epochs__nnUNetPlans__3d_fullres'),\n",
    "        'nnUNet global custom loss': os.path.join(os.environ.get('nnUNet_inference'), os.environ.get('TotalBinary'), 'nnUNetTrainerCervical_500epochs__nnUNetPlans__3d_fullres'),\n",
    "        'UniverSeg out-of-the-box': '/vol/biomedic3/bglocker/ugproj2324/az620/radiotherapy/research/source/code/UniverSeg/results/Bladder',\n",
    "        'MedSAM boxed out-of-the-box': os.path.join(os.environ.get('MedSAM_finetuned'), 'boxed_lowres_2', 'Bladder'),\n",
    "        'MedSAM fine-tuned': os.path.join(os.environ.get('MedSAM_finetuned'), 'boxed_lowres_2', 'Bladder'),\n",
    "        'total segmentator': os.path.join(os.environ.get('TotalSegmentator_inference'), os.environ.get('Bladder'), 'nnUNetTrainer__nnUNetPlans__3d_fullres'),\n",
    "        'total segmentator (fine-tuned)': os.path.join(os.environ.get('TotalSegmentator_inference'), os.environ.get('Bladder'), 'nnUNetTrainer_250epochs__totseg_nnUNetPlans__3d_fullres'),\n",
    "        'total segmentator (fine-tuned) global': os.path.join(os.environ.get('TotalSegmentator_inference'), os.environ.get('TotalBinary'), 'nnUNetTrainer_500epochs__totseg_nnUNetPlans__3d_fullres'),\n",
    "        'total segmentator (fine-tuned) global custom loss': os.path.join(os.environ.get('TotalSegmentator_inference'), os.environ.get('TotalBinary'), 'nnUNetTrainerCervical_500epochs__totseg_nnUNetPlans__3d_fullres'),\n",
    "    }\n",
    "\n",
    "    ctvn = {\n",
    "        'nnUNet': os.path.join(os.environ.get('nnUNet_inference'), os.environ.get('CTVn'), 'nnUNetTrainer_500epochs__nnUNetResEncUNetLPlans__3d_fullres'),\n",
    "        'nnUNet global': os.path.join(os.environ.get('nnUNet_inference'), os.environ.get('TotalBinary'), 'nnUNetTrainer_500epochs__nnUNetPlans__3d_fullres'),\n",
    "        'nnUNet global custom loss': os.path.join(os.environ.get('nnUNet_inference'), os.environ.get('TotalBinary'), 'nnUNetTrainerCervical_500epochs__nnUNetPlans__3d_fullres'),\n",
    "        'UniverSeg out-of-the-box': '/vol/biomedic3/bglocker/ugproj2324/az620/radiotherapy/research/source/code/UniverSeg/results/CTVn',\n",
    "        'MedSAM boxed out-of-the-box': os.path.join(os.environ.get('MedSAM_finetuned'), 'boxed_lowres_2', 'CTVn'),\n",
    "        'MedSAM fine-tuned': os.path.join(os.environ.get('MedSAM_finetuned'), 'boxed_lowres_2', 'CTVn'),\n",
    "        'total segmentator (fine-tuned)': os.path.join(os.environ.get('TotalSegmentator_inference'), os.environ.get('CTVn'), 'nnUNetTrainer_250epochs__totseg_nnUNetPlans__3d_fullres'),\n",
    "        'total segmentator (fine-tuned) global': os.path.join(os.environ.get('TotalSegmentator_inference'), os.environ.get('TotalBinary'), 'nnUNetTrainer_500epochs__totseg_nnUNetPlans__3d_fullres'),\n",
    "        'total segmentator (fine-tuned) global custom loss': os.path.join(os.environ.get('TotalSegmentator_inference'), os.environ.get('TotalBinary'), 'nnUNetTrainerCervical_500epochs__totseg_nnUNetPlans__3d_fullres'),\n",
    "    }\n",
    "\n",
    "    ctvp = {\n",
    "        'nnUNet': os.path.join(os.environ.get('nnUNet_inference'), os.environ.get('CTVp'), 'nnUNetTrainer_500epochs__nnUNetResEncUNetLPlans__3d_fullres'),\n",
    "        'nnUNet global': os.path.join(os.environ.get('nnUNet_inference'), os.environ.get('TotalBinary'), 'nnUNetTrainer_500epochs__nnUNetPlans__3d_fullres'),\n",
    "        'nnUNet global custom loss': os.path.join(os.environ.get('nnUNet_inference'), os.environ.get('TotalBinary'), 'nnUNetTrainerCervical_500epochs__nnUNetPlans__3d_fullres'),\n",
    "        'UniverSeg out-of-the-box': '/vol/biomedic3/bglocker/ugproj2324/az620/radiotherapy/research/source/code/UniverSeg/results/CTVp',\n",
    "        'MedSAM boxed out-of-the-box': os.path.join(os.environ.get('MedSAM_finetuned'), 'boxed_lowres_2', 'CTVp'),\n",
    "        'MedSAM fine-tuned': os.path.join(os.environ.get('MedSAM_finetuned'), 'boxed_lowres_2', 'CTVp'),\n",
    "        'total segmentator (fine-tuned)': os.path.join(os.environ.get('TotalSegmentator_inference'), os.environ.get('CTVp'), 'nnUNetTrainer_250epochs__totseg_nnUNetPlans__3d_fullres'),\n",
    "        'total segmentator (fine-tuned) global': os.path.join(os.environ.get('TotalSegmentator_inference'), os.environ.get('TotalBinary'), 'nnUNetTrainer_500epochs__totseg_nnUNetPlans__3d_fullres'),\n",
    "        'total segmentator (fine-tuned) global custom loss': os.path.join(os.environ.get('TotalSegmentator_inference'), os.environ.get('TotalBinary'), 'nnUNetTrainerCervical_500epochs__totseg_nnUNetPlans__3d_fullres'),\n",
    "    }\n",
    "\n",
    "    parametrium = {\n",
    "        'nnUNet': os.path.join(os.environ.get('nnUNet_inference'), os.environ.get('Parametrium'), 'nnUNetTrainer_500epochs__nnUNetResEncUNetLPlans__3d_fullres'),\n",
    "        'nnUNet global': os.path.join(os.environ.get('nnUNet_inference'), os.environ.get('TotalBinary'), 'nnUNetTrainer_500epochs__nnUNetPlans__3d_fullres'),\n",
    "        'nnUNet global custom loss': os.path.join(os.environ.get('nnUNet_inference'), os.environ.get('TotalBinary'), 'nnUNetTrainerCervical_500epochs__nnUNetPlans__3d_fullres'),\n",
    "        'UniverSeg out-of-the-box': '/vol/biomedic3/bglocker/ugproj2324/az620/radiotherapy/research/source/code/UniverSeg/results/Parametrium',\n",
    "        'MedSAM boxed out-of-the-box': os.path.join(os.environ.get('MedSAM_finetuned'), 'boxed_lowres_2', 'Parametrium'),\n",
    "        'MedSAM fine-tuned': os.path.join(os.environ.get('MedSAM_finetuned'), 'boxed_lowres_2', 'Parametrium'),\n",
    "        'total segmentator (fine-tuned)': os.path.join(os.environ.get('TotalSegmentator_inference'), os.environ.get('Parametrium'), 'nnUNetTrainer_250epochs__totseg_nnUNetPlans__3d_fullres'),\n",
    "        'total segmentator (fine-tuned) global': os.path.join(os.environ.get('TotalSegmentator_inference'), os.environ.get('TotalBinary'), 'nnUNetTrainer_500epochs__totseg_nnUNetPlans__3d_fullres'),\n",
    "        'total segmentator (fine-tuned) global custom loss': os.path.join(os.environ.get('TotalSegmentator_inference'), os.environ.get('TotalBinary'), 'nnUNetTrainerCervical_500epochs__totseg_nnUNetPlans__3d_fullres'),\n",
    "    }\n",
    "\n",
    "    uterus = {\n",
    "        'nnUNet': os.path.join(os.environ.get('nnUNet_inference'), os.environ.get('Uterus'), 'nnUNetTrainer_500epochs__nnUNetResEncUNetLPlans__3d_fullres'),\n",
    "        'nnUNet global': os.path.join(os.environ.get('nnUNet_inference'), os.environ.get('TotalBinary'), 'nnUNetTrainer_500epochs__nnUNetPlans__3d_fullres'),\n",
    "        'nnUNet global custom loss': os.path.join(os.environ.get('nnUNet_inference'), os.environ.get('TotalBinary'), 'nnUNetTrainerCervical_500epochs__nnUNetPlans__3d_fullres'),\n",
    "        'UniverSeg out-of-the-box': '/vol/biomedic3/bglocker/ugproj2324/az620/radiotherapy/research/source/code/UniverSeg/results/Uterus',\n",
    "        'MedSAM boxed out-of-the-box': os.path.join(os.environ.get('MedSAM_finetuned'), 'boxed_lowres_2', 'Uterus'),\n",
    "        'MedSAM fine-tuned': os.path.join(os.environ.get('MedSAM_finetuned'), 'boxed_lowres_2', 'Uterus'),\n",
    "        'total segmentator (fine-tuned)': os.path.join(os.environ.get('TotalSegmentator_inference'), os.environ.get('Uterus'), 'nnUNetTrainer_250epochs__totseg_nnUNetPlans__3d_fullres'),\n",
    "        'total segmentator (fine-tuned) global': os.path.join(os.environ.get('TotalSegmentator_inference'), os.environ.get('TotalBinary'), 'nnUNetTrainer_500epochs__totseg_nnUNetPlans__3d_fullres'),\n",
    "        'total segmentator (fine-tuned) global custom loss': os.path.join(os.environ.get('TotalSegmentator_inference'), os.environ.get('TotalBinary'), 'nnUNetTrainerCervical_500epochs__totseg_nnUNetPlans__3d_fullres'),\n",
    "    }\n",
    "\n",
    "    vagina = {\n",
    "        'nnUNet': os.path.join(os.environ.get('nnUNet_inference'), os.environ.get('Vagina'), 'nnUNetTrainer_500epochs__nnUNetResEncUNetLPlans__3d_fullres'),\n",
    "        'nnUNet global': os.path.join(os.environ.get('nnUNet_inference'), os.environ.get('TotalBinary'), 'nnUNetTrainer_500epochs__nnUNetPlans__3d_fullres'),\n",
    "        'nnUNet global custom loss': os.path.join(os.environ.get('nnUNet_inference'), os.environ.get('TotalBinary'), 'nnUNetTrainerCervical_500epochs__nnUNetPlans__3d_fullres'),\n",
    "        'UniverSeg out-of-the-box': '/vol/biomedic3/bglocker/ugproj2324/az620/radiotherapy/research/source/code/UniverSeg/results/Vagina',\n",
    "        'MedSAM boxed out-of-the-box': os.path.join(os.environ.get('MedSAM_finetuned'), 'boxed_lowres_2', 'Vagina'),\n",
    "        'MedSAM fine-tuned': os.path.join(os.environ.get('MedSAM_finetuned'), 'boxed_lowres_2', 'Vagina'),\n",
    "        'total segmentator (fine-tuned)': os.path.join(os.environ.get('TotalSegmentator_inference'), os.environ.get('Vagina'), 'nnUNetTrainer_250epochs__totseg_nnUNetPlans__3d_fullres'),\n",
    "        'total segmentator (fine-tuned) global': os.path.join(os.environ.get('TotalSegmentator_inference'), os.environ.get('TotalBinary'), 'nnUNetTrainer_500epochs__totseg_nnUNetPlans__3d_fullres'),\n",
    "        'total segmentator (fine-tuned) global custom loss': os.path.join(os.environ.get('TotalSegmentator_inference'), os.environ.get('TotalBinary'), 'nnUNetTrainerCervical_500epochs__totseg_nnUNetPlans__3d_fullres'),\n",
    "    }\n",
    "\n",
    "    predictions = [anorectum, bladder, ctvn, ctvp, parametrium, uterus, vagina]\n",
    "\n",
    "    if 1 <= class_id <= len(predictions):\n",
    "\n",
    "        prediction = dict()\n",
    "\n",
    "        for k in predictions[class_id - 1].keys():\n",
    "            if ('nnUNet' == k and include_baseline) or\\\n",
    "               ('nnUNet' in k and 'global' not in k and include_nnUNet) or\\\n",
    "               ('total segmentator' in k and 'global' not in k and include_TotalSegmentator) or\\\n",
    "               ('MedSAM' in k and include_MedSAM) or\\\n",
    "               ('UniverSeg' in k and include_UniverSeg) or\\\n",
    "               ('global' in k and include_global):\n",
    "                prediction[k] =  predictions[class_id - 1][k]   \n",
    "\n",
    "        return calculate_metrics(gt_labels[class_id - 1], prediction, class_id - 1)\n",
    "    raise ValueError(\"Invalid class_id. Please choose a class between 1 and 5.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting Section"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot for MedSAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "save = True\n",
    "separate = False\n",
    "table = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching metrics for  Dataset001_Anorectum  id  1\n",
      "Calculating metrics for  nnUNet\n",
      "WARNING: [Errno 2] No such file or directory: 'metrics/metricsanorectum_0_combined_MedSAM_analysis.png'\n",
      "Fetching metrics for  Dataset002_Bladder  id  2\n",
      "Calculating metrics for  nnUNet\n",
      "WARNING: [Errno 2] No such file or directory: 'metrics/metricsbladder_0_combined_MedSAM_analysis.png'\n",
      "Fetching metrics for  Dataset003_CTVn  id  3\n",
      "Calculating metrics for  nnUNet\n",
      "WARNING: [Errno 2] No such file or directory: 'metrics/metricsctvn_0_combined_MedSAM_analysis.png'\n",
      "Fetching metrics for  Dataset004_CTVp  id  4\n",
      "Calculating metrics for  nnUNet\n",
      "WARNING: [Errno 2] No such file or directory: 'metrics/metricsctvp_0_combined_MedSAM_analysis.png'\n",
      "Fetching metrics for  Dataset005_Parametrium  id  5\n",
      "Calculating metrics for  nnUNet\n",
      "WARNING: [Errno 2] No such file or directory: 'metrics/metricsparametrium_0_combined_MedSAM_analysis.png'\n",
      "Fetching metrics for  Dataset006_Uterus  id  6\n",
      "Calculating metrics for  nnUNet\n",
      "WARNING: [Errno 2] No such file or directory: 'metrics/metricsuterus_0_combined_MedSAM_analysis.png'\n",
      "Fetching metrics for  Dataset007_Vagina  id  7\n",
      "Calculating metrics for  nnUNet\n",
      "WARNING: [Errno 2] No such file or directory: 'metrics/metricsvagina_0_combined_MedSAM_analysis.png'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1792x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1792x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1792x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1792x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1792x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1792x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1792x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "include_baseline = True\n",
    "include_nnUNet = False\n",
    "include_TotalSegmentator = False\n",
    "include_MedSAM = True\n",
    "include_UniverSeg = False\n",
    "include_global = False\n",
    "\n",
    "split_axis = False\n",
    "\n",
    "for c in [\n",
    "             os.environ.get('Anorectum'),\n",
    "             os.environ.get('Bladder'),\n",
    "             os.environ.get('CTVn'),\n",
    "             os.environ.get('CTVp'),\n",
    "             os.environ.get('Parametrium'),\n",
    "             os.environ.get('Uterus'),\n",
    "             os.environ.get('Vagina'),\n",
    "             ]:\n",
    "    id = int(c.split('_')[0][len('Dataset'):])\n",
    "    print('Fetching metrics for ', c, ' id ', id)\n",
    "    metrics = fetch_metric_for_class(id)\n",
    "    plot_metrics(metrics, c, save=save, separate=separate, table=table, showfliers=False, additional_title_context='MedSAM analysis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching metrics for  Dataset001_Anorectum  id  1\n",
      "Calculating metrics for  nnUNet\n",
      "WARNING: [Errno 2] No such file or directory: 'metrics/metricsanorectum_1_combined_MedSAM_split_analysis.png'\n",
      "Fetching metrics for  Dataset002_Bladder  id  2\n",
      "Calculating metrics for  nnUNet\n",
      "WARNING: [Errno 2] No such file or directory: 'metrics/metricsbladder_1_combined_MedSAM_split_analysis.png'\n",
      "Fetching metrics for  Dataset003_CTVn  id  3\n",
      "Calculating metrics for  nnUNet\n",
      "WARNING: [Errno 2] No such file or directory: 'metrics/metricsctvn_1_combined_MedSAM_split_analysis.png'\n",
      "Fetching metrics for  Dataset004_CTVp  id  4\n",
      "Calculating metrics for  nnUNet\n",
      "WARNING: [Errno 2] No such file or directory: 'metrics/metricsctvp_1_combined_MedSAM_split_analysis.png'\n",
      "Fetching metrics for  Dataset005_Parametrium  id  5\n",
      "Calculating metrics for  nnUNet\n",
      "WARNING: [Errno 2] No such file or directory: 'metrics/metricsparametrium_1_combined_MedSAM_split_analysis.png'\n",
      "Fetching metrics for  Dataset006_Uterus  id  6\n",
      "Calculating metrics for  nnUNet\n",
      "WARNING: [Errno 2] No such file or directory: 'metrics/metricsuterus_1_combined_MedSAM_split_analysis.png'\n",
      "Fetching metrics for  Dataset007_Vagina  id  7\n",
      "Calculating metrics for  nnUNet\n",
      "WARNING: [Errno 2] No such file or directory: 'metrics/metricsvagina_1_combined_MedSAM_split_analysis.png'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 7488x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 7488x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 7488x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 7488x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 7488x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 7488x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 7488x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "include_baseline = True\n",
    "include_nnUNet = False\n",
    "include_TotalSegmentator = False\n",
    "include_MedSAM = True\n",
    "include_UniverSeg = False\n",
    "include_global = False\n",
    "\n",
    "split_axis = True\n",
    "\n",
    "for c in [\n",
    "             os.environ.get('Anorectum'),\n",
    "             os.environ.get('Bladder'),\n",
    "             os.environ.get('CTVn'),\n",
    "             os.environ.get('CTVp'),\n",
    "             os.environ.get('Parametrium'),\n",
    "             os.environ.get('Uterus'),\n",
    "             os.environ.get('Vagina'),\n",
    "             ]:\n",
    "    id = int(c.split('_')[0][len('Dataset'):])\n",
    "    print('Fetching metrics for ', c, ' id ', id)\n",
    "    metrics = fetch_metric_for_class(id)\n",
    "    plot_metrics(metrics, c, save=save, separate=separate, table=table, showfliers=False, additional_title_context='MedSAM split analysis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UniverSeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching metrics for  Dataset001_Anorectum  id  1\n",
      "Calculating metrics for  nnUNet\n",
      "[WARNING]: There should be 3 axis in the model path, got [0]\n",
      "WARNING: [Errno 2] No such file or directory: 'metrics/metricsanorectum_2_combined_UniverSeg_analysis.png'\n",
      "Fetching metrics for  Dataset002_Bladder  id  2\n",
      "Calculating metrics for  nnUNet\n",
      "WARNING: [Errno 2] No such file or directory: 'metrics/metricsbladder_2_combined_UniverSeg_analysis.png'\n",
      "Fetching metrics for  Dataset003_CTVn  id  3\n",
      "Calculating metrics for  nnUNet\n",
      "WARNING: [Errno 2] No such file or directory: 'metrics/metricsctvn_2_combined_UniverSeg_analysis.png'\n",
      "Fetching metrics for  Dataset004_CTVp  id  4\n",
      "Calculating metrics for  nnUNet\n",
      "WARNING: [Errno 2] No such file or directory: 'metrics/metricsctvp_2_combined_UniverSeg_analysis.png'\n",
      "Fetching metrics for  Dataset005_Parametrium  id  5\n",
      "Calculating metrics for  nnUNet\n",
      "WARNING: [Errno 2] No such file or directory: 'metrics/metricsparametrium_2_combined_UniverSeg_analysis.png'\n",
      "Fetching metrics for  Dataset006_Uterus  id  6\n",
      "Calculating metrics for  nnUNet\n",
      "WARNING: [Errno 2] No such file or directory: 'metrics/metricsuterus_2_combined_UniverSeg_analysis.png'\n",
      "Fetching metrics for  Dataset007_Vagina  id  7\n",
      "Calculating metrics for  nnUNet\n",
      "WARNING: [Errno 2] No such file or directory: 'metrics/metricsvagina_2_combined_UniverSeg_analysis.png'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1792x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1536x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1536x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1536x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1536x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1536x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1536x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "include_baseline = True\n",
    "include_nnUNet = False\n",
    "include_TotalSegmentator = False\n",
    "include_MedSAM = False\n",
    "include_UniverSeg = True\n",
    "include_global = False\n",
    "\n",
    "split_axis = False\n",
    "\n",
    "for c in [\n",
    "             os.environ.get('Anorectum'),\n",
    "             os.environ.get('Bladder'),\n",
    "             os.environ.get('CTVn'),\n",
    "             os.environ.get('CTVp'),\n",
    "             os.environ.get('Parametrium'),\n",
    "             os.environ.get('Uterus'),\n",
    "             os.environ.get('Vagina'),\n",
    "             ]:\n",
    "    id = int(c.split('_')[0][len('Dataset'):])\n",
    "    print('Fetching metrics for ', c, ' id ', id)\n",
    "    metrics = fetch_metric_for_class(id)\n",
    "    plot_metrics(metrics, c, save=save, separate=separate, table=table, showfliers=False, additional_title_context='UniverSeg analysis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching metrics for  Dataset001_Anorectum  id  1\n",
      "Calculating metrics for  nnUNet\n",
      "[WARNING]: There should be 3 axis in the model path, got [0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/vol/biomedic3/bglocker/ugproj2324/az620/radiotherapy/.venv/lib/python3.10/site-packages/numpy/core/fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/vol/biomedic3/bglocker/ugproj2324/az620/radiotherapy/.venv/lib/python3.10/site-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/vol/biomedic3/bglocker/ugproj2324/az620/radiotherapy/.venv/lib/python3.10/site-packages/numpy/core/_methods.py:206: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/vol/biomedic3/bglocker/ugproj2324/az620/radiotherapy/.venv/lib/python3.10/site-packages/numpy/core/_methods.py:163: RuntimeWarning: invalid value encountered in divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean,\n",
      "/vol/biomedic3/bglocker/ugproj2324/az620/radiotherapy/.venv/lib/python3.10/site-packages/numpy/core/_methods.py:198: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/vol/biomedic3/bglocker/ugproj2324/az620/radiotherapy/.venv/lib/python3.10/site-packages/numpy/core/fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/vol/biomedic3/bglocker/ugproj2324/az620/radiotherapy/.venv/lib/python3.10/site-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/vol/biomedic3/bglocker/ugproj2324/az620/radiotherapy/.venv/lib/python3.10/site-packages/numpy/core/_methods.py:206: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/vol/biomedic3/bglocker/ugproj2324/az620/radiotherapy/.venv/lib/python3.10/site-packages/numpy/core/_methods.py:163: RuntimeWarning: invalid value encountered in divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean,\n",
      "/vol/biomedic3/bglocker/ugproj2324/az620/radiotherapy/.venv/lib/python3.10/site-packages/numpy/core/_methods.py:198: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/vol/biomedic3/bglocker/ugproj2324/az620/radiotherapy/.venv/lib/python3.10/site-packages/numpy/core/fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/vol/biomedic3/bglocker/ugproj2324/az620/radiotherapy/.venv/lib/python3.10/site-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/vol/biomedic3/bglocker/ugproj2324/az620/radiotherapy/.venv/lib/python3.10/site-packages/numpy/core/_methods.py:206: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/vol/biomedic3/bglocker/ugproj2324/az620/radiotherapy/.venv/lib/python3.10/site-packages/numpy/core/_methods.py:163: RuntimeWarning: invalid value encountered in divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean,\n",
      "/vol/biomedic3/bglocker/ugproj2324/az620/radiotherapy/.venv/lib/python3.10/site-packages/numpy/core/_methods.py:198: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/vol/biomedic3/bglocker/ugproj2324/az620/radiotherapy/.venv/lib/python3.10/site-packages/numpy/core/fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/vol/biomedic3/bglocker/ugproj2324/az620/radiotherapy/.venv/lib/python3.10/site-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/vol/biomedic3/bglocker/ugproj2324/az620/radiotherapy/.venv/lib/python3.10/site-packages/numpy/core/_methods.py:206: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/vol/biomedic3/bglocker/ugproj2324/az620/radiotherapy/.venv/lib/python3.10/site-packages/numpy/core/_methods.py:163: RuntimeWarning: invalid value encountered in divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean,\n",
      "/vol/biomedic3/bglocker/ugproj2324/az620/radiotherapy/.venv/lib/python3.10/site-packages/numpy/core/_methods.py:198: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/vol/biomedic3/bglocker/ugproj2324/az620/radiotherapy/.venv/lib/python3.10/site-packages/numpy/core/fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/vol/biomedic3/bglocker/ugproj2324/az620/radiotherapy/.venv/lib/python3.10/site-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/vol/biomedic3/bglocker/ugproj2324/az620/radiotherapy/.venv/lib/python3.10/site-packages/numpy/core/_methods.py:206: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/vol/biomedic3/bglocker/ugproj2324/az620/radiotherapy/.venv/lib/python3.10/site-packages/numpy/core/_methods.py:163: RuntimeWarning: invalid value encountered in divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean,\n",
      "/vol/biomedic3/bglocker/ugproj2324/az620/radiotherapy/.venv/lib/python3.10/site-packages/numpy/core/_methods.py:198: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: [Errno 2] No such file or directory: 'metrics/metricsanorectum_3_combined_UniverSeg_split_analysis.png'\n",
      "Fetching metrics for  Dataset002_Bladder  id  2\n",
      "Calculating metrics for  nnUNet\n",
      "WARNING: [Errno 2] No such file or directory: 'metrics/metricsbladder_3_combined_UniverSeg_split_analysis.png'\n",
      "Fetching metrics for  Dataset003_CTVn  id  3\n",
      "Calculating metrics for  nnUNet\n",
      "WARNING: [Errno 2] No such file or directory: 'metrics/metricsctvn_3_combined_UniverSeg_split_analysis.png'\n",
      "Fetching metrics for  Dataset004_CTVp  id  4\n",
      "Calculating metrics for  nnUNet\n",
      "WARNING: [Errno 2] No such file or directory: 'metrics/metricsctvp_3_combined_UniverSeg_split_analysis.png'\n",
      "Fetching metrics for  Dataset005_Parametrium  id  5\n",
      "Calculating metrics for  nnUNet\n",
      "WARNING: [Errno 2] No such file or directory: 'metrics/metricsparametrium_3_combined_UniverSeg_split_analysis.png'\n",
      "Fetching metrics for  Dataset006_Uterus  id  6\n",
      "Calculating metrics for  nnUNet\n",
      "WARNING: [Errno 2] No such file or directory: 'metrics/metricsuterus_3_combined_UniverSeg_split_analysis.png'\n",
      "Fetching metrics for  Dataset007_Vagina  id  7\n",
      "Calculating metrics for  nnUNet\n",
      "WARNING: [Errno 2] No such file or directory: 'metrics/metricsvagina_3_combined_UniverSeg_split_analysis.png'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 7488x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 2880x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 2880x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 2880x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 2880x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 2880x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 2880x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "include_baseline = True\n",
    "include_nnUNet = False\n",
    "include_TotalSegmentator = False\n",
    "include_MedSAM = False\n",
    "include_UniverSeg = True\n",
    "\n",
    "split_axis = True\n",
    "\n",
    "for c in [\n",
    "             os.environ.get('Anorectum'),\n",
    "             os.environ.get('Bladder'),\n",
    "             os.environ.get('CTVn'),\n",
    "             os.environ.get('CTVp'),\n",
    "             os.environ.get('Parametrium'),\n",
    "             os.environ.get('Uterus'),\n",
    "             os.environ.get('Vagina'),\n",
    "             ]:\n",
    "    id = int(c.split('_')[0][len('Dataset'):])\n",
    "    print('Fetching metrics for ', c, ' id ', id)\n",
    "    metrics = fetch_metric_for_class(id)\n",
    "    plot_metrics(metrics, c, save=save, separate=separate, table=table, showfliers=False, additional_title_context='UniverSeg split analysis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TotalSegmentator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching metrics for  Dataset001_Anorectum  id  1\n",
      "Calculating metrics for  nnUNet\n",
      "Calculating metrics for  total segmentator (fine-tuned)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]/tmp/ipykernel_376852/2679383285.py:45: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([df, new_record], ignore_index=True)\n",
      " 57%|█████▋    | 57/100 [02:51<02:16,  3.18s/it]"
     ]
    }
   ],
   "source": [
    "include_baseline = True\n",
    "include_nnUNet = False\n",
    "include_TotalSegmentator = True\n",
    "include_MedSAM = False\n",
    "include_UniverSeg = False\n",
    "include_global = False\n",
    "\n",
    "split_axis = False\n",
    "\n",
    "for c in [\n",
    "             os.environ.get('Anorectum'),\n",
    "             os.environ.get('Bladder'),\n",
    "             os.environ.get('CTVn'),\n",
    "             os.environ.get('CTVp'),\n",
    "             os.environ.get('Parametrium'),\n",
    "             os.environ.get('Uterus'),\n",
    "             os.environ.get('Vagina'),\n",
    "             ]:\n",
    "    id = int(c.split('_')[0][len('Dataset'):])\n",
    "    print('Fetching metrics for ', c, ' id ', id)\n",
    "    metrics = fetch_metric_for_class(id)\n",
    "    plot_metrics(metrics, c, save=save, separate=separate, table=table, showfliers=False, additional_title_context='TotalSegmentator analysis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TotalBinary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "include_baseline = True\n",
    "include_nnUNet = False\n",
    "include_TotalSegmentator = False\n",
    "include_MedSAM = False\n",
    "include_UniverSeg = False\n",
    "include_global = True\n",
    "\n",
    "split_axis = True\n",
    "\n",
    "for c in [\n",
    "             os.environ.get('Anorectum'),\n",
    "             os.environ.get('Bladder'),\n",
    "             os.environ.get('CTVn'),\n",
    "             os.environ.get('CTVp'),\n",
    "             os.environ.get('Parametrium'),\n",
    "             os.environ.get('Uterus'),\n",
    "             os.environ.get('Vagina'),\n",
    "             ]:\n",
    "    id = int(c.split('_')[0][len('Dataset'):])\n",
    "    print('Fetching metrics for ', c, ' id ', id)\n",
    "    metrics = fetch_metric_for_class(id)\n",
    "    plot_metrics(metrics, c, save=save, separate=separate, table=table, showfliers=False, additional_title_context='TotalSegmentator analysis')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
