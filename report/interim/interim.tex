\documentclass[11pt,twoside]{report}

% some definitions for the title page
\newcommand{\reporttitle}{Transfer Learning for Deep Learning Radiotherapy Planning applied to Cervical Cancer}
\newcommand{\reportauthor}{Anton Zhitomirsky}
\newcommand{\supervisor}{Ben Glocker}
\newcommand{\secondMarker}{TODO}
\newcommand{\reporttype}{MEng Individual Project}

\usepackage{pifont,mdframed}
\newenvironment{warning}
  {\par\begin{mdframed}[linewidth=1pt,linecolor=black]%
    \begin{list}{}{\leftmargin=1cm
                   \labelwidth=\leftmargin}\item[\Large\ding{43}]}
  {\end{list}\end{mdframed}\par}

% load some definitions and default packages
\input{../.latex-templates/includes}

% load some macros
\input{../.latex-templates/notation}

\addbibresource{../../research/source/bibliography.bib}


% load title page
\begin{document}
\input{../.latex-templates/titlepage}


% page numbering etc.
\pagenumbering{roman}
\clearpage{\pagestyle{empty}\cleardoublepage}
\setcounter{page}{1}
\pagestyle{fancy}

% \cleardoublepage
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \section*{Acknowledgments}
% Comment this out if not needed.

% \clearpage{\pagestyle{empty}\cleardoublepage}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



\begin{abstract} \label{sect:abstract}

  \begin{warning}
    First draft of abstract
  \end{warning}
  
  Clinicians target cancerous tumours by studying 3D contrasting images of cancerous tumours and surrounding soft tissues to plan targets for radiation therapy. The Royal Marsden Hospital is a key contributor of data for this project, which uses this approach to delineate tumours for cervical cancers. Typically after a gross tumour volume (GTV) is extrapolated from the relevant imaging modality, clinicians append tailored safety margins to also account for the microscopic cancerous spreads not visible in the scan to generate the planned target volume (PTV).

  The PTV area has to be generous enough to attempt to treat the problem in one-shot, yet conservative enough to not harm surrounding healthy tissue with radiation over the course of the treatment. Compounded with small sample size of labelled data this proposes a significant challenge for developing deep-learning segmentation models to identify an optimal PTV.

  Thus we propose a transfer learning strategy to utilize imaging models in similar domains to attempt to learn from the limited input size to provide clinicians with a faster and more accurate segmentation method.
\end{abstract}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%--- table of contents
% \fancyhead[RE,LO]{\sffamily {Table of Contents}}
\tableofcontents


\clearpage{\pagestyle{empty}\cleardoublepage}
\pagenumbering{arabic}
\setcounter{page}{1}
\fancyhead[LE,RO]{\slshape \rightmark}
\fancyhead[LO,RE]{\slshape \leftmark}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Introduction} \label{sect:intro}

\section{Clinical Context} \label{sect:clinical-context-summary}
% the problem is not trivial of outlining a mass on a scan, there is also an area of non-zero probability that the tumour has spread around microscopically. Need to make sure 

\section{Motivation}\label{sect:motivation}
% Auto contouring vs Auto Segmentation?

\section{Current Solutions}\label{sect:current-solutions}
% 

\section{Outline of Report}\label{sect:outline-of-report}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Background}\label{sect:background}

\section{Clinical Context}\label{sect:clinical-context}

``To administer radiotherapy we need to identify target structures and structures we want to protect (organs-at-risk). These all need to be delineated on each slice of a CT scan, so the amount of radiation planned to reach each area can be calculated and checked.

The clinical target volume is the area where there is likely microscopic cancer and this area needs to receive sufficient radiation doses to achieve cancer cure. As microscopic cancer cannot be seen on CT, the clinical target volume is not an obvious structure that can be drawn around. The CTV is however constructed based on an Oncologist's knowledge of where each particular cancer is likely to spread to. It is drawn based on guidelines, atlases and clinical information. There are currently no internationally agreed guidelines for exactly how the clinical target volume should be drawn for cervix cancer and practice varies. Practice varies based on how the individual components of the CTV are labelled and this in theory could make it difficult for an AI model to learn patterns (or to generate large quantities of similar quality training data).

For the purpose of reproducibility, all scans in this training data have been labelled consistently, to see if an AI model can learn cervical cancer CTV pattern detection. Clinical decisions also affect how many structures are included in the CTV and an AI model is not likely to be able to make these decisions. An AI model is therefore unlikely to be able to produce a perfect CTV for treatment and a clinician will have to select which components of the CTV are required. Training models capable of producing the substructures needed within the CTV that a clinician can select from could still overall save time and improve consistency within the radiotherapy planning process.
''

\section{Vanilla Image Segmentation Models}\label{sect:vanilla-image-segmentation-models}

\subsection{Convolutional Neural Networks (CNN)}\label{sect:CNNs}

\subsection{U-Net}\label{sect:u-net}

\subsection{nnU-Net}\label{sect:nnu-net}

\subsection{Traditional Limitations}\label{sect:vanilla-limitations}

\section{Existing Auto-Segmentation Methods}\label{sect:existing-auto-segmentation-methods}

\subsection{Total Segmentator}\label{sect:totalseg}

\subsection{UniverSeg}\label{sect:universeg}

\subsection{SAM}\label{sect:sam}

\section{Transfer Learning}\label{sect:transfer-learning}

\subsection{Intuition}\label{sect:transfer-learning-intuition}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Data}\label{sect:data}

The data is acquired during a CT scan (Section \ref{sec:data-ct-scan}) and presented as a set of \texttt{NIfTI} (Section \ref{sec:data-file-format}) files provided by the Royal Marsden Hospital. The data is of 100 patients each with a variant of cervical cancer. We have obtained from the hospital a spreadsheet with additional notes about each patient which may be useful in training and debugging (Section \ref{sec:data-notes}). Finally, this data is labelled into 5 different classes as a binary segmentation problem (Section \ref{sec:data-delineation-classes}). Included is a set of 10 hold-out data items, which are patients with only the raw CT scan with no labels.

\section{CT scan}\label{sec:data-ct-scan}

Before we consider other aspects of the data it is helpful to consider the context from which it was extracted and therefore what we might expect to see. This data is in CT scan, and so will be the focus, although there exist other imaging modalities such as Magnetic Resonance Imaging (MRI) and others.

A CT Scan is an X-ray study, where a series of rays are rotated around a specified body part, and computer-generated cross-sectional images are produced~\cite{file-formats}. The granularity or image slice thickness is decided by the operator or physician and ranges from 1mm to 10mm. Whilst the scanner rotates the X-ray tube the patient is slowly moved up or down in the table to produce different cross-section images. 
 
We therefore expect to receive a representation of the internal structure or functions of an atomic region in the form of an array of voxels. A voxel represents the value on a grid in three-dimensional space and is decided by the physician once they establish the slice thickness.

\section{File Format}\label{sec:data-file-format}

The files are stored in a \texttt{.nii} file format which defines a style of image called the `Neuroimaging Informatics Technology Initiative' (NIfTI)~\cite{file-formats}. It serves as a lightweight alternative to other formats such as DICOM and eliminates ambiguity from spatial orientation information~\cite{dicom-to-nifti-conversion}.

The file has a fixed-size header which stores information about the data collected. Table \ref{tab:nifti-header} summarizes some key attributes of the header. All other attributes not listed are handled by the SimpleITK library~\cite{SimpleITK-paper} which we use to read and manipulate the data in this project. The library defines the image as a set of points in a grid occupying a physical region in space as defined by this metadata, and therefore is influenced by the origin, size, spacing and so on. 

\begin{table}[ht]
  \centering
  \begin{tabular}{>{\raggedright}p{1.5cm}p{8cm}p{4cm}}
      \toprule
      \textbf{Name} & \textbf{Meaning} & \textbf{Value example} \\
      \midrule
      dim & Image dimension & 3 512 512 193 1 1 1 1 \\
      bitpix & Number of bits per voxel & 32 \\
      pixdim & The grid spacing (voxel size) and optionally time interval & 0 1.3 1.3 2.5 0 0 0 0 \\
      xyzt\_units & indicates units of pixdim and defined in the C header, e.g. \texttt{NIFTI\_UNITS\_MM = 2} & 2 \\
      \bottomrule
  \end{tabular}
  \caption{Description of NIfTI header parameters relevant to this project~\cite{dicom-to-nifti-conversion, nifti-headers, nifti-data-format}. Example values are taken from patient id:075.}
  \label{tab:nifti-header}
\end{table}

\section{Notes}\label{sec:data-notes}

The notes contain information about each of the 100 labelled data pairs~\cite{AMLART-data}. This information can be helpful in debugging or troubleshooting. It also provides a good warning regarding the variability of the data. In particular some aspects to note are summarized in Table \ref{tab:notes-summary}.

\begin{table}[ht]
  \centering
  \begin{tabular}{>{\raggedright}p{3cm}p{6cm}p{6cm}}
      \toprule
      \textbf{Patient ID} & \textbf{Comment} & \textbf{Concern} \\
      \midrule
      zzAMLART003 & ``no GTVp'' & Some scans contain no visible tumour, but we still draw a CTV \\
      \midrule
      zzAMLART017 & ``only scanned bottom of kidneys'' & We should be cautious of variability of width scope given in our source data \\
      \midrule
      zzAMLART017 & ``missing left kidney'' & Unusual body anatomy might trip up the model, mentioned elsewhere are also  \\
      \midrule
      zzAMLART041 & ``extra slices'' & variability in voxels or quantity may require data pre-processing to eliminate data uncertainty \\
      \midrule
      zzAMLART055 & ``no contrast - hard to see LNs. NG tube in situ. posterior renal vein. small parametrium and low uterus'' & An edge case like this will require more thought \\
      \bottomrule
  \end{tabular}
  \caption{A few captivating notes about each patient and why it might be concerning}
  \label{tab:notes-summary}
\end{table}

There exist note entires for the majority of the 100 patients which weren't shown in Table \ref{tab:notes-summary}. Regardless, these notes are helpful to identify what type of pre-processing we must do in order to fully address some differences between patients. The concern is to not overfit on the 'normal' cases but also generalize and engineer a solution that is also open-minded to extreme or poorly captured cases; there is a vast variability in the anatomy of patients which makes computer vision tasks more challenging.

\section{Delineation classes}\label{sec:data-delineation-classes}

The clinicians at the Royal Marsden Hospital have provided segmentation labels for 5 high-priority classes of interest. These are the Bladder, Anorectum, CTVn, CTVp, and Parametrium. 

\subsection{Organs At Risk}\label{sec:data-organs-at-risk}

\begin{figure}[H]
  \centering
  \subfigure[Axial]{
    \includegraphics[width=0.3\textwidth]{../figures/PatientStructureExamples/Anorectum_003/Axial.png}
    \label{fig:example-anorectum-axial}
  }
  \subfigure[Coronal]{
    \includegraphics[width=0.3\textwidth]{../figures/PatientStructureExamples/Anorectum_003/Coronal.png}
    \label{fig:example-anorectum-coronal}
  }
  \subfigure[Sagittal]{
    \includegraphics[width=0.3\textwidth]{../figures/PatientStructureExamples/Anorectum_003/Sagittal.png}
    \label{fig:example-anorectum-sagittal}
  }
  \vspace{1em}
  \subfigure[Axial]{
    \includegraphics[width=0.3\textwidth]{../figures/PatientStructureExamples/Bladder_088/Axial.png}
    \label{fig:example-bladder-axial}
  }
  \subfigure[Coronal]{
    \includegraphics[width=0.3\textwidth]{../figures/PatientStructureExamples/Bladder_088/Coronal.png}
    \label{fig:example-bladder-coronal}
  }
  \subfigure[Sagittal]{
    \includegraphics[width=0.3\textwidth]{../figures/PatientStructureExamples/Bladder_088/Sagittal.png}
    \label{fig:example-bladder-sagittal}
  }
  \caption{Views of a segmented (in red) Anorectum (\ref{fig:example-anorectum-axial}-\ref{fig:example-anorectum-sagittal}) and Bladder (\ref{fig:example-bladder-axial}-\ref{fig:example-bladder-sagittal}) of an arbitrary patient}
\end{figure}

An organ at risk is an organ which has a substantial probability of being within the PTV despite being healthy. Any areas that are created around the area should actively avoid these organs because by overlapping with them we risk complicating the treatment and compromising the health of functioning organs.

Many anatomies have been provided in the risk categories, however, in particular we have been supplied with contours for the Bladder (Figure \ref{fig:example-bladder-axial}-\ref{fig:example-bladder-sagittal}) and the Anorectum (Figure \ref{fig:example-anorectum-axial}-\ref{fig:example-anorectum-sagittal}). In particular, clinicians have identified that the Bladder may overlap with the CTVn (Section \ref{sec:data-CTVn}) and the Parametrium (Section \ref{sec:data-Parametrium}). 

\subsection{CTVp}\label{sec:data-CTVp}

\begin{figure}[H]
  \centering
  \subfigure[Axial]{
    \includegraphics[width=0.3\textwidth]{../figures/PatientStructureExamples/CTVp_096/Axial.png}
    \label{fig:example-CTVp-axial}
  }
  \subfigure[Coronal]{
    \includegraphics[width=0.3\textwidth]{../figures/PatientStructureExamples/CTVp_096/Coronal.png}
    \label{fig:example-CTVp-coronal}
  }
  \subfigure[Sagittal]{
    \includegraphics[width=0.3\textwidth]{../figures/PatientStructureExamples/CTVp_096/Sagittal.png}
    \label{fig:example-CTVp-sagittal}
  }
  \caption{Views of a segmented (in red) CTVp of an arbitrary patient}
  \label{fig:example-CTVp}
\end{figure}

The CTVp stands for the Primary Clinical Target Volume, see the example at Figure \ref{fig:example-CTVp}. This is the CTV where there may be local microscopic spread (uterus, cervix, upper vagina, primary tumour)~\cite{AMLART-data}. This is the area that contains the tumour.

This isn't by any means an organ in a body, but rather an area comprised of other components formed by joining other structures together. The CTVp is an area defined in Equation \ref{eq:ctvp}.

\subsection{CTVn}\label{sec:data-CTVn}

\begin{figure}[H]
  \centering
  \subfigure[Axial]{
    \includegraphics[width=0.3\textwidth]{../figures/PatientStructureExamples/CTVn_007/Axial.png}
    \label{fig:example-CTVn-axial}
  }
  \subfigure[Coronal]{
    \includegraphics[width=0.3\textwidth]{../figures/PatientStructureExamples/CTVn_007/Coronal.png}
    \label{fig:example-CTVn-coronal}
  }
  \subfigure[Sagittal]{
    \includegraphics[width=0.3\textwidth]{../figures/PatientStructureExamples/CTVn_007/Sagittal.png}
    \label{fig:example-CTVn-sagittal}
  }
  \caption{Views of a segmented (in red) CTVn of an arbitrary patient}
  \label{fig:example-CTVn}
\end{figure}

The CTVn stands for Nodal Clinical Target Volume, see the example at Figure \ref{fig:example-CTVn}. This is the CTV where there may be microscopic spread to lymph nodes. It is drawn based on set margins around pelvic blood vessels and includes pelvic lymph nodes, common iliac lymph nodes and para-aortic lymph nodes~\cite{AMLART-data}. 

Similarly to CTVp, this is a compound area with three groups of lymph nodes. In clinical practice, the number of these groups included in the CTV varies in each patient, depending on how advanced the disease is. Pathological lymph nodes (GTVn) are also included. The CTVn is an area defined in Equation \ref{eq:ctvn}.

\subsection{Parametrium}\label{sec:data-Parametrium}

\begin{figure}[H]
  \subfigure[Axial]{
    \includegraphics[width=0.3\textwidth]{../figures/PatientStructureExamples/Parametrium_088/Axial.png}
    \label{fig:example-Parametrium-axial}
  }
  \subfigure[Coronal]{
    \includegraphics[width=0.3\textwidth]{../figures/PatientStructureExamples/Parametrium_088/Coronal.png}
    \label{fig:example-Parametrium-coronal}
  }
  \subfigure[Sagittal]{
    \includegraphics[width=0.3\textwidth]{../figures/PatientStructureExamples/Parametrium_088/Sagittal.png}
    \label{fig:example-Parametrium-saggital}
  }
  \caption{Views of a segmented (in red) Parametrium of an arbitrary patient}
  \label{fig:example-Parametrium}
\end{figure}

The Parametrium (or Paravagina) is the tissue surrounding the cervix/vagina - at risk of local spread, see Figure \ref{fig:example-Parametrium}. Drawn as a complete structure and editing back to the level of vagina to be included~\cite{AMLART-data}.

\section{Establishing Rules for Structures}\label{sec:data-delineation-rules}

\begin{minipage}{0.5\textwidth}
  \subsubsection{Notation of Structures}
  \begin{enumerate}
    \item Let the Anorectum be denoted as $A$
    \item Let the Bladder be denoted as $B$
    \item Let the Cervix be denoted with $C$
    \item Let the CTVn be denoted with $C_n$
    \item Let the CTVp be denoted with $C_p$
    \item Let the GTVp be denoted with $G_p$
    \item Let the GTVn be denoted with $G_n$
    \item Let the Pelvic Lymph Node be denoted as $L_p$
    \item Let the Common Iliac Lymph Node be denoted as $L_i$
    \item Let the Para-aortic Lymph Node be denoted as $L_{pa}$
  \end{enumerate}
\end{minipage}%
\begin{minipage}{0.5\textwidth}

\begin{enumerate}
  \setcounter{enumi}{10}
  \item Let the Parametrium be denoted with $P$
  \item Let the Uterus be denoted with $U$
  \item Let the Vagina be denoted with $V$
\end{enumerate}

\subsection{Relationship between Structures}

\begin{enumerate}
  \item Let $O$ denote the set $O = \{B, A, C_n, C_p, P \}$ for a particular patient. If we want to talk about a specific patient, we should use the super-script notation to differentiate patients, e.g., $O^i = \{B^i, A^i, C_n^i, C_p^i, P^i\}$.
  \item Let the overlap of two structures be denoted by the set intersect symbol $\cap$.
  \item Let the joint area of two structures be denoted by the set union symbol $\cup$.
\end{enumerate}

% \vspace{4em}

\end{minipage}

\subsection{Rules}

The top 5 priority structures have been selected to identify and plan an area where radiotherapy should be used. With these structures, there are rules that the clinicians have outlined, they are quoted for clarification (these structures only refer to each independent patient):

\begin{enumerate}
  \item There should be no overlap between the CTVn, CTVp or Anorectum. 
  
  \begin{equation}
    \forall{i,j \in \{C_n, C_p, A\}}\text{ with } i \neq j, i \cap j = \emptyset
  \end{equation}

  \item The Parametrium may overlap with all of the other structures.
  
  \begin{equation}
    \forall i \in S, \quad P \cap S_i \neq \emptyset \quad \text{(Possibly)}
  \end{equation}

  \item The Bladder may overlap with the CTVn.
  
  \begin{equation}
    B \cap C_n \neq \emptyset \vee B \cap C_n = \emptyset\label{eq:ctvn}
  \end{equation}

  \item The CTVp is defined as a compound structure containing:
  
  \begin{equation}
    C_p = \overbrace{C \cup G_p}^{\text{High Risk CTV}} \quad \cup \quad U \cup V\label{eq:ctvp}
  \end{equation}

  \item The CTVn is defined as a compound structure containing: 
  
  \begin{equation}
    C_n = G_n \cup L_i \cup L_p + L_{pa}
  \end{equation}
  
\end{enumerate}

\section{Data Cleaning}\label{sect:data-cleaning}

\begin{warning}
  TODO
\end{warning}

\chapter{Evaluation Metrics}\label{sect:evaluation-metrics}

To determine if a contour can be used in a clinical context, would be include calculating the difference between the provided labelled data. However, in a delineation context, we have different ways to evaluate this measure.

Suppose we are writing a linear-regression model to match a line onto a set of points. To quantify the performance of our line we would measure the shortest distance between each point and the predicted line. This relies on the assumption of points in a known domain that a model is attempting to approximate. In this case we are fitting a 1-dimensional model onto 0-dimensional points in the grid space. 

However, it is far harder to decide on a scoring system when in a delineation context. Consider a single slice of a CT-scan with a known contour around the perimeter of a tumour\footnote{Here we assume that the contour will hug the GTV tightly with no concern for microscopic spread around the remainder of the system}. A model like those mentioned in Section \ref{sect:vanilla-image-segmentation-models} would attempt to learn a function to closely replicate the contour. Here our domain, prediction and ground truth are all 2-dimensional objects. 

Geometric measures are the most popular, a survey has found~\cite{review-metrics}. These measures compare an auto-contour to a ground-truth contour and return a relative score based on its performance. 

\section{Classification Based}\label{sect:classification-based}

Assesses if voxels within and outside the auto-contour have been correctly labelled~\cite{review-metrics}. To begin, we define 'positive' to mean that the voxel selected is indeed in need of radiotherapy treatment, and 'negative' to mean that the voxel is classified as healthy.

A standard measure of classification is accuracy. It measures the total amount of correct predictions vs the total predictions it made. However, this measure alone isn't enough to fully capture the bias of a model because it doesn't tell you the full story with class-imbalanced data when there isn't an even number between positive and negative labels.

\begin{equation*}
  \text{Accuracy} = \frac{TP + TN}{TP + TN + FP + FN}
\end{equation*}

Better measures are Precision and Recall scores. The Precision (also known as the Positive Predictive Value~\cite{evaluation-metrics}) measures the proportion of predictions that were successfully correct. The Recall (also known as True Positive Rate~\cite{evaluation-metrics}), on the other hand, ``measures the portion of positive voxels in the ground truth that are also identified as positive by the segmentation being evaluated''.

\begin{equation*}
  \text{Precision} = \frac{TP}{TP+FP}, \quad \text{Recall} = \frac{TP}{TP+FN}
\end{equation*}

\section{Spatial Overlap Based} \label{sect:spatial-overlap-based}

Similarly to Classification Based metrics in Section \ref{sect:classification-based}, an Overlap Based metric measures the extent of overlap between an auto-contour and a reference structure~\cite{review-metrics}. 

The scores above can be combined into a more general score $F_\beta$ to give 

\begin{equation*}
  \text{F}_\beta = (1+\beta^2)\cdot \frac{\text{Precision} \cdot \text{Recall}}{\beta^2 \cdot \text{Precision}+\text{Recall}}
\end{equation*}

A specific case of this equation with $\beta=1$ is mathematically equivalent to the DICE Similarity Coefficient which was found to be the most popular evaluation metric amongst 2021 studies~\cite{review-metrics,evaluation-metrics, Sherer2021-le}. 

% \begin{align*}
%   F_1 = \text{DICE} & = \frac{2 \cdot \text{Precision} \cdot \text{Recall}} {\text{Precision} + \text{Recall}} & \\ 
%   % & = \frac{2 \cdot \frac{TP}{TP + FP} \cdot \frac{TP}{TP + FN}}{\frac{TP}{TP + FP} + \frac{TP}{TP + FN}} \\
%   % & = \frac{2 \cdot TP \cdot TP}{TP(TP+FN)+TP(TP+FP)} \\ 
%   & = \frac{2 \cdot TP}{2TP + FP + FN} \quad = \quad \frac{2|S_g^1\cap S_p^1|}{|S_g^1|+|S_p^1|} , \text{where} \begin{cases}
%     S_g^1 & \text{ground truth} \\
%     S_p^1 & \text{segmentation}
%   \end{cases}
% \end{align*}

\begin{equation*}
  F_1 = \text{DICE} = \frac{2 \cdot \text{Precision} \cdot \text{Recall}} {\text{Precision} + \text{Recall}} = \frac{2 \cdot TP}{2TP + FP + FN} \quad = \quad \frac{2|S_g\cap S_p|}{|S_g|+|S_p|}
\end{equation*}

Where $S_g$ is the ground truth segmentation and $S_p$ is the predicted segmentation. From this relationship, the DICE score has found popularity in image segmentation for similar reasons that the $F_1$ score has found its popularity classical machine learning; it is able to provide a fair result for imbalanced datasets. This mentality is applicable in our scenario because a tumour will make up very little of the total volume of the domain space. This can be extended to a Volumetric DSC by considering the above in all 3-dimensions~\cite{APL}.

Another popular related evaluation method is the Jaccard Index, which measures the intersection over the union of two sets:

\begin{equation*}
  \text{JAC} = \frac{TP}{TP+FP+FN} = \frac{|S_g\cap S_p|}{|S_g \cup S_p|} \iff \frac{DICE}{2 - DICE}
\end{equation*}

Since the numerator for the Jaccard Index is smaller (since we avoid the issue of counting the intersecting sections twice) the JAC is always larger than the DICE score.

\section{Surface Based} \label{sect:surface-based}

Also commonly known as Boundary-Distance-Based Methods~\cite{boundary-overlap-metrics} compares the distance between two structure
surfaces. These can be either maximum distance, average distance or distance at a set percentile of ordered distances~\cite{evaluation-metrics}.

A common example is the Haussdorf Distance. Here, a directed distance metric is defined as the maximum distance from a point in the first set to a nearest point in the other between two individual voxels~\cite{boundary-overlap-metrics}. Therefore, the better the HD metric, the smaller the value it returns. Here, the distance is taken by some norm, typically Euclidian distnace.

\begin{equation*}
  \text{HD}(A,B) = \max(h(A,B), h(B,A)), \quad \text{ and directed h}(A,B)=\max_{a\in A}\min_{b \in B} ||a-b||
\end{equation*}

The HD is generally sensitive to outliers. Because noise and outliers are common in medical segmentations, it is not recommended to use the HD directly~\cite{boundary-overlap-metrics}. Therefore, we can calculate the average directed Haussdorf Distance.


\section{Volume Based}

Volume-based metrics consider only the volume of the segmentation~\cite{evaluation-of-metrics-in-prostate,review-metrics, boundary-overlap-metrics}. However, due to its poor spatial descriptions it is more commonly used jointly with other metrics.

\begin{equation*}
  \text{Relative Volume Difference (RVD)} = \bigg| \frac{|S_g|-|S_p|}{|S_g|}\bigg|
\end{equation*}

\section{Evaluation}\label{sect:evaluation-of-evaluation-methods}

All these methods can be advantageous in some places rather than other. We can begin to list off some challenging scenarios to decide which segmentation is the best.

\begin{figure}[H]
  \centering
  \includegraphics[width=\linewidth]{../figures/segmentation-cases-1.png}
  \caption{Figure from~\cite{boundary-overlap-metrics} illustrating cases of segmentation to aid with explanation of set-backs of certain evaluation metrics}
  \label{fig:segmentation-cases-1}
\end{figure}

\begin{itemize}
  \item Classification Based (Section \ref{sect:classification-based}) and Spatial Overlap Based (Section \ref{sect:spatial-overlap-based}) are similar; they are concerned with the number of correctly classified or misclassified voxels without taking into account their spatial distribution. Here, Figure \ref{fig:segmentation-cases-1}(a) and Figure \ref{fig:segmentation-cases-1}(c) would achieve similar results despite Figure \ref{fig:segmentation-cases-1}(a) being locally bound to a better area.
  \item With Haussdorf Distance (Section \ref{sect:surface-based}) output segmentations generated by Figure \ref{fig:segmentation-cases-1}(d) and Figure \ref{fig:segmentation-cases-1}(e) will result in the same score, which is not favorable in a radiotherapy planning environment where an organ-at-risk is involved.
  \item Figure \ref{fig:segmentation-cases-1}(b) would score flawlessly when using volumetric score estimation, however, it doesn't take into acount spatial placement, which makes this measurement rather poor when used individually.
\end{itemize}

\section{Estimated Editing Based}\label{sect:surface-dice}

\begin{warning}
  This is a quotation from this paper,~\cite{Sherer2021-le}, however, it is referencing a paper of its own. Shall I reference the original paper or are 'linked' references OK?
\end{warning}

It is difficult to select a measurement which can reflect a clinicians acceptability score. A study found that there was a lack of correlation between a geometric index and expert evaluation, with the JAC score having a 13\% False Positive Rate. The conclusion of the study summarised that scores such as JSC and volumetric DSC, ``provide limited clinical context and correlation with clinical or dosimetric quality''~\cite{Sherer2021-le}.

Because of the clinical context of evaluating the segmentation by a machine, it may sometimes be helpful to define a performance metric as the ``fraction of the surface that needs to be redrawn''~\cite{Nikolov2021-xe} since models at this point require manual review to avoid automation bias (Section \ref{sect:using-the-tool}). For larger structures, this method is useful it doesn't assign a lot of weight on the large trivial internal volume which accounts for a much larger proportion of the score.

\subsection{Surface DSC} \label{sect:surface-DSC}

The study at~\cite{Sherer2021-le} helped drive an initiative to combine aspects of Surface Based evaluation (Section \ref{sect:surface-based}) and Spatial Overlap Based evaluation (Section \ref{sect:spatial-overlap-based}) into a Surface DICE. This assesses the specified tolerance instead of the overlap of the two volumes. 

\begin{figure}[H]
  \centering
  \includegraphics[width=0.3\linewidth]{../figures/Surface-dice.png}
  \caption{Taken from~\cite{Nikolov2021-xe}. Illustrates the computation of the surface DICE, where the continuous line is the predicted surface and the dashed line is the ground truth. The black arrows show the maximum deviation tolerated without penalty; therefore, in pink is the unacceptable deviations and green otherwise.}
\end{figure}

We can formulate the Surface DSC score in a mathematical definition~\cite{Sherer2021-le}.

\begin{equation*}
  \text{Surface DSC} = \frac{|S_p \cap B_{g,\tau}| + |S_g \cap B_{p,\tau}|}{|S_p| + |S_g|}
\end{equation*}

Which provides a measure of the agreement between just the surfaces of two structures above a clinically determined tolerance parameter, $\tau$. Here, $B_{p,\tau}$ represents the  boundary region of the predicted surface within a maximum margin of deviation $\tau$ and similarly for $B_{g,\tau}$ for the ground truth.

\subsection{Added Path Length}

In a similar spirit, the APL was proposed as a score to predict ``the path length of a contour that has to be added''~\cite{APL}. This is achieved similarly by considering the number of added voxels required between the prediction and the gold standard with no regard to tolerance as a pose to Surface DSC (Section \ref{sect:surface-DSC})

\begin{warning}
  For future reference, \textit{\href{https://stackoverflow.com/questions/73286639/how-to-calculate-added-path-length-apl-image-segmentation-metric}{stack overflow discussion}}

  Implementation of surface DSC and APL: \textit{\href{https://github.com/pyplati/platipy/blob/master/platipy/imaging/label/comparison.py}{source code}}
\end{warning}

\section{Summary}

This is why we settle at the Surface DSC (Section \ref{sect:surface-dice}) which prioritizes deviation along boundary to a certain degree while measuring the fraction of the surface that needs to be redrawn, thus favouring a more conservative prediction of Figure \ref{fig:segmentation-cases-1}(d) instead of (e).

For the purpose of this project, we shall select a evaluation measurement which is more bias towards conservative boundary estimates to not touch the organs at risk. This choice was in-part influenced by the clinician's review pipeline; it would easier to correct Figure \ref{fig:segmentation-cases-1}(d) instead of (e) because correcting the latter would likely take a considerable amount of time as it would require redrawing almost all of the boundary, whereas the former could be corrected much faster~\cite{Nikolov2021-xe}.

% \begin{figure}[H]
%   \centering
%   \includegraphics[width=\linewidth]{../figures/segmentation-cases-2.png}
%   \caption{Figure from~\cite{evaluation-of-metrics-in-prostate} illustrating cases of segmentation to aid with explanation of set-backs of certain evaluation metrics}
%   \label{fig:segmentation-cases-2}
% \end{figure}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Proposal}\label{sect:proposal}

\section{Baseline Results}\label{sect:baseline-results}

\begin{warning}
  TODO for all
\end{warning}

\subsection{nnU-Net}\label{sect:results-nnu-net}

\subsection{Total Segmentator}\label{sect:results-totalseg}

\subsection{UinverSeg}\label{sect:results-universeg}

\section{Summary}\label{sect:results-summary}


\begin{warning}
  Should we keep labels individual and segment them separately or should we segment it all in one shot?
\end{warning}

\begin{warning}
  Solution to resolution problem, down-sample all samples or think of average?
\end{warning}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Ethics}\label{sect:ethics}

This project involves very intimate and personal information of many female patients. Researchers may collaborate with third-parties by providing anonymized data which may not be reverse engineered back to the patient.
The lack of this effort may result in ``stigma, embarrassment, and discrimination''~\cite{health-privacy} if the data is misused.

\section{Patient disclosures}\label{sect:patient-disclosures}

The Royal Marsden Hospital doesn't require ``explicit consent'' for sharing collected clinical data with outside entities as long as the patient is made aware of the ways their ``de-identified/anonymized'' data may be used ~\cite{royal-marsden-privacy-note}. Formalities are also arranged with Imperial Collage's Medical Imaging team such as acting as ``ethical data stewards''~\cite{ethics-imaging-AI}. Without such disclosure and anonymisation of data, patients may be reluctant to provide candid and complete disclosures of their sensitive information, even to physicians, which may prevent a full diagnosis if their data isn't maintained in an anonymous fashion.

The MIRA team acts as responsible data stewards by storing anonymized data within a folder on the college network. All provided data was anonymized by the Royal Marsden Hospital and sent to team MIRA in the \texttt{NIfTI} file format which discloses no personal identifiable information, as defined by GOV website~\cite{gov-gdpr}. This folder contains security measures which limit the availability of data only to those with specific access rights. Furthermore, operating on the preamble of de-identified data further reduces individual patient risk in the event that data is ever brought outside the confines of this folder.

\section{Using the tool}\label{sect:using-the-tool}

The applications of this tool bode well in the healthcare ecosystem as the community slowly realizes the importance of AI-powered tools for the next generation of medical technology. Radiology has been one application that has been most welcoming of the new advances in technology as there is potential for substantial aid by reducing manual labor, increasing precision and freeing up the primary care physician's time~\cite{overview-of-ai-medicine}.

Yet, it is too early to take result the medical tool as gospel. For current cervical radiotherapy delineation tools, only 90\% of the output is considered as acceptable for clinical use~\cite{auto-delineation-cervical-cancer-development}. The remainder therefore has the potential to cause more harm than good if not checked properly. For example, overlap of a PTV onto an organ-at-risk may invoke a cascade of negative effects for the patient. A potential cause may be the lack of multivariate analysis, where an oncologist would need to consider a variety of data, whereas this model only considers a single point of evidence (results of an imaging modality).

Clinicians can fall into the trap of automation-bias as AI becomes more common place in clinical environments~\cite{automation-bias}. However, many models of this age codify the existing bias in common cases, which often will fail those patients who do not fit the expectations of the majority. Therefore, a degree of supervision required from physicians has to be established if this tool is to be used in practice. Oncologists will be required to reverse-engineer results of the `black-box' to verify why a decision has been made. Secondly, the responsible party for incorrect decisions made by DL tools should also be determined~\cite{AI-in-cancer-diagnosis-era}.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\printbibliography
\addcontentsline{toc}{chapter}{Bibliography}

\end{document}